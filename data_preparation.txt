############################################################################################################################
###                                                                                                                      ###
### R log book describing the data preparation steps for the analyses presented in the paper:                            ###
### Determinants of phonetic word duration in ten language documentation corpora                                         ###
### by Jan Strunk, Frank Seifart, Swintha Danielsen, Iren Hartmann, Brigitte Pakendorf, Søren Wichmann,                  ###
### Alena Witzlack-Makarevich, and Balthasar Bickel                                                                      ###
###                                                                                                                      ###
### 2019                                                                                                                 ###
###                                                                                                                      ###
############################################################################################################################


### Import data

## Baure

# Prepare corpus for importing
preparecorpus.bat Korpora\Baure 2016-01-06 ref brg

# List of files - 61 files
AD-090807S.tbt
AD_DC-C060401S.txt
CS_FS-C090809S.txt
DC-081105S.txt
DC-C081111SL.tbt
DC-D101027S-2.txt
DC-N101103S-3.tbt
DC-N121215S-3.txt
DC-N121216S.txt
DC-N121218S.tbt
DC-P081201L.tbt
DC-P090914S-4.tbt
DC-S090914S-1.tbt
DC-S090914S-2.txt
DC-S090914S-3.txt
DC_AM-C081114L.tbt
HC-D120509S-1.tbt
HC-D120509S-2.tbt
HC-D120514S.tbt
HC-P030913S-3.txt
HC_PO-120518S.tbt
II-P081210L.txt
JP-S040709S-2.tbt
JP-S040709S-4.tbt
JP-S040709S-5.tbt
JP-S040709S-6.tbt
JP-S040709S-7.tbt
LO-P101030S-1.txt
LO_GP-N091220P.txt
LO_GP-P091220P-2.txt
MC_DC-C090812S.tbt
RP-101206S-1.tbt
RP-110901S-3.tbt
RP-110901S-4.tbt
RP-110904S.tbt
RP-D081118S.txt
RP-D101030S-1.tbt
RP-D101030S-2.txt
RP-D101030S-3.tbt
RP-D101030S-4.tbt
RP-N030929S-1.tbt
RP-N040721S.tbt
RP-N040724S-5.txt
RP-N081126SL.tbt
RP-N081128L.tbt
RP-N081212LF.tbt
RP-N090810S-2.txt
RP-N110901S-1a.tbt
RP-N110901S-2b.tbt
RP-N110901S-3a.tbt
RP-N120507S-1.tbt
RP-N121213S-2.tbt
RP-P030819S-1.txt
RP-P081120L.tbt
RP-P081126L.tbt
RP-P081212LF.tbt
RP-P090810S.txt
RP-S081126L-1.tbt
RP-S081126L-2.tbt
RP_DC-C090811S.txt
SIL3-N.txt

# Toolbox markers
ELANBegin
ELANEnd
ELANMediaExtracted
ELANMediaMIME
ELANMediaURL
ELANParticipant
WordBegin
WordEnd
fldps
ft
ftE
ge
le
lg
mb
mt
nt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root
ntvr_ref
ps
ref
root
tx
tx2


# Count tokens using Python
counttokens.bat Korpora\Baure 2016-01-06 ref tx WordBegin WordEnd fldps le root mb ge ps lg ntvr_ps_root mt
10930 tokens found in tier ref
29771 tokens found in tier tx
28621 tokens found in tier WordBegin
28621 tokens found in tier WordEnd
29771 tokens found in tier fldps
29771 tokens found in tier le
29771 tokens found in tier root
52707 tokens found in tier mb
52707 tokens found in tier ge
52707 tokens found in tier ps
52707 tokens found in tier lg
52707 tokens found in tier ntvr_ps_root
52707 tokens found in tier mt

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
baure.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "ELANParticipant", "nt", "ft", "ftE", "tx2"),
"word" = c("tx", "WordBegin", "WordEnd", "ntvr_ps_word", "fldps", "le", "root"),
"morpheme" = c("mb", "ge", "ps", "lg", "ntvr_ps_root", "mt")
)

baure.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Baure/UniqueRecordMarker/2016-01-06/", full.names=T), baure.fmt)

length.corpus(baure.corpus.pos.positiontracking, "record")
[1] 7967

length.corpus(baure.corpus.pos.positiontracking, "word")
[1] 29771

length.corpus(baure.corpus.pos.positiontracking, "morpheme")
[1] 52707

# Problems detected in the corpus
baure.parselog.pos.positiontracking = parse.log(baure.corpus.pos.positiontracking)
write.parselog(baure.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Baure/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
baure.corpus.pos.data.frame = as.data.frame(baure.corpus.pos.positiontracking)

# Set correct encoding
baure.corpus.pos.data.frame = set.encoding(baure.corpus.pos.data.frame)

# Combine morphemes into words
baure.corpus.pos.data.frame = combine.morphemes.into.words(baure.corpus.pos.data.frame, c("mb","ge","ps","lg","ntvr_ps_root","mt"))

# Original part-of-speech tags
table(baure.corpus.pos.data.frame$ps)

         -       -adv -base.suff       -clf      -intj         -n       -num       -prn     -redup       -rep -root.suff -stem.suff      -suff    -v.suff        ***        ???         ?v 
       360         10       5879        645         13         70        118          1         97          1        161        647       2928        135        400          7          1 
  =cl.encl  =psn.encl        adj       adj-       adj?        adv        art        aux base.pref-    cl.encl        clf      compl       conj        dem        det expression       ideo 
      1263       2655        835        112          1       3283        167          1        108          1         12         48       1886       2851       1193         69          9 
      intj      intj?        loc          n         n-       name        neg        num       num-   particle      pref-       prep   prevpart        prn  psn.prcl=         qu     redup- 
      1622          1          2       4665          1         28        858        192        124       1415         23        143        944       1041       7392         31         21 
         v 
      8237 

# Cross-linguistic part-of-speech tags
table(baure.corpus.pos.data.frame$ntvr_ps_root)

     - -AFFIX   -BPN     -N -OTHER   =BPN =OTHER AFFIX-    AUX   BPN=      N     N-  OTHER    PRO      V 
   360  10624      1     70     10   2655   1263    388      1   7392   4693      1  15970   1041   8238 



## Bora

# Prepare corpus for importing
preparecorpus.bat Korpora\Bora 2016-01-06 ref boa

# List of files - 37 files
aakityeAC1.txt
aakityeJP1.txt
aakityeMM1.txt
ajpakyo_hist.txt
booake_idyone.txt
bora_inf_2.txt
cahu_1.txt
cahu_2.txt
cntres_10_Bora.txt
dahpe_VR.txt
fb_6.txt
ijtyahooja.txt
inf_josrobetc3.txt
llijchu_ine_I.txt
llijchu_ine_II1.txt
lluuhii.txt
maloca_renov.txt
meenujkatsi.txt
mEEvaAurel06.txt
mEEvaMM06_5.txt
mEEva_llij.txt
mEEva_ran.txt
minga_2.txt
minga_7.txt
minga_8.txt
namedij_aurel.txt
nEjke_kuriota.txt
niivuwa.txt
niivuwajE.txt
ovehe_1.txt
peetsocouuba.txt
piivyeebe_ajyu.txt
taava_meewa.txt
vuurihii.txt
wakyu_cant_1.txt
wakyu_hist.txt
warEhko_mEE.txt

# Toolbox markers
ELANBegin
ELANEnd
ELANMediaExtracted
ELANMediaMIME
ELANMediaURL
ELANParticipant
WordBegin
WordEnd
com
com_MO
com_RB
f
fe
fldps
gl
le
mb
mt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root
ntvr_ps_word
ntvr_ref
ps
ref
root
t

# Count tokens using Python
counttokens.bat Korpora\Bora 2016-01-06 ref t WordBegin WordEnd fldps le root ntvr_ps_word mb gl ps ntvr_ps_root mt
4062 tokens found in tier ref
30140 tokens found in tier t
30140 tokens found in tier WordBegin
30140 tokens found in tier WordEnd
30140 tokens found in tier fldps
30002 tokens found in tier le              # Checked! Correct! Missing le and root tokens due to records without glosses
30002 tokens found in tier root
30140 tokens found in tier ntvr_ps_word
66470 tokens found in tier mb
66470 tokens found in tier gl
66470 tokens found in tier ps
66470 tokens found in tier ntvr_ps_root
66470 tokens found in tier mt

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
bora.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "ELANParticipant", "com", "com_RB", "com_MO", "f", "fe"),
"word" = c("t", "ntvr_ps_word", "WordBegin", "WordEnd", "fldps", "le", "root"),
"morpheme" = c("mb", "gl", "ps", "ntvr_ps_root", "mt")
)

bora.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Bora/UniqueRecordMarker/2016-01-06/", full.names=T), bora.fmt)

length.corpus(bora.corpus.pos.positiontracking, "record")
[1] 4062

length.corpus(bora.corpus.pos.positiontracking, "word")
[1] 30140

length.corpus(bora.corpus.pos.positiontracking, "morpheme")
[1] 66470

# Problems detected in the corpus
bora.parselog.pos.positiontracking = parse.log(bora.corpus.pos.positiontracking)
write.parselog(bora.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Bora/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
bora.corpus.pos.data.frame = as.data.frame(bora.corpus.pos.positiontracking)

# Set correct encoding
bora.corpus.pos.data.frame = set.encoding(bora.corpus.pos.data.frame)

# Combine morphemes into words
bora.corpus.pos.data.frame = combine.morphemes.into.words(bora.corpus.pos.data.frame, c("mb","gl","ps","ntvr_ps_root","mt"))

# Original part-of-speech annotation
table(bora.corpus.pos.data.frame$ps)

      -    -***      -?    -clf    -cli     -nd     -ni     -vd     -vi     ***       ?      ?-       a     adv     con     det     itj      iv       n   n.abs   n.col   n.loc   n.pos 
     51       4      59    3084    6571     421   12136    2303    8934     597      95       1     946    3934    1210    1590     224    1928    3448     742     818     606      76 
    ni-      no     num    onom     p.n    part    pron sng_elm      tv       v   v.sta     vd-     vi- 
   1161    6149      20     343     285     619      14       5    4211    2017     170     267    1431 

# Cross-linguistic part-of-speech tags
table(bora.corpus.pos.data.frame$ntvr_ps_root)

     - -AFFIX   -BPN    *** AFFIX-    BPN   BPN-   BPP-  FLDPS      N  OTHER    PRO      V 
    51  30494   3018    364    274   1120   1431   1155    231   5967   9355   4686   8324 

# Cross-linguistic part-of-speech tags for whole words
table(bora.corpus.pos.data.frame$ntvr_ps_word)

    ***     BPN     BPP   FLDPS       N   OTHER     PRO UNKNOWN       V 
    138    1123      12     586   12293   17960   11327      17   23152 



## Chintang

# Prepare corpus for importing
preparecorpus.bat Korpora\Chintang 2016-01-06 ref ctn

# List of files - 55 files
bhale_song.txt
Burhahang_01.txt
celi_azik_01.txt
chintang_now.txt
comolung_song.txt
ctn_prob_talk.txt
ctn_song_RM01.txt
Durga_job.txt
hutlung_1.txt
Intro_chintang.txt
kamce_talk.txt
kholamang.txt
lifestory_JK.txt
mechacha_talk.txt
pani_panca.txt
pear_1-1.txt
pear_1-2.txt
pear_1-3.txt
pear_1-4.txt
pear_11-1.txt
pear_12-1.txt
pear_14-1.txt
pear_2-1.txt
pear_2-2.txt
pear_2-3.txt
pear_3-1.txt
pear_3-2.txt
pear_3-3.txt
pear_3-4.txt
pear_3-5.txt
pear_5-1.txt
pear_6-1.txt
pear_7-1.txt
pear_8-1.txt
pear_8-2.txt
pear_8-3.txt
pear_8-4.txt
phidang_talk.txt
rajdeo_02.txt
rajdeu_wal01.txt
rana_pilgrim.txt
sadstory_RM.txt
story_chintang.txt
story_demon.txt
story_rabbit.txt
story_tiger.txt
Student_life.txt
sudhar_cuwa.txt
sudhar_daijo.txt
sudhar_pakuwa.txt
sudhar_palawa.txt
tele_des.txt
them_talk.txt
tupla_phema_1.txt
wassa_katha.txt

# Toolbox markers
Comment
ELANBegin
ELANEnd
ELANMediaExtracted
ELANMediaMIME
ELANMediaURL
ELANParticipant
WordBegin
WordEnd
anno
check
comm
comment
conv
cxt
dt
ed
eng
eth
fldps
gram
grandfather1
gw
id
le
lg
mgl
mph
mt
nep
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root
ntvr_ref
ps
qst
ref
root
rt
tx
unknown

# Count tokens using Python
counttokens.bat Korpora\Chintang 2016-01-06 ref gw WordBegin WordEnd fldps le root mph mgl ps ntvr_ps_root lg id mt
12364 tokens found in tier ref
47868 tokens found in tier gw
47868 tokens found in tier WordBegin
47868 tokens found in tier WordEnd
47868 tokens found in tier fldps
47868 tokens found in tier le
47868 tokens found in tier root
82417 tokens found in tier mph
82417 tokens found in tier mgl
82417 tokens found in tier ps
82417 tokens found in tier ntvr_ps_root
82417 tokens found in tier lg
61936 tokens found in tier id
82417 tokens found in tier mt

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
chintang.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "ELANParticipant", "comment", "dt", "eng", "nep"),
"word" = c("gw", "WordBegin", "WordEnd", "ntvr_ps_word", "fldps", "le", "root"),
"morpheme" = c("mph", "mgl", "ps", "lg", "id", "ntvr_ps_root", "mt")
)

chintang.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Chintang/UniqueRecordMarker/2016-01-06/", full.names=T), chintang.fmt)

length.corpus(chintang.corpus.pos.positiontracking, "record")
[1] 12364

length.corpus(chintang.corpus.pos.positiontracking, "word")
[1] 47868

length.corpus(chintang.corpus.pos.positiontracking, "morpheme")
[1] 82417

# Problems detected in the corpus
chintang.parselog.pos.positiontracking = parse.log(chintang.corpus.pos.positiontracking)
write.parselog(chintang.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Chintang/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
chintang.corpus.pos.data.frame = as.data.frame(chintang.corpus.pos.positiontracking)

# Set correct encoding
chintang.corpus.pos.data.frame = set.encoding(chintang.corpus.pos.data.frame)

# Combine morphemes into words
chintang.corpus.pos.data.frame = combine.morphemes.into.words(chintang.corpus.pos.data.frame, c("mph","mgl","lg","ps","id","ntvr_ps_root","mt"))

# Original part-of-speech annotation
table(chintang.corpus.pos.data.frame$ps)

     -    -gm     -n   -pro    -v2    -vi    -vt     13     59   6870    adj    adv     gm    gm- interj      n   none    num    pro   pro-  sound     v-     vi    vi-     vt    vt- 
   169  27685     25      2   2611     27      7      2      1      2    944   4102  11036   3906   4209   9846    362   1132   6017      4     12      5   4052     15   6181     63 

# Cross-linguistic part-of-speech tags
table(chintang.corpus.pos.data.frame$ntvr_ps_root)

     - -AFFIX   -BPN     -N   -PRO     -V AFFIX-   BPN-   BPP-      N  OTHER    PRO   PRO-      V     V- 
   169  25588   4735     25      2      7    697   2082   1127   9846  21802   6017      4  10233     83 



## Dutch (Corpus Gesproken Nederlands)

preparecorpus.bat Korpora\Dutch 2016-01-06 ref nld

# List of files - 17 files
fn000086.txt
fn000106.txt
fn000137.txt
fn000140.txt
fn000254.txt
fn000265.txt
fn000280.txt
fn000415.txt
fn000446.txt
fn000485.txt
fn000505.txt
fn000559.txt
fn000570.txt
fn000573.txt
fn000587.txt
fn000594.txt
fn000674.txt

# Toolbox markers
ELANBegin
ELANEnd
ELANParticipant
WordBegin
WordEnd
fldps
le
mb
mg
ml
mr
mt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root_old
ntvr_ps_word
ntvr_ref
ph
ps
ref
rl
sl
tx

# Count tokens using Python
counttokens.bat Korpora\Dutch 2016-01-06 ref tx WordBegin WordEnd fldps ph le mr mg ps sl rl ntvr_ps_root_old mb ml mt ntvr_ps_root
5822 tokens found in tier ref
39720 tokens found in tier tx
39720 tokens found in tier WordBegin
39720 tokens found in tier WordEnd
39720 tokens found in tier fldps
39720 tokens found in tier ph
39720 tokens found in tier le
39720 tokens found in tier mr
39720 tokens found in tier mg
39720 tokens found in tier ps
39720 tokens found in tier sl
39720 tokens found in tier rl
39720 tokens found in tier ntvr_ps_root_old
48738 tokens found in tier mb
48738 tokens found in tier ml
48738 tokens found in tier mt
0 tokens found in tier ntvr_ps_root

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
# TODO: Ignore morphemes for now until morphological annotation is complete
dutch.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "ELANParticipant"),
"word" = c("tx", "ph", "le", "WordBegin", "WordEnd", "ntvr_ps_word", "fldps", "mr", "mg", "ps", "sl", "rl", "ntvr_ps_root_old"),
"morpheme" = c("mb","ml","mt","ntvr_ps_root")
)

dutch.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "ELANParticipant"),
"word" = c("tx", "ph", "le", "WordBegin", "WordEnd", "ntvr_ps_word", "fldps"),
"morpheme" = c("mr","mg","ps","ntvr_ps_root_old")
)

dutch.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Dutch/UniqueRecordMarker/2016-01-06/", full.names=T), dutch.fmt)

length.corpus(dutch.corpus.pos.positiontracking, "record")
[1] 5822

length.corpus(dutch.corpus.pos.positiontracking, "word")
[1] 39720

length.corpus(dutch.corpus.pos.positiontracking, "morpheme")
[1] 39720

# Problems detected in the corpus
dutch.parselog.pos.positiontracking = parse.log(dutch.corpus.pos.positiontracking)
write.parselog(dutch.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Dutch/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
dutch.corpus.pos.data.frame = as.data.frame(dutch.corpus.pos.positiontracking)

# Set correct encoding
dutch.corpus.pos.data.frame = set.encoding(dutch.corpus.pos.data.frame)

# Combine morphemes into words
dutch.corpus.pos.data.frame = combine.morphemes.into.words(dutch.corpus.pos.data.frame, c("mb","ml","ntvr_ps_root","mt"))

# Change because of morphological analysis
table(dutch.corpus.pos.data.frame$ps)

 ADJ   BW  LID    N SPEC  TSW   TW   VG  VNW   VZ   WW 
2735 5437 1799 4005 1586 3882  475 2583 7598 2901 6719 

#  ADJ    BW   LID     N  SPEC   TSW    TW    VG   VNW    VZ    WW 
# 4137  5689  1799  6902  1652  3914   812  2583  7598  2901 10751 

# Change because of morphological analysis
table(dutch.corpus.pos.data.frame$ntvr_ps_root_old)

FLDPS     N OTHER   PRO     V V-BPN 
 1798  4005 21405  5793  1733  4986 

# FLDPS     N OTHER   PRO     V V-BPN 
# 1810  6902 23482  5793  3949  6802 

# FLDPS     N OTHER   PRO     V V-BPN 
#  1798  4005 21405  5793  1733  4986 

# Change because of morphological analysis
# TODO: Why different from ntvr_ps_root_old?
table(dutch.corpus.pos.data.frame$ntvr_ps_word)

FLDPS     N OTHER   PRO     V 
 1798  4176 21319  5793  6634 

# FLDPS     N OTHER   PRO     V 
# 1810  7261 23324  5793 10550 

# FLDPS     N OTHER   PRO     V 
# 1798  4176 21319  5793  6634 

# Add an empty translation column
dutch.corpus.pos.data.frame$translation = ""



## English (Switchboard)

preparecorpus.bat Korpora\English 2017-07-19 ref eng

# List of files - 47 files
sw2104.txt
sw2295.txt
sw2305.txt
sw2540.txt
sw2546.txt
sw2558.txt
sw2589.txt
sw2628.txt
sw2667.txt
sw2743.txt
sw2749.txt
sw2761.txt
sw2800.txt
sw2837.txt
sw3012.txt
sw3062.txt
sw3072.txt
sw3080.txt
sw3085.txt
sw3097.txt
sw3120.txt
sw3154.txt
sw3174.txt
sw3182.txt
sw3187.txt
sw3219.txt
sw3223.txt
sw3227.txt
sw3239.txt
sw3246.txt
sw3343.txt
sw3360.txt
sw3409.txt
sw3435.txt
sw3476.txt
sw3495.txt
sw3515.txt
sw3658.txt
sw3697.txt
sw3707.txt
sw4033.txt
sw4049.txt
sw4153.txt
sw4159.txt
sw4358.txt
sw4733.txt
sw4784.txt

# Toolbox markers
ELANBegin
ELANEnd
ELANParticipant
PhonesBegin
PhonesEnd
WordBegin
WordEnd
dialect
fldps
le
mb
mg
mp
mt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root
ntvr_ps_root_old
ntvr_ps_word_old
ntvr_ref
ph
ps
ref
root
sex
st
topic
tx
year

# Count tokens using Python
counttokens.bat Korpora\English 2017-07-19 ref tx WordBegin WordEnd PhonesBegin PhonesEnd ph st ps fldps le root ntvr_ps_word_old ntvr_ps_root_old mb mg mp mt ntvr_ps_root
6941 tokens found in tier ref
56138 tokens found in tier tx
56138 tokens found in tier WordBegin
56138 tokens found in tier WordEnd
56138 tokens found in tier PhonesBegin
56138 tokens found in tier PhonesEnd
56138 tokens found in tier ph
56138 tokens found in tier st
56138 tokens found in tier ps
56138 tokens found in tier fldps
56138 tokens found in tier le
56138 tokens found in tier root
56138 tokens found in tier ntvr_ps_word_old
56138 tokens found in tier ntvr_ps_root_old
61564 tokens found in tier mb
61564 tokens found in tier mg
61564 tokens found in tier mp
61564 tokens found in tier mt
61564 tokens found in tier ntvr_ps_root

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
english.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "ELANParticipant", "topic", "sex", "year", "dialect"),
"word" = c("tx", "ph", "st", "WordBegin", "WordEnd", "PhonesBegin", "PhonesEnd", "ntvr_ps_word_old", "fldps", "ps", "le", "root", "ntvr_ps_root_old"),
"morpheme" = c("mb", "mg", "mp", "mt", "ntvr_ps_root")
)

english.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/English/UniqueRecordMarker/2017-07-19/", full.names=T), english.fmt)

length.corpus(english.corpus.pos.positiontracking, "record")
[1] 6941

length.corpus(english.corpus.pos.positiontracking, "word")
[1] 56138

length.corpus(english.corpus.pos.positiontracking, "morpheme")
[1] 61564

# Problems detected in the corpus
english.parselog.pos.positiontracking = parse.log(english.corpus.pos.positiontracking)
write.parselog(english.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/English/Logs/2017-07-19/parse.positiontracking.log")

# Convert corpus object to data.frame
english.corpus.pos.data.frame = as.data.frame(english.corpus.pos.positiontracking)

# Set correct encoding
english.corpus.pos.data.frame = set.encoding(english.corpus.pos.data.frame)

# Combine morphemes into words
english.corpus.pos.data.frame = combine.morphemes.into.words(english.corpus.pos.data.frame, c("mb","mg","mp","ntvr_ps_root","mt"))

# Original part-of-speech annotation
table(english.corpus.pos.data.frame$ps)

     ^CC      ^DT      ^GW      ^IN      ^JJ      ^NN     ^NNS ^NNS^POS     ^PRP      ^RB      ^RP      ^UH      ^VB     ^VBG     ^VBN 
       3        2        1        2        7        8       14        2        1       12        1        1        5        2        1 
    ^VBZ      BES       CC       CD       DT       EX       FW       GW      HVS       IN       JJ      JJR      JJS       MD       NN 
       2     1058     2747      563     4658      180        9       34       48     4902     2805      171       83      766     5999 
     NNP     NNPS      NNS      PDT      POS      PRP     PRP$       RB      RBR      RBS       RP      SYM       TO       UH    UH|IN 
     655       43     3529       86       56     7696      652     5253       92       18      241       16     1041     3982        1 
      VB      VBD      VBG      VBN      VBP      VBZ      WDT       WP      WP$      WRB       XX 
    2590     1975     1936     1082     4013     1239      412      355        1      428       85 

# Cross-linguistic part-of-speech tags
table(english.corpus.pos.data.frame$ntvr_ps_root)

     - -AFFIX AFFIX-  FLDPS      N  OTHER    PRO      V 
   212   4591    411    227   7779  27635   7937  12772 

# Cross-linguistic part-of-speech tags for whole words
table(english.corpus.pos.data.frame$ntvr_ps_word_old)

  AUX FLDPS     N OTHER   PRO     V 
 1874  1292  9299 26790  9464 12845 

# Cross-linguistic part-of-speech tags distinguishing between auxiliaries and content verbs
table(english.corpus.pos.data.frame$ntvr_ps_root_old)

AUX-BPN   FLDPS       N   OTHER     PRO       V   V-BPN 
   1874    1292    9299   26790    9464    5616    7229 

# Add an empty translation column
english.corpus.pos.data.frame$translation = ""


## Even

preparecorpus.bat Korpora\Even 2016-01-06 id eve

# List of files - 73 files
3_women_3_songs_07Aug.txt
ARD_chuchuna_family_07Aug.txt
ARD_intro_stado_07Aug.txt
ARD_lost_tapes_znatoki_07Aug.txt
ARD_old_remains_traditions_07Aug.txt
ARD_shatun_07Aug.txt
ARD_stado_then_now_07Aug.txt
ARD_stuck_in_stado_07Aug.txt
BID_traditions_07Aug.txt
KAA_headmistress_07Aug.txt
KTV_family_07Aug.txt
KTV_pear_story_07Aug.txt
KXA_various_07Aug.txt
KKK_dve_skazki_07Aug.txt
KKK_emcheni_07Aug.txt
KKK_history_07Aug.txt
KAE_childhood_07Aug.txt
KAX_1930s_07Aug.txt
KAX_Seb_history1_07Aug.txt
KAX_svatovstvo_07Aug.txt
KI_memories_07Aug.txt
KM_bear_07Aug.txt
KMK_nastavlenie_materi_07Aug.txt
KS_life_07Aug.txt
KIN_pearstory_07Aug.txt
KM_school_07Aug.txt
KSP_oxota_07Aug.txt
NPD_bearhunt_07Aug.txt
NPD_Eveno_Bytantaj_07Aug.txt
NPD_hebdjenek_07Aug.txt
NPD_migratory_cycle_07Aug.txt
NPD_nimat_07Aug.txt
NPD_nimkan_07Aug.txt
NPD_sled_07Aug.txt
NM_pearstory_07Aug.txt
RDA_TPK_birth_with_even_07Aug.txt
RDA_TPK_death_07Aug.txt
RDA_TPK_delburge_07Aug.txt
RDA_TPK_hongachan_baldarakan_07Aug.txt
RDA_TPK_names_origins_07Aug.txt
RDA_TPK_spirits_07Aug.txt
stado#10_AN_07Aug.txt
stado#10_NAE_traditions_07Aug.txt
stado#10_NM_life_stado_07Aug.txt
stado#10_NSE_poems_07Aug.txt
stado#10_NSE_traditions_07Aug.txt
stado#9_introductions_07Aug.txt
stado#9_kochevka_07Aug.txt
stado#9_learning_olenevod_07Aug.txt
stado#9_wild_animals_07Aug.txt
SNA_kochevaja_shkola_07Aug.txt
SZA_1_svatovstvo_07Aug.txt
SZA_2_sibling_07Aug.txt
SZA_3_hunting_stado_07Aug.txt
SZA_4_parents_07Aug.txt
SZA_arrival_Tashkent_07Aug.txt
SZA_bochilikan_etiken_07Aug.txt
SZA_jubki_Aniwrin_07Aug.txt
SZA_naled_07Aug.txt
SZA_song_Lamutskogo_07Aug.txt
SZA_song_ujamkan_07Aug.txt
SAA_den'_olenovoda_07Aug.txt
SAA_elk_07Aug.txt
SAA_his_life_07Aug.txt
SO_eveny_tompo_07Aug.txt
SO_pro_babushku_07Aug.txt
SO_stado_07Aug.txt
TLA_family_history_07Aug.txt
ZJP_pear_story_07Aug.txt
ZZ_pear_story_07Aug.txt
ZAV_indjuk_internat_07Aug.txt
ZAV_song_07Aug.txt
ZVN_poselok_07Aug.txt

# Toolbox markers
ELANBegin
ELANEnd
ELANMediaExtracted
ELANMediaMIME
ELANMediaURL
ELANParticipant
WordBegin
WordEnd
ev
fldps
ft
ge
gr
id
le
mb
mt
nt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_orig
ntvr_ps_root
ntvr_ref
ph
ps
qu
ref
root
ru
tx

# Count tokens using Python
counttokens.bat Korpora\Even 2016-01-06 id tx WordBegin WordEnd fldps le root ntvr_ps_word mb ge ntvr_ps_orig ntvr_ps_root mt
6117 tokens found in tier id
41700 tokens found in tier tx
41700 tokens found in tier WordBegin
41700 tokens found in tier WordEnd
41700 tokens found in tier fldps
41700 tokens found in tier le
41700 tokens found in tier root
0 tokens found in tier ntvr_ps_word
76814 tokens found in tier mb
76814 tokens found in tier ge
76814 tokens found in tier ntvr_ps_orig
76814 tokens found in tier ntvr_ps_root
76814 tokens found in tier mt

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
even.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "id", "ELANBegin", "ELANEnd", "ref", "ELANParticipant", "ft", "ru", "ev", "nt", "gr", "ph", "ps", "qu", "lg"),
"word" = c("tx", "WordBegin", "WordEnd", "ntvr_ps_word", "fldps", "le", "root"),
"morpheme" = c("mb", "ge", "ntvr_ps_orig", "ntvr_ps_root", "mt")
)

even.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Even/UniqueRecordMarker/2016-01-06/", full.names=T), even.fmt)

length.corpus(even.corpus.pos.positiontracking, "record")
[1] 5782

length.corpus(even.corpus.pos.positiontracking, "word")
[1] 41700

length.corpus(even.corpus.pos.positiontracking, "morpheme")
[1] 76814

# Problems detected in the corpus
even.parselog.pos.positiontracking = parse.log(even.corpus.pos.positiontracking)
write.parselog(even.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Even/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
even.corpus.pos.data.frame = as.data.frame(even.corpus.pos.positiontracking)

# Set correct encoding
even.corpus.pos.data.frame = set.encoding(even.corpus.pos.data.frame)

# Combine morphemes into words
even.corpus.pos.data.frame = combine.morphemes.into.words(even.corpus.pos.data.frame, c("mb","ge","ntvr_ps_orig","ntvr_ps_root","mt"))

# Original part-of-speech annotation
table(even.corpus.pos.data.frame$ntvr_ps_orig)

                     -                   -adj                  -advb                  -case           -case_marker                   -cvb                   -der                -epenth 
                     9                    348                    161                   6583                     18                   3020                   5867                   1566 
                  -nmb    -nominal_derivation                    -nr    -numeral_derivation            -participle                   -ptc                   -ptl              -subj.agr 
                  1742                      7                    294                     59                     34                    697                     47                   8583 
             -subj_agr -subordinate_predicate                  -suff                   -TAM          -TAM_subj_agr               -UNKNOWN     -verbal_derivation                    -vr 
                   113                      3                      3                   5506                     32                     19                      5                    177 
                   ***                   =der                   =ptl                    adj                  adj|n                    adv                adv|adj                adv|ptl 
                  2989                    126                   1048                   1167                      3                   2626                    900                     75 
             AMBIGUOUS                    aux                   conj                    cvb                    dem                    der                   excl            false_start 
                     1                    666                    542                     20                   3300                      4                      1                     59 
             ideophone                 interj          interrogative     interrogative|conj                      n                   name                    num                  OTHER 
                    30                    578                   1683                     27                   8784                    909                   1173                    344 
            participle              poss_pron                postpos            predicative           predicative?                   prep                   pron               pron_dem 
                     1                      2                    104                      1                      2                     92                   1669                     15 
             pron_pers                    ptc                    ptl                  quant                   refl                  rel.n                    TAM                UNKNOWN 
                     3                      3                   1635                    530                    115                    420                      1                     38 
                    vb                   vb|n 
                 10232                      3 

# Cross-linguistic part-of-speech tags
table(even.corpus.pos.data.frame$ntvr_ps_root)

        -    -AFFIX      -BPN      -BPP    =AFFIX AMBIGUOUS       AUX         N     OTHER       PRO   UNKNOWN         V 
        9     26156      6364      2364      1174         7       667      9693     18306      1804        38     10232 


## Hoocak

preparecorpus.bat Korpora\Hoocak 2016-01-06 ref win

# List of files - 63 files
16pics2_MK.txt
16pic_3CG.txt
16pic_3EG.txt
16pic_3WF.txt
alvin_cloud.txt
birthday2_prayer.txt
blueberries.txt
BO_bear_movies.txt
BO_funny.txt
BO_funny2.txt
caa_worak.txt
Cecil_funny.txt
ceexji_chloris.txt
CGEG_burgers.txt
CGEG_owl1.txt
CG_burger_solo.txt
CG_owl_solo.txt
CHT_discussion.txt
deerhunt.txt
dogCGEG.txt
dogEGCG.txt
ED_01.txt
ED_02.txt
ED_03.txt
ED_04.txt
ED_05.txt
ED_06.txt
ED_07.txt
ED_08.txt
ED_09.txt
ED_10.txt
emma.txt
feather.txt
frog2oral.txt
FrogiinekiEG.txt
FrogiinekiWF.txt
ghost.txt
gilbert.txt
giving_directions.txt
grizzly_bear.txt
hills.txt
horses.txt
JSmoke.txt
maple_syrup.txt
Matthew_24_1.txt
Matthew_24_2.txt
moccasin_game.txt
names.txt
napak.txt
newspaper.txt
New_Birth.txt
OneFrogTooMany.txt
preston.txt
RabbitandTurtle.txt
Richard.txt
Rich_Man_and_Lazarus1.txt
Rich_Man_and_Lazarus2.txt
Saved_By_Grace.txt
twins.txt
watermelon.txt
When_the_Roll_is_Called_Up_Yonder.txt
willard_speech.txt
womentrack2.txt

# Toolbox markers
ELANBegin
ELANEnd
ELANMediaExtracted
ELANMediaMIME
ELANMediaURL
ELANParticipant
WordBegin
WordEnd
cm
comments_DA
dt
ed
fldps
ft
gl
gl-old
jl
le
mo
mo-old
mt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root
ntvr_ref
or
ot
pr
ps
ref
root
sep_gl
sep_mo
sep_ps
so
ts
tx

# Count tokens using Python
counttokens.bat Korpora\Hoocak 2016-01-06 ref tx mo gl ps WordBegin WordEnd ntvr_ps_word fldps le root sep_mo sep_gl sep_ps ntvr_ps_root mt
3692 tokens found in tier ref
23419 tokens found in tier tx
23419 tokens found in tier mo
23419 tokens found in tier gl
23419 tokens found in tier ps
23419 tokens found in tier WordBegin
23419 tokens found in tier WordEnd
0 tokens found in tier ntvr_ps_word
23419 tokens found in tier fldps
23419 tokens found in tier le
23419 tokens found in tier root
41386 tokens found in tier sep_mo
41386 tokens found in tier sep_gl
41386 tokens found in tier sep_ps
41386 tokens found in tier ntvr_ps_root
41386 tokens found in tier mt

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
hoocak.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "ELANParticipant", "cm", "comments_DA", "dt", "ed", "ft", "gl-old", "jl", "mo-old", "or", "ot", "pr", "so", "ts"),
"word" = c("tx","mo", "gl", "ps", "WordBegin", "WordEnd", "ntvr_ps_word", "fldps", "le", "root"),
"morpheme" = c("sep_mo", "sep_gl", "sep_ps", "ntvr_ps_root", "mt")
)

hoocak.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Hoocak/UniqueRecordMarker/2016-01-06/", full.names=T), hoocak.fmt)

length.corpus(hoocak.corpus.pos.positiontracking, "record")
[1] 2988

length.corpus(hoocak.corpus.pos.positiontracking, "word")
[1] 23419

length.corpus(hoocak.corpus.pos.positiontracking, "morpheme")
[1] 41386

# Problems detected in the corpus
hoocak.parselog.pos.positiontracking = parse.log(hoocak.corpus.pos.positiontracking)
write.parselog(hoocak.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Hoocak/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
hoocak.corpus.pos.data.frame = as.data.frame(hoocak.corpus.pos.positiontracking)

# Set correct encoding
hoocak.corpus.pos.data.frame = set.encoding(hoocak.corpus.pos.data.frame)

# Combine morphemes into words
hoocak.corpus.pos.data.frame  = combine.morphemes.into.words(hoocak.corpus.pos.data.frame, c("ntvr_ps_root","mt"))

# Original part-of-speech annotation
table(hoocak.corpus.pos.data.frame$sep_ps)

                     -                  -adv.                 -affix                -affix-                  -num.             -pron_dem.                     -X                    -X- 
                  1491                     86                   6043                     49                    210                     10                      1                    167 
                   ***                      =                 =affix              =art_def.                  =aux.              =enclitic             =pron_dem.                 =ptcl. 
                     2                    103                    319                   1992                    842                    646                    412                    142 
                   adv                   adv.           adv./pron._?             adv./ptcl.                 affirm                 AFFIRM                  affix                 affix- 
                     5                   5601                      4                   1331                     30                      1                     17                   3828 
affix+adv.|ptcl.|affix               art_def.                   aux.             aux.|v.tr.                  chant                  conj. discontinuous_morpheme               enclitic 
                    34                      5                    383                    777                     39                   1766                    404                     32 
               ENGLISH                  hesit                interj.                     n.              n.|v.act.            n.|v.inact.               n.|v.tr.                   num. 
                   461                    578                    257                   3632                     12                      5                      8                    461 
                 OTHER                  pron.              pron_dem.        pron_dem.|pron.              pron_int.             pron_pers.                prop_n.                  ptcl. 
                    45                    537                    475                    429                      6                    231                    118                     84 
                quant.                    rdp                   slip               UNKNOWN-                     v.                 v.act.        v.act./v.inact.                v.ditr. 
                     1                     39                    116                      1                     11                   2126                      2                     36 
              v.inact.          v.inact./adv.      v.inact._/_v.act.         v.inact.|v.tr.                v.intr.                  v.tr.                     X- 
                  1148                     27                      2                      1                     37                   3727                      1 

# Cross-linguistic part-of-speech tags
table(hoocak.corpus.pos.data.frame$ntvr_ps_root)

       -   -AFFIX  -AFFIX-     -BPN   -OTHER  -OTHER-     -PRO        =   =AFFIX     =AUX   =OTHER     =PRO    AFFIX   AFFIX-      AUX      BPN     BPN-     BPP-        N    OTHER 
    1491     4782       49     1261      297      167       10      103      319      842     2780      412        7      705     1160       10     2966      157     3750    11294 
  OTHER-      PRO  UNKNOWN UNKNOWN-        V 
       1     1678        2        1     7142 


## Nǁng (called nuu in the code)

# Prepare corpus for importing
preparecorpus.bat Korpora\Nuu 2016-01-06 ref ngh

# List of files - 33 files
NB041016-01_A.txt
NB041016-04_A.txt
NB041016-05_A.txt
NB041016-08_A.txt
NB081007-01_A.txt
NB081007-02_A.txt
NC060710-02aA.txt
NC060710-02bA.txt
NC060710-02cA.txt
NC060710-02dA.txt
NC060715-01bA.txt
NC071107-01_A.txt
NC080903-01_A.txt
NC090930-01_A.txt
ND060719-01aA.txt
NE060715-02aA.txt
NE080825-01_A.txt
NE091006-01_A.txt
NF071017-02_A.txt
NF080903-01_A.txt
NF091001-01_A.txt
NG060718-02aA.txt
NG060718-02cA.txt
NG071114-01_A.txt
NG071119-01_A_till_087.txt
NG091103-01_A.txt
NM071022-01aA.txt
NM071109-01_A_till_270.txt
NM071213-01_A.txt
NM071214-01bA.txt
NM071214-01cA.txt
NM080903-01bE.txt
NM081007-02aA.txt

# Toolbox markers
ELANBegin
ELANEnd
ELANMediaMIME
ELANMediaURL
ELANParticipant
PAUSE
WordBegin
WordEnd
cfn
dt
et
fldps
fta
fte
ge
le
lxid
mb
mt
na
ng
np
nq
nt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root
ntvr_ref
orig
ps
ref
root
so
tx

# Count tokens using Python
counttokens.bat Korpora\Nuu 2016-01-06 ref tx WordBegin WordEnd fldps le root mb ge ps so lxid ntvr_ps_root mt
9732 tokens found in tier ref
31760 tokens found in tier tx
31760 tokens found in tier WordBegin
31760 tokens found in tier WordEnd
31760 tokens found in tier fldps
31760 tokens found in tier le
31760 tokens found in tier root
35797 tokens found in tier mb
35797 tokens found in tier ge
35797 tokens found in tier ps
35797 tokens found in tier so
35797 tokens found in tier lxid
35797 tokens found in tier ntvr_ps_root
35797 tokens found in tier mt

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
nuu.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "PAUSE", "ELANParticipant", "dt", "orig", "fta", "fte", "nt", "na", "ng", "np", "nq", "cfn", "et"),
"word" = c("tx", "WordBegin", "WordEnd", "ntvr_ps_word", "fldps", "le", "root"),
"morpheme" = c("mb", "ge", "ps", "so", "lxid", "ntvr_ps_root", "mt")
)

nuu.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Nuu/UniqueRecordMarker/2016-01-06/", full.names=T), nuu.fmt)

length.corpus(nuu.corpus.pos.positiontracking, "record")
[1] 9732

length.corpus(nuu.corpus.pos.positiontracking, "word")
[1] 31760

length.corpus(nuu.corpus.pos.positiontracking, "morpheme")
[1] 35797

# Problems detected in the corpus
nuu.parselog.pos.positiontracking = parse.log(nuu.corpus.pos.positiontracking)
write.parselog(nuu.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Nuu/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
nuu.corpus.pos.data.frame = as.data.frame(nuu.corpus.pos.positiontracking)

# Set correct encoding
nuu.corpus.pos.data.frame = set.encoding(nuu.corpus.pos.data.frame)

# Combine morphemes into words
nuu.corpus.pos.data.frame = combine.morphemes.into.words(nuu.corpus.pos.data.frame, c("mb","ge","ps","so","lxid","ntvr_ps_root","mt"))

# Original part-of-speech annotation
table(nuu.corpus.pos.data.frame$ps)

     - -adjsf   -nsf -prosf    -sf   -vsf    ***      ?    adj    adp    adv    art   conj    dei    ide interj      n   npf-   part    pro  quant   vatr   vitr  vpart   vpf-    vtr 
   114     46   2136     10     25   1219   1047    136    468     60   1466    234    252    600     15    856   5591    150   5149   7187     86   1851   3048     52    231   3768 

# Cross-linguistic part-of-speech tags
table(nuu.corpus.pos.data.frame$ntvr_ps_root)

     - -AFFIX AFFIX-      N  OTHER    PRO      V 
   114   3436    381   5500  10512   7187   8667 


## Texistepec Popoluca (called popoluca in the code)

# Prepare corpus for importing
preparecorpus.bat Korpora\Popoluca 2016-01-06 rf poq

# List of files - 9 files
Blancaflor.txt
JesusQuevedo.txt            # no audio, hence no word times
JuanFlojo.txt
JuanRatoncito.txt
LaChichimeca.txt
LaMujerFloja.txt
LosGatos.txt                # no audio, hence no word times
NicolasitoyNicolason.txt    # no audio, hence no word times
Pepito.txt

# Toolbox Markers
ELANBegin
ELANEnd
ELANMediaMIME
ELANMediaURL
ELANParticipant
WordBegin
WordEnd
fldps
ge
le
mr
mt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root
ntvr_ref
ps
rf
root
sy
tr
tx

# Count tokens using Python
counttokens.bat Korpora\Popoluca 2016-01-06 rf tx WordBegin WordEnd ntvr_ps_word fldps le root mr ge ps ntvr_ps_root mt
18993 tokens found in tier rf
24811 tokens found in tier tx
21604 tokens found in tier WordBegin
21604 tokens found in tier WordEnd
0 tokens found in tier ntvr_ps_word
24811 tokens found in tier fldps
24811 tokens found in tier le
24811 tokens found in tier root
46629 tokens found in tier mr
46629 tokens found in tier ge
46629 tokens found in tier ps
46629 tokens found in tier ntvr_ps_root
46629 tokens found in tier mt

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
popoluca.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "rf", "ELANBegin", "ELANEnd", "ELANParticipant", "tr", "sy"),
"word" = c("tx", "WordBegin", "WordEnd", "ntvr_ps_word", "fldps", "le", "root"),
"morpheme" = c("mr", "ge", "ps", "ntvr_ps_root", "mt")
)

popoluca.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Popoluca/UniqueRecordMarker/2016-01-06/", full.names=T), popoluca.fmt)

length.corpus(popoluca.corpus.pos.positiontracking, "record")
[1] 6480

length.corpus(popoluca.corpus.pos.positiontracking, "word")
[1] 24811

length.corpus(popoluca.corpus.pos.positiontracking, "morpheme")
[1] 46629

# Problems detected in the corpus
popoluca.parselog.pos.positiontracking = parse.log(popoluca.corpus.pos.positiontracking)
write.parselog(popoluca.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Popoluca/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
popoluca.corpus.pos.data.frame = as.data.frame(popoluca.corpus.pos.positiontracking)

# Set correct encoding
popoluca.corpus.pos.data.frame = set.encoding(popoluca.corpus.pos.data.frame)

# Combine morphemes into words
popoluca.corpus.pos.data.frame = combine.morphemes.into.words(popoluca.corpus.pos.data.frame, c("mr","ge","ps","ntvr_ps_root","mt"))

# Original part-of-speech annotation
table(popoluca.corpus.pos.data.frame$ps)

                   -               -affix         -affix/enclt                 -der             -der_adj             -der_num            -der_pron               -der_s 
                1358                 3884                   32                   65                  989                    1                   69                  195 
              -der_v              -der_vi        -der_vt/der_v               -enclt                -infl                  ***                  adj                  adv 
                 158                   67                  659                  723                  867                   61                  946                 2063 
             adv/adj           adv/interr           adv/partcl               affix-                  aux                 conj               der_v-                infl- 
                   1                   10                  162                11375                 2503                  532                   21                    3 
              interj               interr              nom_pro                  num               partcl        partcl$interr        partcl/interj        partcl_interr 
                 542                  225                  148                  397                 2214                   10                    7                   58 
                pron             pron$adj          pron_interr pron_interr/pron_rel                    s                s$adj           s$interj$v                s_pos 
                1983                   39                  125                   56                 3071                   36                    5                  521 
             unknown                    v                 v/vt         v_imperativo                   vi              vi/vi_a                vi/vt                 vi_a 
                   1                  440                    4                   40                 5907                    7                  208                    5 
         vi_ap/vt/vi                 vi_e           vi_e$s_pos              vi_e/vt              vi_e_pl                   vt                vt/vi              vt/vi_a 
                  15                  145                    3                   12                    1                 2569                  382                  209 
             vt/vi_p               vt_apl                 vt_c            vt_c/vi_p 
                 486                    4                    7                    3 

# Cross-linguistic part-of-speech tags
table(popoluca.corpus.pos.data.frame$ntvr_ps_root)

        -    -AFFIX      -BPN    AFFIX- AMBIGUOUS       AUX      BPN-      BPP-         N     OTHER       PRO   UNKNOWN         V 
     1358      6708      1001      3414        83      2503      6953      1032      3740      9690      2164         1      7982 

# Name the one and only speaker "SP1"
popoluca.corpus.pos.data.frame$ELANParticipant = "SP1"


## Sakha

# Prepare corpus for importing
preparecorpus.bat Korpora\Sakha 2016-01-06 ref sah

# List of files - 16 files
K_09Aug.txt
BR_AR_09Aug.txt
BP_09Aug.txt
MA_09Aug.txt
M1_09Aug.txt
M2_09Aug.txt
P90_09Aug.txt
P95_09Aug.txt
TC_09Aug.txt
TE_09Aug.txt
TP_09Aug.txt
XI_09Aug.txt
XY_09Aug.txt
XRE_09Aug.txt
ZA2_09Aug.txt
ZL_09Aug.txt

# Toolbox markers
ELANBegin
ELANEnd
ELANMediaMIME
ELANMediaURL
ELANParticipant
WordBegin
WordEnd
ch
f
fldps
g
gr
le
m
mt
ntvr_file
ntvr_language
ntvr_number
ntvr_ps_root
ntvr_ref
ph
ps
ref
rem
root
t
tr

# Count tokens using Python
counttokens.bat Korpora\Sakha 2016-01-06 ref t WordBegin WordEnd ntvr_ps_word fldps le root m g ps ntvr_ps_root mt
7542 tokens found in tier ref
31783 tokens found in tier t
31783 tokens found in tier WordBegin
31783 tokens found in tier WordEnd
0 tokens found in tier ntvr_ps_word
31783 tokens found in tier fldps
31783 tokens found in tier le
31783 tokens found in tier root
53029 tokens found in tier m
53029 tokens found in tier g
53029 tokens found in tier ps
53029 tokens found in tier ntvr_ps_root
53029 tokens found in tier mt

# Import corpus into R using Taras Zakharko's R library ToolboxSearch
sakha.fmt = toolboxFormat (
"record" = c("ntvr_ref", "ntvr_language", "ntvr_file", "ntvr_number", "ref", "ELANBegin", "ELANEnd", "ELANParticipant", "f", "tr", "ch", "gr", "ph", "rem"),
"word" = c("t", "ntvr_ps_word", "WordBegin", "WordEnd", "fldps", "le", "root"),
"morpheme" = c("m", "g", "ps", "ntvr_ps_root", "mt")
)

sakha.corpus.pos.positiontracking = readToolbox(dir("F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Sakha/UniqueRecordMarker/2016-01-06/", full.names=T), sakha.fmt)

length.corpus(sakha.corpus.pos.positiontracking, "record")
[1] 4229

length.corpus(sakha.corpus.pos.positiontracking, "word")
[1] 31783

length.corpus(sakha.corpus.pos.positiontracking, "morpheme")
[1] 53029

# Problems detected in the corpus
sakha.parselog.pos.positiontracking = parse.log(sakha.corpus.pos.positiontracking)
write.parselog(sakha.parselog.pos.positiontracking,"F:/Arbeit/MPILeipzig/Projektdaten/Korpora/Sakha/Logs/2016-01-06/parse.positiontracking.log")

# Convert corpus object to data.frame
sakha.corpus.pos.data.frame = as.data.frame(sakha.corpus.pos.positiontracking)

# Set correct encoding
sakha.corpus.pos.data.frame = set.encoding(sakha.corpus.pos.data.frame)

# Combine morphemes into words
sakha.corpus.pos.data.frame = combine.morphemes.into.words(sakha.corpus.pos.data.frame, c("m","g","ps","ntvr_ps_root","mt"))

# Original part-of-speech annotation
table(sakha.corpus.pos.data.frame$ps)

                     -          -adjectivizer         -adverbializer           -case_marker                  -conv              -emphatic              -negation    -nominal_derivation 
                     8                    166                    197                   4085                   3564                      6                     28                     19 
          -nominalizer                   -num    -numeral_derivation            -participle           -proprietive                   -ptl       -question_marker              -subj_agr 
                   281                    775                    177                   2841                    694                      1                     90                   4635 
-subordinate_predicate                   -TAM          -TAM_subj_agr     -verbal_derivation            -verbalizer                    ***              =question                    adj 
                    21                   1138                    667                    930                    876                    959                      1                   1039 
              adj_comp                    adv                   adv?                adv_man               adv_time                adv|adj               adv|conj                  adv|n 
                     5                   1942                     28                     11                    252                     71                     17                     15 
               adv|ptl                   conj       conj_disjunctive                    cvb                    dem              emphatic-            false_start                 interj 
                   128                    545                     97                      3                     11                    109                    115                    530 
         interrogative                      n          n_existential                   name          negation_noun                    num                  OTHER                   part 
                   554                   8263                    196                    904                    248                   1441                    439                      8 
               postpos                   prep                   pron               pron_dem     pron_dem_(distant)              pron_pers              pron_poss              pron_refl 
                   408                     21                     53                   1121                   1310                    605                      7                    152 
                   ptl             quantifier                 rel._n                     vb                 vb_aux 
                  2482                      5                    127                   7049                    559 

# Cross-linguistic part-of-speech annotation (-subj_agr should also be -AFFIX)
table(sakha.corpus.pos.data.frame$ntvr_ps_root)

        -    -AFFIX      -BPN      -BPP -subj_agr    =AFFIX    AFFIX- AMBIGUOUS       AUX         N     OTHER       PRO         V 
        8     15551      4029      1448       163         1       109        15       559      9167     11860      2626      7493 



### Add information about word order
baure.corpus.pos.data.frame$word_order = "VO"
bora.corpus.pos.data.frame$word_order = "OV"
chintang.corpus.pos.data.frame$word_order = "OV"
dutch.corpus.pos.data.frame$word_order = "OV/VO"
english.corpus.pos.data.frame$word_order = "VO"
even.corpus.pos.data.frame$word_order = "OV"
hoocak.corpus.pos.data.frame$word_order = "OV"
nuu.corpus.pos.data.frame$word_order = "VO"
popoluca.corpus.pos.data.frame$word_order = "VO"
sakha.corpus.pos.data.frame$word_order = "OV"

baure.corpus.pos.data.frame$word_order = factor(baure.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
bora.corpus.pos.data.frame$word_order = factor(bora.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
chintang.corpus.pos.data.frame$word_order = factor(chintang.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
dutch.corpus.pos.data.frame$word_order = factor(dutch.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
english.corpus.pos.data.frame$word_order = factor(english.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
even.corpus.pos.data.frame$word_order = factor(even.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
hoocak.corpus.pos.data.frame$word_order = factor(hoocak.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
nuu.corpus.pos.data.frame$word_order = factor(nuu.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
popoluca.corpus.pos.data.frame$word_order = factor(popoluca.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))
sakha.corpus.pos.data.frame$word_order = factor(sakha.corpus.pos.data.frame$word_order,levels=c("VO","OV","OV/VO"))

### Add information about person marking
baure.corpus.pos.data.frame$agreement = "SUBJ+OBJ"
bora.corpus.pos.data.frame$agreement = "SUBJ"
chintang.corpus.pos.data.frame$agreement = "SUBJ+OBJ"
dutch.corpus.pos.data.frame$agreement = "SUBJ"
english.corpus.pos.data.frame$agreement = "SUBJ"
even.corpus.pos.data.frame$agreement = "SUBJ"
hoocak.corpus.pos.data.frame$agreement = "SUBJ+OBJ"
nuu.corpus.pos.data.frame$agreement = "none"
popoluca.corpus.pos.data.frame$agreement = "SUBJ+OBJ"
sakha.corpus.pos.data.frame$agreement = "SUBJ"

baure.corpus.pos.data.frame$agreement = factor(baure.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
bora.corpus.pos.data.frame$agreement = factor(bora.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
chintang.corpus.pos.data.frame$agreement = factor(chintang.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
dutch.corpus.pos.data.frame$agreement = factor(dutch.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
english.corpus.pos.data.frame$agreement = factor(english.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
even.corpus.pos.data.frame$agreement = factor(even.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
hoocak.corpus.pos.data.frame$agreement = factor(hoocak.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
nuu.corpus.pos.data.frame$agreement = factor(nuu.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
popoluca.corpus.pos.data.frame$agreement = factor(popoluca.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))
sakha.corpus.pos.data.frame$agreement = factor(sakha.corpus.pos.data.frame$agreement,levels=c("none","SUBJ","SUBJ+OBJ"))

### Add information about case marking
baure.corpus.pos.data.frame$case_based = "-CS"
bora.corpus.pos.data.frame$case_based = "+CS"
chintang.corpus.pos.data.frame$case_based = "-CS"
dutch.corpus.pos.data.frame$case_based = "+CS"
english.corpus.pos.data.frame$case_based = "+CS"
even.corpus.pos.data.frame$case_based = "+CS"
hoocak.corpus.pos.data.frame$case_based = "-CS"
nuu.corpus.pos.data.frame$case_based = "-CS"
popoluca.corpus.pos.data.frame$case_based = "?"
sakha.corpus.pos.data.frame$case_based = "+CS"

baure.corpus.pos.data.frame$case_based = factor(baure.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
bora.corpus.pos.data.frame$case_based = factor(bora.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
chintang.corpus.pos.data.frame$case_based = factor(chintang.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
dutch.corpus.pos.data.frame$case_based = factor(dutch.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
english.corpus.pos.data.frame$case_based = factor(english.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
even.corpus.pos.data.frame$case_based = factor(even.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
hoocak.corpus.pos.data.frame$case_based = factor(hoocak.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
nuu.corpus.pos.data.frame$case_based = factor(nuu.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
popoluca.corpus.pos.data.frame$case_based = factor(popoluca.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))
sakha.corpus.pos.data.frame$case_based = factor(sakha.corpus.pos.data.frame$case_based,levels=c("-CS","+CS","?"))


### Map column names to common names

# Use: words, morph, gloss, language, id, ps, translation

# Baure
colnames(baure.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "ref"                     "ELANBegin"               "ELANEnd"                 "ELANParticipant"         "nt"                      "ft"                      "ftE"                    
[15] "tx2"                     "tx"                      "WordBegin"               "WordEnd"                 "ntvr_ps_word"            "fldps"                   "le"                     
[22] "root"                    "mb"                      "ge"                      "ps"                      "lg"                      "ntvr_ps_root"            "mt"                     
[29] "whole_word_mb"           "whole_word_ge"           "whole_word_ps"           "whole_word_lg"           "whole_word_ntvr_ps_root" "whole_word_mt"           "word_order"             
[36] "agreement"               "case_based"             

colnames(baure.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ELANParticipant","nt","ft","translation","tx2","word","WordBegin","WordEnd","ntvr_ps_word","fldps","le","root",
"morph","gloss","ps","lg","ntvr_ps_root","mt","whole_word_morph","whole_word_gloss","whole_word_ps","whole_word_lg","whole_word_ntvr_ps_root","whole_word_mt",
"word_order","agreement","case_based")

# Bora
colnames(bora.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "ref"                     "ELANBegin"               "ELANEnd"                 "ELANParticipant"         "com"                     "com_RB"                  "com_MO"                 
[15] "f"                       "fe"                      "t"                       "ntvr_ps_word"            "WordBegin"               "WordEnd"                 "fldps"                  
[22] "le"                      "root"                    "mb"                      "gl"                      "ps"                      "ntvr_ps_root"            "mt"                     
[29] "whole_word_mb"           "whole_word_gl"           "whole_word_ps"           "whole_word_ntvr_ps_root" "whole_word_mt"           "word_order"              "agreement"              
[36] "case_based"             

colnames(bora.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ELANParticipant","com","com_RB","com_MO","f","translation","word","ntvr_ps_word","WordBegin","WordEnd",
"fldps","le","root","morph","gloss","ps","ntvr_ps_root","mt","whole_word_morph","whole_word_gloss","whole_word_ps","whole_word_ntvr_ps_root",
"whole_word_mt","word_order","agreement","case_based")

# Chintang
colnames(chintang.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "ref"                     "ELANBegin"               "ELANEnd"                 "ELANParticipant"         "comment"                 "dt"                      "eng"                    
[15] "nep"                     "gw"                      "WordBegin"               "WordEnd"                 "ntvr_ps_word"            "fldps"                   "le"                     
[22] "root"                    "mph"                     "mgl"                     "ps"                      "lg"                      "id"                      "ntvr_ps_root"           
[29] "mt"                      "whole_word_mph"          "whole_word_mgl"          "whole_word_lg"           "whole_word_ps"           "whole_word_id"           "whole_word_ntvr_ps_root"
[36] "whole_word_mt"           "word_order"              "agreement"               "case_based"             

colnames(chintang.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ELANParticipant","comment","dt","translation","nep","word","WordBegin","WordEnd","ntvr_ps_word","fldps",
"le","root","morph","gloss","ps","lg","id","ntvr_ps_root","mt","whole_word_morph","whole_word_gloss","whole_word_lg","whole_word_ps","whole_word_id",
"whole_word_ntvr_ps_root","whole_word_mt","word_order","agreement","case_based")

# Dutch
colnames(dutch.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "ref"                     "ELANBegin"               "ELANEnd"                 "ELANParticipant"         "tx"                      "ph"                      "le"                     
[15] "WordBegin"               "WordEnd"                 "ntvr_ps_word"            "fldps"                   "mr"                      "mg"                      "ps"                     
[22] "sl"                      "rl"                      "ntvr_ps_root_old"        "mb"                      "ml"                      "mt"                      "ntvr_ps_root"           
[29] "whole_word_mb"           "whole_word_ml"           "whole_word_ntvr_ps_root" "whole_word_mt"           "translation"             "word_order"              "agreement"              
[36] "case_based"             

# TODO: "gloss" is not really correct, it now contains the basic morpheme forms
# TODO: "ps" is still per word instead of per morpheme
colnames(dutch.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ELANParticipant","word","phon","le","WordBegin","WordEnd","ntvr_ps_word","fldps",
"mr","mg","ps","le","root","ntvr_ps_root_old","morph","gloss","mt","ntvr_ps_root","whole_word_morph","whole_word_gloss","whole_word_ntvr_ps_root",
"whole_word_mt","translation","word_order","agreement","case_based")

dutch.corpus.pos.data.frame$whole_word_ps = dutch.corpus.pos.data.frame$ps
dutch.corpus.pos.data.frame$root = NA
dutch.corpus.pos.data.frame$mt = NA
dutch.corpus.pos.data.frame$whole_word_mt = NA


# TODO: Old version
colnames(dutch.corpus.pos.data.frame)
 [1] "record.id"        "word.id"          "morpheme.id"      "ntvr_ref"         "ntvr_language"    "ntvr_file"        "ntvr_number"      "ref"              "ELANBegin"       
[10] "ELANEnd"          "ELANParticipant"  "tx"               "ph"               "le"               "WordBegin"        "WordEnd"          "ntvr_ps_word"     "fldps"           
[19] "mr"               "mg"               "ps"               "ntvr_ps_root_old" "translation"      "word_order"       "agreement"        "case_based"      

colnames(dutch.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ELANParticipant","word","phon","lemma","WordBegin","WordEnd","ntvr_ps_word","fldps",
"morph","gloss","ps","ntvr_ps_root","translation","word_order","agreement","case_based")

dutch.corpus.pos.data.frame$whole_word_morph = dutch.corpus.pos.data.frame$morph
dutch.corpus.pos.data.frame$whole_word_gloss = dutch.corpus.pos.data.frame$gloss
dutch.corpus.pos.data.frame$whole_word_ps = dutch.corpus.pos.data.frame$ps
dutch.corpus.pos.data.frame$whole_word_ntvr_ps_root = dutch.corpus.pos.data.frame$ntvr_ps_root

# English
colnames(english.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"          
 [6] "ntvr_file"               "ntvr_number"             "ref"                     "ELANBegin"               "ELANEnd"                
[11] "ELANParticipant"         "topic"                   "sex"                     "year"                    "dialect"                
[16] "tx"                      "ph"                      "st"                      "WordBegin"               "WordEnd"                
[21] "PhonesBegin"             "PhonesEnd"               "ntvr_ps_word_old"        "fldps"                   "ps"                     
[26] "le"                      "root"                    "ntvr_ps_root_old"        "mb"                      "mg"                     
[31] "mp"                      "mt"                      "ntvr_ps_root"            "whole_word_mb"           "whole_word_mg"          
[36] "whole_word_mp"           "whole_word_ntvr_ps_root" "whole_word_mt"           "translation"             "word_order"             
[41] "agreement"               "case_based"             

colnames(english.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number","orig_ref","ELANBegin","ELANEnd","ELANParticipant","topic","sex","year","dialect","word","phon","stress","WordBegin","WordEnd", "PhonesBegin","PhonesEnd","ntvr_ps_word","fldps","ps_orig","le","root","ntvr_ps_root_old","morph","gloss","ps","mt","ntvr_ps_root","whole_word_morph","whole_word_gloss","whole_word_ps","whole_word_ntvr_ps_root","whole_word_mt","translation","word_order","agreement","case_based")

# Even
colnames(even.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "id"                      "ELANBegin"               "ELANEnd"                 "ref"                     "ELANParticipant"         "ft"                      "ru"                     
[15] "ev"                      "nt"                      "gr"                      "ph"                      "ps"                      "qu"                      "lg"                     
[22] "tx"                      "WordBegin"               "WordEnd"                 "ntvr_ps_word"            "fldps"                   "le"                      "root"                   
[29] "mb"                      "ge"                      "ntvr_ps_orig"            "ntvr_ps_root"            "mt"                      "whole_word_mb"           "whole_word_ge"          
[36] "whole_word_ntvr_ps_orig" "whole_word_ntvr_ps_root" "whole_word_mt"           "word_order"              "agreement"               "case_based"             

colnames(even.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ref","ELANParticipant","translation","ru","ev","nt","gr","ph","ps_old","qu","lg","word",
"WordBegin","WordEnd","ntvr_ps_word","fldps","le","root","morph","gloss","ps","ntvr_ps_root","mt","whole_word_morph","whole_word_gloss","whole_word_ps",
"whole_word_ntvr_ps_root","whole_word_mt","word_order","agreement","case_based")

# Hoocak
colnames(hoocak.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "ref"                     "ELANBegin"               "ELANEnd"                 "ELANParticipant"         "cm"                      "comments_DA"             "dt"                     
[15] "ed"                      "ft"                      "gl-old"                  "jl"                      "mo-old"                  "or"                      "ot"                     
[22] "pr"                      "so"                      "ts"                      "tx"                      "mo"                      "gl"                      "ps"                     
[29] "WordBegin"               "WordEnd"                 "ntvr_ps_word"            "fldps"                   "le"                      "root"                    "sep_mo"                 
[36] "sep_gl"                  "sep_ps"                  "ntvr_ps_root"            "mt"                      "whole_word_ntvr_ps_root" "whole_word_mt"           "word_order"             
[43] "agreement"               "case_based"             

colnames(hoocak.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ELANParticipant","cm","comments_DA","dt","ed","translation","gl-old","jl","mo-old","or",
"ot","pr","so","ts","word","whole_word_morph","whole_word_gloss","whole_word_ps","WordBegin","WordEnd","ntvr_ps_word","fldps","le","root",
"morph","gloss","ps","ntvr_ps_root","mt","whole_word_ntvr_ps_root","whole_word_mt","word_order","agreement","case_based")

# Nǁng
colnames(nuu.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "ref"                     "ELANBegin"               "ELANEnd"                 "PAUSE"                   "ELANParticipant"         "dt"                      "orig"                   
[15] "fta"                     "fte"                     "nt"                      "na"                      "ng"                      "np"                      "nq"                     
[22] "cfn"                     "et"                      "tx"                      "WordBegin"               "WordEnd"                 "ntvr_ps_word"            "fldps"                  
[29] "le"                      "root"                    "mb"                      "ge"                      "ps"                      "so"                      "lxid"                   
[36] "ntvr_ps_root"            "mt"                      "whole_word_mb"           "whole_word_ge"           "whole_word_ps"           "whole_word_so"           "whole_word_lxid"        
[43] "whole_word_ntvr_ps_root" "whole_word_mt"           "word_order"              "agreement"               "case_based"             

colnames(nuu.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","PAUSE","ELANParticipant","dt","orig","fta","translation","nt","na","ng","np","nq","cfn","et",
"word","WordBegin","WordEnd","ntvr_ps_word","fldps","le","root","morph","gloss","ps","lg","id","ntvr_ps_root","mt","whole_word_morph","whole_word_gloss",
"whole_word_ps","whole_word_lg","whole_word_id","whole_word_ntvr_ps_root","whole_word_mt","word_order","agreement","case_based")

# Texistepec Popoluca
colnames(popoluca.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "rf"                      "ELANBegin"               "ELANEnd"                 "ELANParticipant"         "tr"                      "sy"                      "tx"                     
[15] "WordBegin"               "WordEnd"                 "ntvr_ps_word"            "fldps"                   "le"                      "root"                    "mr"                     
[22] "ge"                      "ps"                      "ntvr_ps_root"            "mt"                      "whole_word_mr"           "whole_word_ge"           "whole_word_ps"          
[29] "whole_word_ntvr_ps_root" "whole_word_mt"           "word_order"              "agreement"               "case_based"             

colnames(popoluca.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ELANParticipant","translation","sy","word","WordBegin","WordEnd","ntvr_ps_word","fldps","le","root","morph","gloss",
"ps","ntvr_ps_root","mt","whole_word_morph","whole_word_gloss","whole_word_ps","whole_word_ntvr_ps_root","whole_word_mt","word_order","agreement","case_based")

# Sakha
colnames(sakha.corpus.pos.data.frame)
 [1] "record.id"               "word.id"                 "morpheme.id"             "ntvr_ref"                "ntvr_language"           "ntvr_file"               "ntvr_number"            
 [8] "ref"                     "ELANBegin"               "ELANEnd"                 "ELANParticipant"         "f"                       "tr"                      "ch"                     
[15] "gr"                      "ph"                      "rem"                     "t"                       "ntvr_ps_word"            "WordBegin"               "WordEnd"                
[22] "fldps"                   "le"                      "root"                    "m"                       "g"                       "ps"                      "ntvr_ps_root"           
[29] "mt"                      "whole_word_m"            "whole_word_g"            "whole_word_ps"           "whole_word_ntvr_ps_root" "whole_word_mt"           "word_order"             
[36] "agreement"               "case_based"             

colnames(sakha.corpus.pos.data.frame) = c("record.id","word.id","morpheme.id","ntvr_ref","ntvr_language","ntvr_file","ntvr_number",
"orig_ref","ELANBegin","ELANEnd","ELANParticipant","translation","tr","ch","gr","ph","rem","word","ntvr_ps_word","WordBegin","WordEnd","fldps",
"le","root","morph","gloss","ps","ntvr_ps_root","mt","whole_word_morph","whole_word_gloss","whole_word_ps","whole_word_ntvr_ps_root","whole_word_mt",
"word_order","agreement","case_based")


### Corpus statistics of whole corpus (before excluding anything)

# Number of sessions
length(unique(na.omit(baure.corpus.pos.data.frame$ntvr_file)))
[1] 61

length(unique(na.omit(bora.corpus.pos.data.frame$ntvr_file)))
[1] 37

length(unique(na.omit(chintang.corpus.pos.data.frame$ntvr_file)))
[1] 55

length(unique(na.omit(dutch.corpus.pos.data.frame$ntvr_file)))
[1] 17

length(unique(na.omit(english.corpus.pos.data.frame$ntvr_file)))
[1] 47

length(unique(na.omit(even.corpus.pos.data.frame$ntvr_file)))
[1] 73

length(unique(na.omit(hoocak.corpus.pos.data.frame$ntvr_file)))
[1] 63

length(unique(na.omit(nuu.corpus.pos.data.frame$ntvr_file)))
[1] 33

length(unique(na.omit(popoluca.corpus.pos.data.frame$ntvr_file)))
[1] 9

length(unique(na.omit(sakha.corpus.pos.data.frame$ntvr_file)))
[1] 16

# Number of speakers
# One less than before for Baure, Chintang and N|uu. Check!
length(unique(na.omit(baure.corpus.pos.data.frame$ELANParticipant)))
[1] 18

length(unique(na.omit(bora.corpus.pos.data.frame$ELANParticipant)))
[1] 47

length(unique(na.omit(chintang.corpus.pos.data.frame$ELANParticipant)))
[1] 83

length(unique(na.omit(dutch.corpus.pos.data.frame$ELANParticipant)))
[1] 42

length(unique(na.omit(english.corpus.pos.data.frame$ELANParticipant)))
[1] 80

length(unique(na.omit(even.corpus.pos.data.frame$ELANParticipant)))
[1] 44

length(unique(na.omit(hoocak.corpus.pos.data.frame$ELANParticipant)))
[1] 31

length(unique(na.omit(nuu.corpus.pos.data.frame$ELANParticipant)))
[1] 14

length(unique(na.omit(popoluca.corpus.pos.data.frame$ELANParticipant)))
[1] 1

length(unique(na.omit(sakha.corpus.pos.data.frame$ELANParticipant)))
[1] 27

# Number of records
length(unique(na.omit(baure.corpus.pos.data.frame$ntvr_ref)))
[1] 7967

length(unique(na.omit(bora.corpus.pos.data.frame$ntvr_ref)))
[1] 4062

length(unique(na.omit(chintang.corpus.pos.data.frame$ntvr_ref)))
[1] 12364

length(unique(na.omit(dutch.corpus.pos.data.frame$ntvr_ref)))
[1] 5822

length(unique(na.omit(english.corpus.pos.data.frame$ntvr_ref)))
[1] 6941

length(unique(na.omit(even.corpus.pos.data.frame$ntvr_ref)))
[1] 5782

length(unique(na.omit(hoocak.corpus.pos.data.frame$ntvr_ref)))
[1] 2988

length(unique(na.omit(nuu.corpus.pos.data.frame$ntvr_ref)))
[1] 9732

length(unique(na.omit(popoluca.corpus.pos.data.frame$ntvr_ref)))
[1] 6480

length(unique(na.omit(sakha.corpus.pos.data.frame$ntvr_ref)))
[1] 4229

# Number of words
length(unique(na.omit(baure.corpus.pos.data.frame$word.id)))
[1] 29771

length(unique(na.omit(bora.corpus.pos.data.frame$word.id)))
[1] 30140

length(unique(na.omit(chintang.corpus.pos.data.frame$word.id)))
[1] 47868

length(unique(na.omit(dutch.corpus.pos.data.frame$word.id)))
[1] 39720

length(unique(na.omit(english.corpus.pos.data.frame$word.id)))
[1] 56138

length(unique(na.omit(even.corpus.pos.data.frame$word.id)))
[1] 41700

length(unique(na.omit(hoocak.corpus.pos.data.frame$word.id)))
[1] 23419

length(unique(na.omit(nuu.corpus.pos.data.frame$word.id)))
[1] 31760

length(unique(na.omit(popoluca.corpus.pos.data.frame$word.id)))
[1] 24811

length(unique(na.omit(sakha.corpus.pos.data.frame$word.id)))
[1] 31783

# Number of morphemes
length(unique(na.omit(baure.corpus.pos.data.frame$morpheme.id)))
[1] 52707

length(unique(na.omit(bora.corpus.pos.data.frame$morpheme.id)))
[1] 66470

length(unique(na.omit(chintang.corpus.pos.data.frame$morpheme.id)))
[1] 82417

length(unique(na.omit(dutch.corpus.pos.data.frame$morpheme.id)))
[1] 39720

length(unique(na.omit(english.corpus.pos.data.frame$morpheme.id)))
[1] 61564

length(unique(na.omit(even.corpus.pos.data.frame$morpheme.id)))
[1] 76814

length(unique(na.omit(hoocak.corpus.pos.data.frame$morpheme.id)))
[1] 41386

length(unique(na.omit(nuu.corpus.pos.data.frame$morpheme.id)))
[1] 35797

length(unique(na.omit(popoluca.corpus.pos.data.frame$morpheme.id)))
[1] 46629

length(unique(na.omit(sakha.corpus.pos.data.frame$morpheme.id)))
[1] 53029

# Words per annotation unit
length(unique(na.omit(baure.corpus.pos.data.frame$word.id))) / length(unique(na.omit(baure.corpus.pos.data.frame$ntvr_ref)))
[1] 3.736789

length(unique(na.omit(bora.corpus.pos.data.frame$word.id))) / length(unique(na.omit(bora.corpus.pos.data.frame$ntvr_ref)))
[1] 7.41999

length(unique(na.omit(chintang.corpus.pos.data.frame$word.id))) / length(unique(na.omit(chintang.corpus.pos.data.frame$ntvr_ref)))
[1] 3.871563

length(unique(na.omit(dutch.corpus.pos.data.frame$word.id))) / length(unique(na.omit(dutch.corpus.pos.data.frame$ntvr_ref)))
[1] 6.822398

length(unique(na.omit(english.corpus.pos.data.frame$word.id))) / length(unique(na.omit(english.corpus.pos.data.frame$ntvr_ref)))
[1] 8.087884

length(unique(na.omit(even.corpus.pos.data.frame$word.id))) / length(unique(na.omit(even.corpus.pos.data.frame$ntvr_ref)))
[1] 7.212037

length(unique(na.omit(hoocak.corpus.pos.data.frame$word.id))) / length(unique(na.omit(hoocak.corpus.pos.data.frame$ntvr_ref)))
[1] 7.837684

length(unique(na.omit(nuu.corpus.pos.data.frame$word.id))) / length(unique(na.omit(nuu.corpus.pos.data.frame$ntvr_ref)))
[1] 3.263461

length(unique(na.omit(popoluca.corpus.pos.data.frame$word.id))) / length(unique(na.omit(popoluca.corpus.pos.data.frame$ntvr_ref)))
[1] 3.828858

length(unique(na.omit(sakha.corpus.pos.data.frame$word.id))) / length(unique(na.omit(sakha.corpus.pos.data.frame$ntvr_ref)))
[1] 7.515488

# Morphemes per word
length(unique(na.omit(baure.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(baure.corpus.pos.data.frame$word.id)))
[1] 1.770414

length(unique(na.omit(bora.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(bora.corpus.pos.data.frame$word.id)))
[1] 2.205375

length(unique(na.omit(chintang.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(chintang.corpus.pos.data.frame$word.id)))
[1] 1.721756

length(unique(na.omit(dutch.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(dutch.corpus.pos.data.frame$word.id)))
[1] 1

length(unique(na.omit(english.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(english.corpus.pos.data.frame$word.id)))
[1] 1.096655

length(unique(na.omit(even.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(even.corpus.pos.data.frame$word.id)))
[1] 1.842062

length(unique(na.omit(hoocak.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(hoocak.corpus.pos.data.frame$word.id)))
[1] 1.767198

length(unique(na.omit(nuu.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(nuu.corpus.pos.data.frame$word.id)))
[1] 1.12711

length(unique(na.omit(popoluca.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(popoluca.corpus.pos.data.frame$word.id)))
[1] 1.879368

length(unique(na.omit(sakha.corpus.pos.data.frame$morpheme.id))) / length(unique(na.omit(sakha.corpus.pos.data.frame$word.id)))
[1] 1.668471


### Set word times to numeric

baure.corpus.pos.data.frame$WordBegin = as.numeric(baure.corpus.pos.data.frame$WordBegin)
baure.corpus.pos.data.frame$WordEnd = as.numeric(baure.corpus.pos.data.frame$WordEnd)
bora.corpus.pos.data.frame$WordBegin = as.numeric(bora.corpus.pos.data.frame$WordBegin)
bora.corpus.pos.data.frame$WordEnd = as.numeric(bora.corpus.pos.data.frame$WordEnd)
chintang.corpus.pos.data.frame$WordBegin = as.numeric(chintang.corpus.pos.data.frame$WordBegin)
chintang.corpus.pos.data.frame$WordEnd = as.numeric(chintang.corpus.pos.data.frame$WordEnd)
dutch.corpus.pos.data.frame$WordBegin = as.numeric(dutch.corpus.pos.data.frame$WordBegin)
dutch.corpus.pos.data.frame$WordEnd = as.numeric(dutch.corpus.pos.data.frame$WordEnd)
english.corpus.pos.data.frame$WordBegin = as.numeric(english.corpus.pos.data.frame$WordBegin)
english.corpus.pos.data.frame$WordEnd = as.numeric(english.corpus.pos.data.frame$WordEnd)
even.corpus.pos.data.frame$WordBegin = as.numeric(even.corpus.pos.data.frame$WordBegin)
even.corpus.pos.data.frame$WordEnd = as.numeric(even.corpus.pos.data.frame$WordEnd)
hoocak.corpus.pos.data.frame$WordBegin = as.numeric(hoocak.corpus.pos.data.frame$WordBegin)
hoocak.corpus.pos.data.frame$WordEnd = as.numeric(hoocak.corpus.pos.data.frame$WordEnd)
nuu.corpus.pos.data.frame$WordBegin = as.numeric(nuu.corpus.pos.data.frame$WordBegin)
nuu.corpus.pos.data.frame$WordEnd = as.numeric(nuu.corpus.pos.data.frame$WordEnd)
popoluca.corpus.pos.data.frame$WordBegin = as.numeric(popoluca.corpus.pos.data.frame$WordBegin)
popoluca.corpus.pos.data.frame$WordEnd = as.numeric(popoluca.corpus.pos.data.frame$WordEnd)
sakha.corpus.pos.data.frame$WordBegin = as.numeric(sakha.corpus.pos.data.frame$WordBegin)
sakha.corpus.pos.data.frame$WordEnd = as.numeric(sakha.corpus.pos.data.frame$WordEnd)

### Set word midpoints
baure.corpus.pos.data.frame$WordMidPoint = (baure.corpus.pos.data.frame$WordBegin + baure.corpus.pos.data.frame$WordEnd) / 2
bora.corpus.pos.data.frame$WordMidPoint = (bora.corpus.pos.data.frame$WordBegin + bora.corpus.pos.data.frame$WordEnd) / 2
chintang.corpus.pos.data.frame$WordMidPoint = (chintang.corpus.pos.data.frame$WordBegin + chintang.corpus.pos.data.frame$WordEnd) / 2
dutch.corpus.pos.data.frame$WordMidPoint = (dutch.corpus.pos.data.frame$WordBegin + dutch.corpus.pos.data.frame$WordEnd) / 2
english.corpus.pos.data.frame$WordMidPoint = (english.corpus.pos.data.frame$WordBegin + english.corpus.pos.data.frame$WordEnd) / 2
even.corpus.pos.data.frame$WordMidPoint = (even.corpus.pos.data.frame$WordBegin + even.corpus.pos.data.frame$WordEnd) / 2
hoocak.corpus.pos.data.frame$WordMidPoint = (hoocak.corpus.pos.data.frame$WordBegin + hoocak.corpus.pos.data.frame$WordEnd) / 2
nuu.corpus.pos.data.frame$WordMidPoint = (nuu.corpus.pos.data.frame$WordBegin + nuu.corpus.pos.data.frame$WordEnd) / 2
popoluca.corpus.pos.data.frame$WordMidPoint = (popoluca.corpus.pos.data.frame$WordBegin + popoluca.corpus.pos.data.frame$WordEnd) / 2
sakha.corpus.pos.data.frame$WordMidPoint = (sakha.corpus.pos.data.frame$WordBegin + sakha.corpus.pos.data.frame$WordEnd) / 2

### Set word lengths
baure.corpus.pos.data.frame$WordLength = baure.corpus.pos.data.frame$WordEnd - baure.corpus.pos.data.frame$WordBegin
bora.corpus.pos.data.frame$WordLength = bora.corpus.pos.data.frame$WordEnd - bora.corpus.pos.data.frame$WordBegin
chintang.corpus.pos.data.frame$WordLength = chintang.corpus.pos.data.frame$WordEnd - chintang.corpus.pos.data.frame$WordBegin
dutch.corpus.pos.data.frame$WordLength = dutch.corpus.pos.data.frame$WordEnd - dutch.corpus.pos.data.frame$WordBegin
english.corpus.pos.data.frame$WordLength = english.corpus.pos.data.frame$WordEnd - english.corpus.pos.data.frame$WordBegin
even.corpus.pos.data.frame$WordLength = even.corpus.pos.data.frame$WordEnd - even.corpus.pos.data.frame$WordBegin
hoocak.corpus.pos.data.frame$WordLength = hoocak.corpus.pos.data.frame$WordEnd - hoocak.corpus.pos.data.frame$WordBegin
nuu.corpus.pos.data.frame$WordLength = nuu.corpus.pos.data.frame$WordEnd - nuu.corpus.pos.data.frame$WordBegin
popoluca.corpus.pos.data.frame$WordLength = popoluca.corpus.pos.data.frame$WordEnd - popoluca.corpus.pos.data.frame$WordBegin
sakha.corpus.pos.data.frame$WordLength = sakha.corpus.pos.data.frame$WordEnd - sakha.corpus.pos.data.frame$WordBegin

### Add language names (Nǁng is still called Nǀuu here)
baure.corpus.pos.data.frame$language="Baure"
bora.corpus.pos.data.frame$language = "Bora"
chintang.corpus.pos.data.frame$language = "Chintang"
dutch.corpus.pos.data.frame$language = "Dutch"
english.corpus.pos.data.frame$language = "English"
even.corpus.pos.data.frame$language = "Even"
hoocak.corpus.pos.data.frame$language = "Hoocąk"
nuu.corpus.pos.data.frame$language = "Nǀuu"
popoluca.corpus.pos.data.frame$language = "Popoluca"
sakha.corpus.pos.data.frame$language = "Sakha"

### Add position of word in annotation unit
baure.corpus.pos.data.frame$position = position.within.annotation.unit(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$position = position.within.annotation.unit(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$position = position.within.annotation.unit(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$position = position.within.annotation.unit(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$position = position.within.annotation.unit(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$position = position.within.annotation.unit(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$position = position.within.annotation.unit(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$position = position.within.annotation.unit(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$position = position.within.annotation.unit(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$position = position.within.annotation.unit(sakha.corpus.pos.data.frame)

### Add position of word in annotation unit (not counting filled pauses and false starts)
baure.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(baure.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
bora.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(bora.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
chintang.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(chintang.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
dutch.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(dutch.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
english.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(english.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
even.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(even.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
hoocak.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(hoocak.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
nuu.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(nuu.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
popoluca.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(popoluca.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
sakha.corpus.pos.data.frame$position.no_fldps = position.within.annotation.unit(sakha.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)

### Add position of word in annotation unit (counting from the end)
baure.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$position_from_last = position.within.annotation.unit.from.last(sakha.corpus.pos.data.frame)

### Add position of word in annotation unit (counting from the end and not counting filled pauses and false starts)
baure.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(baure.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
bora.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(bora.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
chintang.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(chintang.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
dutch.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(dutch.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
english.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(english.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
even.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(even.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
hoocak.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(hoocak.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
nuu.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(nuu.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
popoluca.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(popoluca.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
sakha.corpus.pos.data.frame$position_from_last.no_fldps = position.within.annotation.unit.from.last(sakha.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)

### Add normalized position of word in annotation unit
baure.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$position_percentage = position.within.annotation.unit.percentage(sakha.corpus.pos.data.frame)

### Add normalized position of word in annotation unit (not counting filled pauses and false starts)
baure.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(baure.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
bora.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(bora.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
chintang.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(chintang.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
dutch.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(dutch.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
english.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(english.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
even.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(even.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
hoocak.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(hoocak.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
nuu.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(nuu.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
popoluca.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(popoluca.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
sakha.corpus.pos.data.frame$position_percentage.no_fldps = position.within.annotation.unit.percentage(sakha.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)


### Add lengths of characters to each word

# The default set of characters that are ignored are: ignore_chars="[])=,?!¿¡.*:;\"\'([-]"
# This default set is changed for some languages.
# A normalization function (see R functions) is used for some languages prior to counting the number of characters in each word.
# TODO: explain type="width"
baure.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(baure.corpus.pos.data.frame, "word", ignore_chars="[])=,?!¿¡.*:;\"([-]")
bora.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(bora.corpus.pos.data.frame, "word", normalize = normalize_bora, type="width")
chintang.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(chintang.corpus.pos.data.frame, "word", normalize = normalize_chintang, type="width")
dutch.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(dutch.corpus.pos.data.frame, "word", ignore_chars="[])=,?!¿¡.*:;\"\'([-]")
english.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(english.corpus.pos.data.frame, "word", ignore_chars="[])=,?!¿¡.*:;\"\'([-]")
even.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(even.corpus.pos.data.frame, "word")
hoocak.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(hoocak.corpus.pos.data.frame, "word", ignore_chars="[])=,?!¿¡.*:;\"<>_([-]", type="width", normalize=normalize_hoocak)
nuu.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(nuu.corpus.pos.data.frame, "word", ignore_chars="[])=,?¿¡.*:;\"([-]")
popoluca.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(popoluca.corpus.pos.data.frame, "word", ignore_chars="[])=,?!¿¡.*:;\"([-]")
sakha.corpus.pos.data.frame$chars_per_word = count.characterlength.perword(sakha.corpus.pos.data.frame, "word")


### Add number of morphemes to each word

baure.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(baure.corpus.pos.data.frame, "morph")
bora.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(bora.corpus.pos.data.frame, "morph")
chintang.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(chintang.corpus.pos.data.frame, "morph")
dutch.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(dutch.corpus.pos.data.frame, "morph")
english.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(english.corpus.pos.data.frame, "morph")
even.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(even.corpus.pos.data.frame, "morph")
hoocak.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(hoocak.corpus.pos.data.frame, "morph")
nuu.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(nuu.corpus.pos.data.frame, "morph")
popoluca.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(popoluca.corpus.pos.data.frame, "morph")
sakha.corpus.pos.data.frame$morphs_per_word = count.morphemes.perword(sakha.corpus.pos.data.frame, "morph")


### Add length of annotation units

## Length of annotation units in words
baure.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$words_per_record = length.of.annotation.units.in.words(sakha.corpus.pos.data.frame)

# Length of annotation units in words (ignoring filled pauses and false starts)
baure.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(baure.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
bora.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(bora.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
chintang.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(chintang.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
dutch.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(dutch.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
english.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(english.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
even.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(even.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
hoocak.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(hoocak.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
nuu.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(nuu.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
popoluca.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(popoluca.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
sakha.corpus.pos.data.frame$words_per_record.no_fldps = length.of.annotation.units.in.words(sakha.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)


## Length of annotation units in characters
baure.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$chars_per_record = length.of.annotation.units.in.characters(sakha.corpus.pos.data.frame)

# Length of annotation units in characters (ignoring filled pauses and false starts)
baure.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(baure.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
bora.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(bora.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
chintang.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(chintang.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
dutch.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(dutch.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
english.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(english.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
even.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(even.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
hoocak.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(hoocak.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
nuu.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(nuu.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
popoluca.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(popoluca.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
sakha.corpus.pos.data.frame$chars_per_record.no_fldps = length.of.annotation.units.in.characters(sakha.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)


## Length of annotation units in morphs
baure.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$morphs_per_record = length.of.annotation.units.in.morphemes(sakha.corpus.pos.data.frame)

# Length of annotation units in morphs (ignoring filled pauses and false starts)
baure.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(baure.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
bora.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(bora.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
chintang.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(chintang.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
dutch.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(dutch.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
english.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(english.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
even.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(even.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
hoocak.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(hoocak.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
nuu.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(nuu.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
popoluca.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(popoluca.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
sakha.corpus.pos.data.frame$morphs_per_record.no_fldps = length.of.annotation.units.in.morphemes(sakha.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)


## Length of annotation units in seconds (including pauses)
baure.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$seconds_per_record = length.of.annotation.units.in.seconds(sakha.corpus.pos.data.frame)

# Length of annotation units in seconds (including silent pauses but excluding filled pauses and false starts)
baure.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(baure.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
bora.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(bora.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
chintang.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(chintang.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
dutch.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(dutch.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
english.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(english.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
even.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(even.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
hoocak.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(hoocak.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
nuu.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(nuu.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
popoluca.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(popoluca.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
sakha.corpus.pos.data.frame$seconds_per_record.no_fldps = length.of.annotation.units.in.seconds(sakha.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)


## Length of annotation units in seconds (sum of word times = excluding silent pauses)
baure.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$seconds_per_record.no_pauses = length.of.annotation.units.from.wordtimes(sakha.corpus.pos.data.frame)

## Length of annotation units in seconds (sum of word times = excluding silent pauses as well as filled pauses and false starts)
baure.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(baure.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
bora.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(bora.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
chintang.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(chintang.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
dutch.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(dutch.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
english.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(english.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
even.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(even.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
hoocak.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(hoocak.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
nuu.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(nuu.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
popoluca.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(popoluca.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)
sakha.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps = length.of.annotation.units.from.wordtimes(sakha.corpus.pos.data.frame, ignore_filled_pauses=T, ignore_false_starts=T)


## Length of pauses per annotation unit
baure.corpus.pos.data.frame$pause_per_record = baure.corpus.pos.data.frame$seconds_per_record - baure.corpus.pos.data.frame$seconds_per_record.no_pauses
bora.corpus.pos.data.frame$pause_per_record = bora.corpus.pos.data.frame$seconds_per_record - bora.corpus.pos.data.frame$seconds_per_record.no_pauses
chintang.corpus.pos.data.frame$pause_per_record = chintang.corpus.pos.data.frame$seconds_per_record - chintang.corpus.pos.data.frame$seconds_per_record.no_pauses
dutch.corpus.pos.data.frame$pause_per_record = dutch.corpus.pos.data.frame$seconds_per_record - dutch.corpus.pos.data.frame$seconds_per_record.no_pauses
english.corpus.pos.data.frame$pause_per_record = english.corpus.pos.data.frame$seconds_per_record - english.corpus.pos.data.frame$seconds_per_record.no_pauses
even.corpus.pos.data.frame$pause_per_record = even.corpus.pos.data.frame$seconds_per_record - even.corpus.pos.data.frame$seconds_per_record.no_pauses
hoocak.corpus.pos.data.frame$pause_per_record = hoocak.corpus.pos.data.frame$seconds_per_record - hoocak.corpus.pos.data.frame$seconds_per_record.no_pauses
nuu.corpus.pos.data.frame$pause_per_record = nuu.corpus.pos.data.frame$seconds_per_record - nuu.corpus.pos.data.frame$seconds_per_record.no_pauses
popoluca.corpus.pos.data.frame$pause_per_record = popoluca.corpus.pos.data.frame$seconds_per_record - popoluca.corpus.pos.data.frame$seconds_per_record.no_pauses
sakha.corpus.pos.data.frame$pause_per_record = sakha.corpus.pos.data.frame$seconds_per_record - sakha.corpus.pos.data.frame$seconds_per_record.no_pauses

## Length of pauses per annotation unit (exluding filled pauses and false starts)
baure.corpus.pos.data.frame$pause_per_record.no_fldps = baure.corpus.pos.data.frame$seconds_per_record - baure.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
bora.corpus.pos.data.frame$pause_per_record.no_fldps = bora.corpus.pos.data.frame$seconds_per_record - bora.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
chintang.corpus.pos.data.frame$pause_per_record.no_fldps = chintang.corpus.pos.data.frame$seconds_per_record - chintang.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
dutch.corpus.pos.data.frame$pause_per_record.no_fldps = dutch.corpus.pos.data.frame$seconds_per_record - dutch.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
english.corpus.pos.data.frame$pause_per_record.no_fldps = english.corpus.pos.data.frame$seconds_per_record - english.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
even.corpus.pos.data.frame$pause_per_record.no_fldps = even.corpus.pos.data.frame$seconds_per_record - even.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
hoocak.corpus.pos.data.frame$pause_per_record.no_fldps = hoocak.corpus.pos.data.frame$seconds_per_record - hoocak.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
nuu.corpus.pos.data.frame$pause_per_record.no_fldps = nuu.corpus.pos.data.frame$seconds_per_record - nuu.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
popoluca.corpus.pos.data.frame$pause_per_record.no_fldps = popoluca.corpus.pos.data.frame$seconds_per_record - popoluca.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
sakha.corpus.pos.data.frame$pause_per_record.no_fldps = sakha.corpus.pos.data.frame$seconds_per_record - sakha.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps


## Relative length of pauses per annotation unit
baure.corpus.pos.data.frame$pause_per_record_percentage = baure.corpus.pos.data.frame$pause_per_record * 100 / baure.corpus.pos.data.frame$seconds_per_record
bora.corpus.pos.data.frame$pause_per_record_percentage = bora.corpus.pos.data.frame$pause_per_record * 100 / bora.corpus.pos.data.frame$seconds_per_record
chintang.corpus.pos.data.frame$pause_per_record_percentage = chintang.corpus.pos.data.frame$pause_per_record * 100 / chintang.corpus.pos.data.frame$seconds_per_record
dutch.corpus.pos.data.frame$pause_per_record_percentage = dutch.corpus.pos.data.frame$pause_per_record * 100 / dutch.corpus.pos.data.frame$seconds_per_record
english.corpus.pos.data.frame$pause_per_record_percentage = english.corpus.pos.data.frame$pause_per_record * 100 / english.corpus.pos.data.frame$seconds_per_record
even.corpus.pos.data.frame$pause_per_record_percentage = even.corpus.pos.data.frame$pause_per_record * 100 / even.corpus.pos.data.frame$seconds_per_record
hoocak.corpus.pos.data.frame$pause_per_record_percentage = hoocak.corpus.pos.data.frame$pause_per_record * 100 / hoocak.corpus.pos.data.frame$seconds_per_record
nuu.corpus.pos.data.frame$pause_per_record_percentage = nuu.corpus.pos.data.frame$pause_per_record * 100 / nuu.corpus.pos.data.frame$seconds_per_record
popoluca.corpus.pos.data.frame$pause_per_record_percentage = popoluca.corpus.pos.data.frame$pause_per_record * 100 / popoluca.corpus.pos.data.frame$seconds_per_record
sakha.corpus.pos.data.frame$pause_per_record_percentage = sakha.corpus.pos.data.frame$pause_per_record * 100 / sakha.corpus.pos.data.frame$seconds_per_record

## Relative length of pauses per annotation unit (excluding filled pauses and false starts)
baure.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = baure.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / baure.corpus.pos.data.frame$seconds_per_record
bora.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = bora.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / bora.corpus.pos.data.frame$seconds_per_record
dutch.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = dutch.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / dutch.corpus.pos.data.frame$seconds_per_record
chintang.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = chintang.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / chintang.corpus.pos.data.frame$seconds_per_record
english.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = english.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / english.corpus.pos.data.frame$seconds_per_record
even.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = even.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / even.corpus.pos.data.frame$seconds_per_record
hoocak.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = hoocak.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / hoocak.corpus.pos.data.frame$seconds_per_record
nuu.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = nuu.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / nuu.corpus.pos.data.frame$seconds_per_record
popoluca.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = popoluca.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / popoluca.corpus.pos.data.frame$seconds_per_record
sakha.corpus.pos.data.frame$pause_per_record_percentage.no_fldps = sakha.corpus.pos.data.frame$pause_per_record.no_fldps * 100 / sakha.corpus.pos.data.frame$seconds_per_record


## Measure the pause before each word
baure.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$pause_before_word = calculate.pause.before.word(sakha.corpus.pos.data.frame)


## Measure the pause after each word
baure.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$pause_after_word = calculate.pause.after.word(sakha.corpus.pos.data.frame)


## Count the number of filled pauses per annotation unit
baure.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$fldps_per_record = filled.pauses.per.record(sakha.corpus.pos.data.frame)


## Count the number of false starts per annotation unit
baure.corpus.pos.data.frame$flst_per_record = false.starts.per.record(baure.corpus.pos.data.frame)
bora.corpus.pos.data.frame$flst_per_record = false.starts.per.record(bora.corpus.pos.data.frame)
chintang.corpus.pos.data.frame$flst_per_record = false.starts.per.record(chintang.corpus.pos.data.frame)
dutch.corpus.pos.data.frame$flst_per_record = false.starts.per.record(dutch.corpus.pos.data.frame)
english.corpus.pos.data.frame$flst_per_record = false.starts.per.record(english.corpus.pos.data.frame)
even.corpus.pos.data.frame$flst_per_record = false.starts.per.record(even.corpus.pos.data.frame)
hoocak.corpus.pos.data.frame$flst_per_record = false.starts.per.record(hoocak.corpus.pos.data.frame)
nuu.corpus.pos.data.frame$flst_per_record = false.starts.per.record(nuu.corpus.pos.data.frame)
popoluca.corpus.pos.data.frame$flst_per_record = false.starts.per.record(popoluca.corpus.pos.data.frame)
sakha.corpus.pos.data.frame$flst_per_record = false.starts.per.record(sakha.corpus.pos.data.frame)


### Calculate speed per annotation unit (raw speed without correction factors)

## Calculate speed per annotation unit - with silent pauses
baure.corpus.pos.data.frame$speed_per_record = baure.corpus.pos.data.frame$chars_per_record / baure.corpus.pos.data.frame$seconds_per_record
bora.corpus.pos.data.frame$speed_per_record = bora.corpus.pos.data.frame$chars_per_record / bora.corpus.pos.data.frame$seconds_per_record
chintang.corpus.pos.data.frame$speed_per_record = chintang.corpus.pos.data.frame$chars_per_record / chintang.corpus.pos.data.frame$seconds_per_record
dutch.corpus.pos.data.frame$speed_per_record = dutch.corpus.pos.data.frame$chars_per_record / dutch.corpus.pos.data.frame$seconds_per_record
english.corpus.pos.data.frame$speed_per_record = english.corpus.pos.data.frame$chars_per_record / english.corpus.pos.data.frame$seconds_per_record
even.corpus.pos.data.frame$speed_per_record = even.corpus.pos.data.frame$chars_per_record / even.corpus.pos.data.frame$seconds_per_record
hoocak.corpus.pos.data.frame$speed_per_record = hoocak.corpus.pos.data.frame$chars_per_record / hoocak.corpus.pos.data.frame$seconds_per_record
nuu.corpus.pos.data.frame$speed_per_record = nuu.corpus.pos.data.frame$chars_per_record / nuu.corpus.pos.data.frame$seconds_per_record
popoluca.corpus.pos.data.frame$speed_per_record = popoluca.corpus.pos.data.frame$chars_per_record / popoluca.corpus.pos.data.frame$seconds_per_record
sakha.corpus.pos.data.frame$speed_per_record = sakha.corpus.pos.data.frame$chars_per_record / sakha.corpus.pos.data.frame$seconds_per_record

## Calculate speed per annotation unit - with silent pauses (excluding filled pauses and false starts)
baure.corpus.pos.data.frame$speed_per_record.no_fldps = baure.corpus.pos.data.frame$chars_per_record.no_fldps / baure.corpus.pos.data.frame$seconds_per_record.no_fldps
bora.corpus.pos.data.frame$speed_per_record.no_fldps = bora.corpus.pos.data.frame$chars_per_record.no_fldps / bora.corpus.pos.data.frame$seconds_per_record.no_fldps
chintang.corpus.pos.data.frame$speed_per_record.no_fldps = chintang.corpus.pos.data.frame$chars_per_record.no_fldps / chintang.corpus.pos.data.frame$seconds_per_record.no_fldps
dutch.corpus.pos.data.frame$speed_per_record.no_fldps = dutch.corpus.pos.data.frame$chars_per_record.no_fldps / dutch.corpus.pos.data.frame$seconds_per_record.no_fldps
english.corpus.pos.data.frame$speed_per_record.no_fldps = english.corpus.pos.data.frame$chars_per_record.no_fldps / english.corpus.pos.data.frame$seconds_per_record.no_fldps
even.corpus.pos.data.frame$speed_per_record.no_fldps = even.corpus.pos.data.frame$chars_per_record.no_fldps / even.corpus.pos.data.frame$seconds_per_record.no_fldps
hoocak.corpus.pos.data.frame$speed_per_record.no_fldps = hoocak.corpus.pos.data.frame$chars_per_record.no_fldps / hoocak.corpus.pos.data.frame$seconds_per_record.no_fldps
nuu.corpus.pos.data.frame$speed_per_record.no_fldps = nuu.corpus.pos.data.frame$chars_per_record.no_fldps / nuu.corpus.pos.data.frame$seconds_per_record.no_fldps
popoluca.corpus.pos.data.frame$speed_per_record.no_fldps = popoluca.corpus.pos.data.frame$chars_per_record.no_fldps / popoluca.corpus.pos.data.frame$seconds_per_record.no_fldps
sakha.corpus.pos.data.frame$speed_per_record.no_fldps = sakha.corpus.pos.data.frame$chars_per_record.no_fldps / sakha.corpus.pos.data.frame$seconds_per_record.no_fldps


## Calculate speed per annotation unit - without silent pauses
baure.corpus.pos.data.frame$speed_per_record.no_pauses = baure.corpus.pos.data.frame$chars_per_record / baure.corpus.pos.data.frame$seconds_per_record.no_pauses
bora.corpus.pos.data.frame$speed_per_record.no_pauses = bora.corpus.pos.data.frame$chars_per_record / bora.corpus.pos.data.frame$seconds_per_record.no_pauses
chintang.corpus.pos.data.frame$speed_per_record.no_pauses = chintang.corpus.pos.data.frame$chars_per_record / chintang.corpus.pos.data.frame$seconds_per_record.no_pauses
dutch.corpus.pos.data.frame$speed_per_record.no_pauses = dutch.corpus.pos.data.frame$chars_per_record / dutch.corpus.pos.data.frame$seconds_per_record.no_pauses
english.corpus.pos.data.frame$speed_per_record.no_pauses = english.corpus.pos.data.frame$chars_per_record / english.corpus.pos.data.frame$seconds_per_record.no_pauses
even.corpus.pos.data.frame$speed_per_record.no_pauses = even.corpus.pos.data.frame$chars_per_record / even.corpus.pos.data.frame$seconds_per_record.no_pauses
hoocak.corpus.pos.data.frame$speed_per_record.no_pauses = hoocak.corpus.pos.data.frame$chars_per_record / hoocak.corpus.pos.data.frame$seconds_per_record.no_pauses
nuu.corpus.pos.data.frame$speed_per_record.no_pauses = nuu.corpus.pos.data.frame$chars_per_record / nuu.corpus.pos.data.frame$seconds_per_record.no_pauses
popoluca.corpus.pos.data.frame$speed_per_record.no_pauses = popoluca.corpus.pos.data.frame$chars_per_record / popoluca.corpus.pos.data.frame$seconds_per_record.no_pauses
sakha.corpus.pos.data.frame$speed_per_record.no_pauses = sakha.corpus.pos.data.frame$chars_per_record / sakha.corpus.pos.data.frame$seconds_per_record.no_pauses

## Calculate speed per annotation unit - without silent pauses (excluding filled pauses and false starts)baure.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = baure.corpus.pos.data.frame$chars_per_record.no_fldps / baure.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
bora.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = bora.corpus.pos.data.frame$chars_per_record.no_fldps / bora.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
chintang.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = chintang.corpus.pos.data.frame$chars_per_record.no_fldps / chintang.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
dutch.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = dutch.corpus.pos.data.frame$chars_per_record.no_fldps / dutch.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
english.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = english.corpus.pos.data.frame$chars_per_record.no_fldps / english.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
even.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = even.corpus.pos.data.frame$chars_per_record.no_fldps / even.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
hoocak.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = hoocak.corpus.pos.data.frame$chars_per_record.no_fldps / hoocak.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
nuu.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = nuu.corpus.pos.data.frame$chars_per_record.no_fldps / nuu.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
popoluca.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = popoluca.corpus.pos.data.frame$chars_per_record.no_fldps / popoluca.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps
sakha.corpus.pos.data.frame$speed_per_record.no_pauses.no_fldps = sakha.corpus.pos.data.frame$chars_per_record.no_fldps / sakha.corpus.pos.data.frame$seconds_per_record.no_pauses.no_fldps


## Mark annotation units with empty words for safety reasons

baure.corpus.pos.data.frame$empty_word_in_record = FALSE
bora.corpus.pos.data.frame$empty_word_in_record = FALSE
chintang.corpus.pos.data.frame$empty_word_in_record = FALSE
dutch.corpus.pos.data.frame$empty_word_in_record = FALSE
english.corpus.pos.data.frame$empty_word_in_record = FALSE
even.corpus.pos.data.frame$empty_word_in_record = FALSE
hoocak.corpus.pos.data.frame$empty_word_in_record = FALSE
nuu.corpus.pos.data.frame$empty_word_in_record = FALSE
popoluca.corpus.pos.data.frame$empty_word_in_record = FALSE
sakha.corpus.pos.data.frame$empty_word_in_record = FALSE

baure.corpus.pos.data.frame$empty_word_in_record[baure.corpus.pos.data.frame$chars_per_word==0 & !is.na(baure.corpus.pos.data.frame$word.id)] = TRUE
bora.corpus.pos.data.frame$empty_word_in_record[bora.corpus.pos.data.frame$chars_per_word==0 & !is.na(bora.corpus.pos.data.frame$word.id)] = TRUE
chintang.corpus.pos.data.frame$empty_word_in_record[chintang.corpus.pos.data.frame$chars_per_word==0 & !is.na(chintang.corpus.pos.data.frame$word.id)] = TRUE
dutch.corpus.pos.data.frame$empty_word_in_record[dutch.corpus.pos.data.frame$chars_per_word==0 & !is.na(dutch.corpus.pos.data.frame$word.id)] = TRUE
english.corpus.pos.data.frame$empty_word_in_record[english.corpus.pos.data.frame$chars_per_word==0 & !is.na(english.corpus.pos.data.frame$word.id)] = TRUE
even.corpus.pos.data.frame$empty_word_in_record[even.corpus.pos.data.frame$chars_per_word==0 & !is.na(even.corpus.pos.data.frame$word.id)] = TRUE
hoocak.corpus.pos.data.frame$empty_word_in_record[hoocak.corpus.pos.data.frame$chars_per_word==0 & !is.na(hoocak.corpus.pos.data.frame$word.id)] = TRUE
nuu.corpus.pos.data.frame$empty_word_in_record[nuu.corpus.pos.data.frame$chars_per_word==0 & !is.na(nuu.corpus.pos.data.frame$word.id)] = TRUE
popoluca.corpus.pos.data.frame$empty_word_in_record[popoluca.corpus.pos.data.frame$chars_per_word==0 & !is.na(popoluca.corpus.pos.data.frame$word.id)] = TRUE
sakha.corpus.pos.data.frame$empty_word_in_record[sakha.corpus.pos.data.frame$chars_per_word==0 & !is.na(sakha.corpus.pos.data.frame$word.id)] = TRUE


### Calculate articulation speed per word

## Calculate speed per word
baure.corpus.pos.data.frame$speed_per_word = baure.corpus.pos.data.frame$chars_per_word / baure.corpus.pos.data.frame$WordLength
bora.corpus.pos.data.frame$speed_per_word = bora.corpus.pos.data.frame$chars_per_word / bora.corpus.pos.data.frame$WordLength
chintang.corpus.pos.data.frame$speed_per_word = chintang.corpus.pos.data.frame$chars_per_word / chintang.corpus.pos.data.frame$WordLength
dutch.corpus.pos.data.frame$speed_per_word = dutch.corpus.pos.data.frame$chars_per_word / dutch.corpus.pos.data.frame$WordLength
english.corpus.pos.data.frame$speed_per_word = english.corpus.pos.data.frame$chars_per_word / english.corpus.pos.data.frame$WordLength
even.corpus.pos.data.frame$speed_per_word = even.corpus.pos.data.frame$chars_per_word / even.corpus.pos.data.frame$WordLength
hoocak.corpus.pos.data.frame$speed_per_word = hoocak.corpus.pos.data.frame$chars_per_word / hoocak.corpus.pos.data.frame$WordLength
nuu.corpus.pos.data.frame$speed_per_word = nuu.corpus.pos.data.frame$chars_per_word / nuu.corpus.pos.data.frame$WordLength
popoluca.corpus.pos.data.frame$speed_per_word = popoluca.corpus.pos.data.frame$chars_per_word / popoluca.corpus.pos.data.frame$WordLength
sakha.corpus.pos.data.frame$speed_per_word = sakha.corpus.pos.data.frame$chars_per_word / sakha.corpus.pos.data.frame$WordLength


### Annotate code-switching

# Look for morphemes annotated as comming from a different language than the one being investigated (for example, Spanish, English, or Afrikaans)
baure.corpus.pos.data.frame$code_switching = calculate.code.switching.per.annotation.unit(baure.corpus.pos.data.frame, "lg", c("-spa","?spa","eng","spa","spa-","spa?","spn"))
chintang.corpus.pos.data.frame$code_switching = calculate.code.switching.per.annotation.unit(chintang.corpus.pos.data.frame, "lg", c("-N","E","N","N-","N/E"))
hoocak.corpus.pos.data.frame$code_switching = calculate.code.switching.per.annotation.unit(hoocak.corpus.pos.data.frame, "ps", c("ENGLISH"))
nuu.corpus.pos.data.frame$code_switching = calculate.code.switching.per.annotation.unit(nuu.corpus.pos.data.frame, "lg", c("-A","A","A-","E"))


### Add information about plannedness
### TODO: Add explanation on plannedness categories

baure.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(baure.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% baure.plannedness$ntvr_file) {
    plannedness = baure.plannedness$plannedness_genre[baure.plannedness$ntvr_file==ntvr_file]
    baure.corpus.pos.data.frame$plannedness[baure.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(baure.corpus.pos.data.frame$plannedness,useNA="ifany")

    0     1     2     3  <NA> 
  467 27445 13638  8605  2591 


bora.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(bora.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% bora.plannedness$ntvr_file) {
    plannedness = bora.plannedness$plannedness[bora.plannedness$ntvr_file==ntvr_file]
    bora.corpus.pos.data.frame$plannedness[bora.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(bora.corpus.pos.data.frame$plannedness,useNA="ifany")

    1     2     3 
58997  3828  3808 


chintang.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(chintang.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% chintang.plannedness$ntvr_file) {
    plannedness = chintang.plannedness$plannedness[chintang.plannedness$ntvr_file==ntvr_file]
    chintang.corpus.pos.data.frame$plannedness[chintang.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(chintang.corpus.pos.data.frame$plannedness,useNA="ifany")

    0     1     2     3 
 8146  1620 11399 61681 


dutch.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(dutch.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% dutch.plannedness$ntvr_file) {
    plannedness = dutch.plannedness$plannedness[dutch.plannedness$ntvr_file==ntvr_file]
    dutch.corpus.pos.data.frame$plannedness[dutch.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(dutch.corpus.pos.data.frame$plannedness,useNA="ifany")

    2     3 
11493 28227 

english.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(english.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% english.plannedness$ntvr_file) {
    plannedness = english.plannedness$plannedness[english.plannedness$ntvr_file==ntvr_file]
    english.corpus.pos.data.frame$plannedness[english.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(english.corpus.pos.data.frame$plannedness,useNA="ifany")

    3 
61564 


even.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(even.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% even.plannedness$ntvr_file) {
    plannedness = even.plannedness$plannedness[even.plannedness$ntvr_file==ntvr_file]
    even.corpus.pos.data.frame$plannedness[even.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(even.corpus.pos.data.frame$plannedness,useNA="ifany")

    0     1     2     3  <NA> 
  944  5833 60524  7211  3263 

table(even.corpus.pos.data.frame$ntvr_file[is.na(even.corpus.pos.data.frame$plannedness)])


hoocak.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(hoocak.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% hoocak.plannedness$ntvr_file) {
    plannedness = hoocak.plannedness$plannedness[hoocak.plannedness$ntvr_file==ntvr_file]
    hoocak.corpus.pos.data.frame$plannedness[hoocak.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(hoocak.corpus.pos.data.frame$plannedness,useNA="ifany")

    0     1     2     3 
  174  3453 35037  2723 


nuu.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(nuu.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% nuu.plannedness$ntvr_file) {
    plannedness = nuu.plannedness$plannedness[nuu.plannedness$ntvr_file==ntvr_file]
    nuu.corpus.pos.data.frame$plannedness[nuu.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(nuu.corpus.pos.data.frame$plannedness,useNA="ifany")

    1     2     3 
10858 19230  5709 


popoluca.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(popoluca.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% popoluca.plannedness$ntvr_file) {
    plannedness = popoluca.plannedness$plannedness[popoluca.plannedness$ntvr_file==ntvr_file]
    popoluca.corpus.pos.data.frame$plannedness[popoluca.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(popoluca.corpus.pos.data.frame$plannedness,useNA="ifany")

    1 
46629 


sakha.corpus.pos.data.frame$plannedness = NA
for (ntvr_file in unique(sakha.corpus.pos.data.frame$ntvr_file)) {
  plannedness = NA
  if (ntvr_file %in% sakha.plannedness$ntvr_file) {
    plannedness = sakha.plannedness$plannedness[sakha.plannedness$ntvr_file==ntvr_file]
    sakha.corpus.pos.data.frame$plannedness[sakha.corpus.pos.data.frame$ntvr_file==ntvr_file] = plannedness
  } else {
     print("No plannedness...")
     print(ntvr_file)
  }
}

table(sakha.corpus.pos.data.frame$plannedness,useNA="ifany")

    2 
53101 


### Add information about word types (def. same word form) and word frequencies
# TODO: keep this section or is it irrelevant because frequencies are counted again for the study?

delete.final_punctuation = function (word) {
  return(gsub("[-=,?¿¡.:;\"]$", "", word))
}

# Count word frequencies per language
# (Use morphological structure in order to potentially distinguish homographs)
# (Delete final punctuation marks)
baure.word.freqs = table(tolower(delete.final_punctuation(baure.corpus.pos.data.frame$whole_word_morph)))
bora.word.freqs = table(tolower(delete.final_punctuation(bora.corpus.pos.data.frame$whole_word_morph)))
chintang.word.freqs = table(tolower(delete.final_punctuation(chintang.corpus.pos.data.frame$whole_word_morph)))
dutch.word.freqs = table(tolower(delete.final_punctuation(dutch.corpus.pos.data.frame$whole_word_morph)))
english.word.freqs = table(tolower(delete.final_punctuation(english.corpus.pos.data.frame$whole_word_morph)))
even.word.freqs = table(tolower(delete.final_punctuation(even.corpus.pos.data.frame$whole_word_morph)))
hoocak.word.freqs = table(tolower(delete.final_punctuation(hoocak.corpus.pos.data.frame$whole_word_morph)))
nuu.word.freqs = table(tolower(delete.final_punctuation(nuu.corpus.pos.data.frame$whole_word_morph)))
popoluca.word.freqs = table(tolower(delete.final_punctuation(popoluca.corpus.pos.data.frame$whole_word_morph)))
sakha.word.freqs = table(tolower(delete.final_punctuation(sakha.corpus.pos.data.frame$whole_word_morph)))

# Add information about word type to all data frames
baure.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(baure.corpus.pos.data.frame$whole_word_morph))
bora.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(bora.corpus.pos.data.frame$whole_word_morph))
chintang.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(chintang.corpus.pos.data.frame$whole_word_morph))
dutch.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(dutch.corpus.pos.data.frame$whole_word_morph))
english.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(english.corpus.pos.data.frame$whole_word_morph))
even.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(even.corpus.pos.data.frame$whole_word_morph))
hoocak.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(hoocak.corpus.pos.data.frame$whole_word_morph))
nuu.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(nuu.corpus.pos.data.frame$whole_word_morph))
popoluca.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(popoluca.corpus.pos.data.frame$whole_word_morph))
sakha.corpus.pos.data.frame$word_type = tolower(delete.final_punctuation(sakha.corpus.pos.data.frame$whole_word_morph))

baure.corpus.pos.data.frame$word_freq = as.numeric(baure.word.freqs[baure.corpus.pos.data.frame$word_type])
bora.corpus.pos.data.frame$word_freq = as.numeric(bora.word.freqs[bora.corpus.pos.data.frame$word_type])
chintang.corpus.pos.data.frame$word_freq = as.numeric(chintang.word.freqs[chintang.corpus.pos.data.frame$word_type])
dutch.corpus.pos.data.frame$word_freq = as.numeric(dutch.word.freqs[dutch.corpus.pos.data.frame$word_type])
english.corpus.pos.data.frame$word_freq = as.numeric(english.word.freqs[english.corpus.pos.data.frame$word_type])
even.corpus.pos.data.frame$word_freq = as.numeric(even.word.freqs[even.corpus.pos.data.frame$word_type])
hoocak.corpus.pos.data.frame$word_freq = as.numeric(hoocak.word.freqs[hoocak.corpus.pos.data.frame$word_type])
nuu.corpus.pos.data.frame$word_freq = as.numeric(nuu.word.freqs[nuu.corpus.pos.data.frame$word_type])
popoluca.corpus.pos.data.frame$word_freq = as.numeric(popoluca.word.freqs[popoluca.corpus.pos.data.frame$word_type])
sakha.corpus.pos.data.frame$word_freq = as.numeric(sakha.word.freqs[sakha.corpus.pos.data.frame$word_type])

# Add rank version of word frequencies (dense ranking), decreasing order
baure.corpus.pos.data.frame$word_freq_rank = dense_rank(-baure.corpus.pos.data.frame$word_freq)
bora.corpus.pos.data.frame$word_freq_rank = dense_rank(-bora.corpus.pos.data.frame$word_freq)
chintang.corpus.pos.data.frame$word_freq_rank = dense_rank(-chintang.corpus.pos.data.frame$word_freq)
dutch.corpus.pos.data.frame$word_freq_rank = dense_rank(-dutch.corpus.pos.data.frame$word_freq)
english.corpus.pos.data.frame$word_freq_rank = dense_rank(-english.corpus.pos.data.frame$word_freq)
even.corpus.pos.data.frame$word_freq_rank = dense_rank(-even.corpus.pos.data.frame$word_freq)
hoocak.corpus.pos.data.frame$word_freq_rank = dense_rank(-hoocak.corpus.pos.data.frame$word_freq)
nuu.corpus.pos.data.frame$word_freq_rank = dense_rank(-nuu.corpus.pos.data.frame$word_freq)
popoluca.corpus.pos.data.frame$word_freq_rank = dense_rank(-popoluca.corpus.pos.data.frame$word_freq)
sakha.corpus.pos.data.frame$word_freq_rank = dense_rank(-sakha.corpus.pos.data.frame$word_freq)


### Combine data frames into one

# Add missing columns to some subcorpora
baure.corpus.pos.data.frame$id = NA
baure.corpus.pos.data.frame$whole_word_id = NA

bora.corpus.pos.data.frame$id = NA
bora.corpus.pos.data.frame$whole_word_id = NA
bora.corpus.pos.data.frame$lg = NA
bora.corpus.pos.data.frame$whole_word_lg = NA
bora.corpus.pos.data.frame$code_switching = 0

dutch.corpus.pos.data.frame$id = NA
dutch.corpus.pos.data.frame$whole_word_id = NA
dutch.corpus.pos.data.frame$lg = NA
dutch.corpus.pos.data.frame$whole_word_lg = NA
dutch.corpus.pos.data.frame$code_switching = 0
dutch.corpus.pos.data.frame$root = NA
dutch.corpus.pos.data.frame$mt = NA
dutch.corpus.pos.data.frame$whole_word_mt = NA

english.corpus.pos.data.frame$id = NA
english.corpus.pos.data.frame$whole_word_id = NA
english.corpus.pos.data.frame$lg = NA
english.corpus.pos.data.frame$whole_word_lg = NA
english.corpus.pos.data.frame$code_switching = 0

even.corpus.pos.data.frame$id = NA
even.corpus.pos.data.frame$whole_word_id = NA
even.corpus.pos.data.frame$whole_word_lg = NA
even.corpus.pos.data.frame$code_switching = 0

hoocak.corpus.pos.data.frame$lg = NA
hoocak.corpus.pos.data.frame$whole_word_lg = NA
hoocak.corpus.pos.data.frame$id = NA
hoocak.corpus.pos.data.frame$whole_word_id = NA

popoluca.corpus.pos.data.frame$id = NA
popoluca.corpus.pos.data.frame$whole_word_id = NA
popoluca.corpus.pos.data.frame$lg = NA
popoluca.corpus.pos.data.frame$whole_word_lg = NA
popoluca.corpus.pos.data.frame$code_switching = 0

sakha.corpus.pos.data.frame$id = NA
sakha.corpus.pos.data.frame$whole_word_id = NA
sakha.corpus.pos.data.frame$lg = NA
sakha.corpus.pos.data.frame$whole_word_lg = NA
sakha.corpus.pos.data.frame$code_switching = 0


# Make IDs (record.id, word.id, morpheme.id) unique by adding the maximal value from the previous subcorpus to the following subcorpus
bora.corpus.pos.data.frame$word.id = bora.corpus.pos.data.frame$word.id + max(na.omit(baure.corpus.pos.data.frame$word.id))
bora.corpus.pos.data.frame$record.id = bora.corpus.pos.data.frame$record.id + max(na.omit(baure.corpus.pos.data.frame$record.id))
bora.corpus.pos.data.frame$morpheme.id = bora.corpus.pos.data.frame$morpheme.id + max(na.omit(baure.corpus.pos.data.frame$morpheme.id))

chintang.corpus.pos.data.frame$word.id = chintang.corpus.pos.data.frame$word.id + max(na.omit(bora.corpus.pos.data.frame$word.id))
chintang.corpus.pos.data.frame$record.id = chintang.corpus.pos.data.frame$record.id + max(na.omit(bora.corpus.pos.data.frame$record.id))
chintang.corpus.pos.data.frame$morpheme.id = chintang.corpus.pos.data.frame$morpheme.id + max(na.omit(bora.corpus.pos.data.frame$morpheme.id))

dutch.corpus.pos.data.frame$word.id = dutch.corpus.pos.data.frame$word.id + max(na.omit(chintang.corpus.pos.data.frame$word.id))
dutch.corpus.pos.data.frame$record.id = dutch.corpus.pos.data.frame$record.id + max(na.omit(chintang.corpus.pos.data.frame$record.id))
dutch.corpus.pos.data.frame$morpheme.id = dutch.corpus.pos.data.frame$morpheme.id + max(na.omit(chintang.corpus.pos.data.frame$morpheme.id))

english.corpus.pos.data.frame$word.id = english.corpus.pos.data.frame$word.id + max(na.omit(dutch.corpus.pos.data.frame$word.id))
english.corpus.pos.data.frame$record.id = english.corpus.pos.data.frame$record.id + max(na.omit(dutch.corpus.pos.data.frame$record.id))
english.corpus.pos.data.frame$morpheme.id = english.corpus.pos.data.frame$morpheme.id + max(na.omit(dutch.corpus.pos.data.frame$morpheme.id))

even.corpus.pos.data.frame$word.id = even.corpus.pos.data.frame$word.id + max(na.omit(english.corpus.pos.data.frame$word.id))
even.corpus.pos.data.frame$record.id = even.corpus.pos.data.frame$record.id + max(na.omit(english.corpus.pos.data.frame$record.id))
even.corpus.pos.data.frame$morpheme.id = even.corpus.pos.data.frame$morpheme.id + max(na.omit(english.corpus.pos.data.frame$morpheme.id))

hoocak.corpus.pos.data.frame$word.id = hoocak.corpus.pos.data.frame$word.id + max(na.omit(even.corpus.pos.data.frame$word.id))
hoocak.corpus.pos.data.frame$record.id = hoocak.corpus.pos.data.frame$record.id + max(na.omit(even.corpus.pos.data.frame$record.id))
hoocak.corpus.pos.data.frame$morpheme.id = hoocak.corpus.pos.data.frame$morpheme.id + max(na.omit(even.corpus.pos.data.frame$morpheme.id))

nuu.corpus.pos.data.frame$word.id = nuu.corpus.pos.data.frame$word.id + max(na.omit(hoocak.corpus.pos.data.frame$word.id))
nuu.corpus.pos.data.frame$record.id = nuu.corpus.pos.data.frame$record.id + max(na.omit(hoocak.corpus.pos.data.frame$record.id))
nuu.corpus.pos.data.frame$morpheme.id = nuu.corpus.pos.data.frame$morpheme.id + max(na.omit(hoocak.corpus.pos.data.frame$morpheme.id))

popoluca.corpus.pos.data.frame$word.id = popoluca.corpus.pos.data.frame$word.id + max(na.omit(nuu.corpus.pos.data.frame$word.id))
popoluca.corpus.pos.data.frame$record.id = popoluca.corpus.pos.data.frame$record.id + max(na.omit(nuu.corpus.pos.data.frame$record.id))
popoluca.corpus.pos.data.frame$morpheme.id = popoluca.corpus.pos.data.frame$morpheme.id + max(na.omit(nuu.corpus.pos.data.frame$morpheme.id))

sakha.corpus.pos.data.frame$word.id = sakha.corpus.pos.data.frame$word.id + max(na.omit(popoluca.corpus.pos.data.frame$word.id))
sakha.corpus.pos.data.frame$record.id = sakha.corpus.pos.data.frame$record.id + max(na.omit(popoluca.corpus.pos.data.frame$record.id))
sakha.corpus.pos.data.frame$morpheme.id = sakha.corpus.pos.data.frame$morpheme.id + max(na.omit(popoluca.corpus.pos.data.frame$morpheme.id))


### Exclude data

## Baure

length(unique(baure.corpus.pos.data.frame$word.id))
[1] 29772

# Look for researchers
table(baure.corpus.pos.data.frame$ELANParticipant)

     AD      AM      CL      CS      DC      FS      FX      GP      HC      II       L      LO      MC      PO      RP       S      SD 
   2178     213       6     455   11054      66       4     974    1137     627     323     342     495      11   24332    7100     176 
unknown 
   3253 

# Exclude S=Swintha, SD=Swintha (?) and L=Lena
baure.corpus.pos.data.frame.excluded = subset(baure.corpus.pos.data.frame,subset=baure.corpus.pos.data.frame$ELANParticipant!="L" & baure.corpus.pos.data.frame$ELANParticipant!="S" & baure.corpus.pos.data.frame$ELANParticipant!="SD")

length(unique(baure.corpus.pos.data.frame.excluded$word.id))
[1] 24472

# Code Switching
# Exclude annotation units with more than 50% Spanish words
baure.corpus.pos.data.frame.excluded = subset(baure.corpus.pos.data.frame.excluded,subset=baure.corpus.pos.data.frame.excluded$code_switching <= 0.5)

length(unique(baure.corpus.pos.data.frame.excluded$word.id))
[1] 22657

# Exclude certain sessions, following Swintha's suggestions
baure.exclude.always = c("DC-081105S.txt", "DC-P081201L.tbt", "HC-D120509S-2.tbt", "HC-D120514S.tbt", "HC-P030913S-3.txt", "II-P081210L.txt", "MD-120507S-1.tbt", "MD-N030824S-1.txt", "MD-N081128LF.tbt", "MD-N081213L.tbt", "MD-P081112L.tbt", "MD-P081117L.tbt", "MD-P081127L-2.tbt", "MD-P081211LF.tbt", "RP-101206S-1.tbt", "RP-110901S-4.tbt", "RP-N081212LF.tbt", "RP-P081126L.tbt", "RP-P030819S-1.txt")

baure.corpus.pos.data.frame.excluded = subset(baure.corpus.pos.data.frame.excluded,subset=!baure.corpus.pos.data.frame.excluded$ntvr_file %in% baure.exclude.always)

length(unique(baure.corpus.pos.data.frame.excluded$word.id))
[1] 19281

# Exclude songs etc., which are of plannedness category 0 (memorized)
unique(baure.corpus.pos.data.frame$ntvr_file[baure.corpus.pos.data.frame$plannedness=="0" | is.na(baure.corpus.pos.data.frame$plannedness)])
 [1] "DC-081105S.txt"    "DC-S090914S-1.tbt" "DC-S090914S-2.txt" "DC-S090914S-3.txt" "JP-S040709S-2.tbt" "JP-S040709S-4.tbt" "JP-S040709S-5.tbt" "JP-S040709S-6.tbt" "JP-S040709S-7.tbt"
[10] "RP-101206S-1.tbt"  "RP-S081126L-1.tbt" "RP-S081126L-2.tbt"
  
baure.corpus.pos.data.frame.excluded = subset(baure.corpus.pos.data.frame.excluded,subset=!baure.corpus.pos.data.frame.excluded$ntvr_file %in% unique(baure.corpus.pos.data.frame$ntvr_file[baure.corpus.pos.data.frame$plannedness=="0" | is.na(baure.corpus.pos.data.frame$plannedness)]))

length(unique(baure.corpus.pos.data.frame.excluded$word.id))
[1] 19105

# Blacklist for incorrect annotation units
baure.annotation_unit.blacklist = c("brg_AD-090807S_0105", "brg_AD-090807S_0277", "brg_AD_DC-C060401S_0030", "brg_AD_DC-C060401S_0035",
"brg_AD_DC-C060401S_0040", "brg_AD_DC-C060401S_0060", "brg_AD_DC-C060401S_0066", "brg_AD_DC-C060401S_0068", "brg_AD_DC-C060401S_0146",
"brg_AD_DC-C060401S_0148", "brg_AD_DC-C060401S_0155", "brg_AD_DC-C060401S_0168", "brg_AD_DC-C060401S_0231", "brg_AD_DC-C060401S_0281",
"brg_DC-C081111SL_0035", "brg_DC-C081111SL_0671", "brg_RP-N040721S_0038", "brg_RP-N040721S_0191", "brg_RP-N040721S_0201",
"brg_RP-P090810S_0025")

baure.corpus.pos.data.frame.excluded = subset(baure.corpus.pos.data.frame.excluded,subset=!baure.corpus.pos.data.frame.excluded$ntvr_ref %in% baure.annotation_unit.blacklist)

length(unique(baure.corpus.pos.data.frame.excluded$word.id))
[1] 19067

# Exclude empty annotation units
baure.corpus.pos.data.frame$ntvr_ref[baure.corpus.pos.data.frame$words_per_record == 0]
 [1] "brg_AD_DC-C060401S_0035"   "brg_AD_DC-C060401S_0040"   "brg_AD_DC-C060401S_0060"   "brg_AD_DC-C060401S_0068"   "brg_AD_DC-C060401S_0146"   "brg_AD_DC-C060401S_0155"  
 [7] "brg_AD_DC-C060401S_0168"   "brg_AD_DC-C060401S_0s281"   "brg_DC-C081111SL_0671"     "brg_DC-S090914S-1_0003"    "brg_II-P081210L_0164"      "brg_LO_GP-P091220P-2_0042"
[13] "brg_LO_GP-P091220P-2_0048" "brg_RP-110901S-4_0063"     "brg_RP-N081126SL_1054"     "brg_RP-N081128L_0290"      "brg_RP-N081128L_0396"      "brg_RP-N081212LF_0001"    
[19] "brg_RP-N081212LF_0002"     "brg_RP-N081212LF_0003"     "brg_RP-N081212LF_0004"     "brg_RP-N081212LF_0005"     "brg_RP-N081212LF_0006"     "brg_RP-N081212LF_0007"    
[25] "brg_RP-N081212LF_0008"     "brg_RP-N081212LF_0009"     "brg_RP-N081212LF_0010"     "brg_RP-N081212LF_0011"     "brg_RP-N081212LF_0012"     "brg_RP-N081212LF_0013"    
[31] "brg_RP-N081212LF_0014"     "brg_RP-N081212LF_0017"     "brg_RP-N081212LF_0020"     "brg_RP-N081212LF_0021"     "brg_RP-N081212LF_0022"     "brg_RP-N081212LF_0374"    
[37] "brg_RP-S081126L-2_0011"    "brg_RP_DC-C090811S_0127"   "brg_SIL3-N_0060"          

baure.corpus.pos.data.frame.excluded = subset(baure.corpus.pos.data.frame.excluded,subset=!baure.corpus.pos.data.frame.excluded$ntvr_ref %in% baure.corpus.pos.data.frame.excluded$ntvr_ref[baure.corpus.pos.data.frame.excluded$words_per_record == 0])

length(unique(baure.corpus.pos.data.frame.excluded$word.id))
[1] 19066

# Omit records without morphological annotation
baure.corpus.pos.data.frame.excluded$ntvr_ref[is.na(baure.corpus.pos.data.frame.excluded$morpheme.id)]
character(0)

baure.corpus.pos.data.frame.excluded = subset(baure.corpus.pos.data.frame.excluded,subset=!baure.corpus.pos.data.frame.excluded$ntvr_ref %in% baure.corpus.pos.data.frame.excluded$ntvr_ref[is.na(baure.corpus.pos.data.frame.excluded$morpheme.id)])

length(unique(baure.corpus.pos.data.frame.excluded$word.id))
[1] 19066

# Exclude additional texts from time based analyses (low quality or missing audio)
baure.exclude.timeseries = unique(baure.corpus.pos.data.frame.excluded$ntvr_file[baure.corpus.pos.data.frame.excluded$plannedness=="0" | is.na(baure.corpus.pos.data.frame.excluded$plannedness)])
baure.exclude.timeseries
character(0)

baure.exclude.timeseries = c(baure.exclude.timeseries, "DC-P090914S-4.tbt", "RP-P081120L.tbt", "SIL3-N.txt")
baure.exclude.timeseries
[1] "DC-P090914S-4.tbt" "RP-P081120L.tbt"   "SIL3-N.txt"       

baure.corpus.pos.data.frame.wordtimes = subset(baure.corpus.pos.data.frame.excluded,subset=!baure.corpus.pos.data.frame.excluded$ntvr_file %in% baure.exclude.timeseries)

length(unique(baure.corpus.pos.data.frame.wordtimes$word.id))
[1] 17652

# Select data for analyzing individual words - exclude empty and unclear words
baure.corpus.pos.data.frame.wordtimes.words = subset(baure.corpus.pos.data.frame.wordtimes,subset=!baure.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(baure.corpus.pos.data.frame.wordtimes$word.id[baure.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(baure.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 17652


## Bora

length(unique(bora.corpus.pos.data.frame$word.id))
[1] 30141

# Look for researchers (FS?)
table(bora.corpus.pos.data.frame$ELANParticipant)

    AAR      AC      AF      AL     ALF      AM      AP     ARR     CAP     CAV      CP     DRS     ELP      EP      ES     ESI     FEB      FS     GPE     HIC     INE       J      JN 
    233    7995      22      33     422     114    4713      91    2707      41     131      19      23       2     173      11      18      38      54      63      29      28      24 
     JP      JR     JUM     JUN     LBP     LIR     LUR     MAM      MM     MVP      OL     OLO      RA      RO     ROR      RR     RUF     RYP     SEC      SV unknown       V     VIR 
   1193      39   13400      42      23      27       3      22   20456       5     165      31     672     147    1393     200     290      19      40     173    8745    2293     264 
    YOS 
      7 

# Exclude FS=Frank
bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame,subset=bora.corpus.pos.data.frame$ELANParticipant!="FS")

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 30119

# Look for songs and other memorized speech (plannedness==0)
unique(bora.corpus.pos.data.frame$ntvr_file[bora.corpus.pos.data.frame$plannedness=="0" | is.na(bora.corpus.pos.data.frame$plannedness)])
character(0)

bora.exclude.timeseries = c()

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded, subset=!bora.corpus.pos.data.frame.excluded$ntvr_file %in% bora.exclude.timeseries)

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 30119

# Remove song parts contained in other texts
bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded, subset=!(bora.corpus.pos.data.frame.excluded$ntvr_file=="llijchu_ine_I.txt" & bora.corpus.pos.data.frame.excluded$orig_ref %in% c("219","549","554")))

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 30112

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded, subset=!(bora.corpus.pos.data.frame.excluded$ntvr_file=="niivuwa.txt" & bora.corpus.pos.data.frame.excluded$orig_ref %in% c("004","033","042")))

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 30084

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded, subset=!(bora.corpus.pos.data.frame.excluded$ntvr_file=="piivyeebe_ajyu.txt" & bora.corpus.pos.data.frame.excluded$orig_ref %in% c("188")))

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 30072

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded, subset=!(bora.corpus.pos.data.frame.excluded$ntvr_file=="taava_meewa.txt" & bora.corpus.pos.data.frame.excluded$orig_ref %in% c("094","115")))

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 30054

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded, subset=!(bora.corpus.pos.data.frame.excluded$ntvr_file=="vuurihii.txt" & bora.corpus.pos.data.frame.excluded$orig_ref %in% c("117")))

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 30049

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded, subset=!(bora.corpus.pos.data.frame.excluded$ntvr_file=="warEhko_mEE.txt" & bora.corpus.pos.data.frame.excluded$orig_ref %in% c("112")))

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 30034

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded, subset=!(bora.corpus.pos.data.frame.excluded$ntvr_file=="wakyu_cant_1.txt" & bora.corpus.pos.data.frame.excluded$orig_ref %in% c("16","17","18","19","20","21","22","23","24","25","26")))

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 29997

# Remove single annotation units with incorrect annotation
bora.annotation_unit.blacklist = c("boa_llijchu_ine_I_0056", "boa_llijchu_ine_I_0057", "boa_llijchu_ine_I_0060", "boa_llijchu_ine_I_0281", "boa_llijchu_ine_I_0294", "boa_meenujkatsi_0072")

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded,subset=!bora.corpus.pos.data.frame.excluded$ntvr_ref %in% bora.annotation_unit.blacklist)

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 29941

# Exclude empty annotation units
bora.corpus.pos.data.frame.excluded$ntvr_ref[bora.corpus.pos.data.frame.excluded$words_per_record == 0]
 [1] "boa_booake_idyone_0001"   "boa_cntres_10_Bora_0001"  "boa_llijchu_ine_I_0001"   "boa_llijchu_ine_II1_0001" "boa_lluuhii_0001"         "boa_maloca_renov_0001"   
 [7] "boa_meenujkatsi_0001"     "boa_mEEva_llij_0001"      "boa_mEEva_ran_0001"       "boa_mEEva_ran_0028"       "boa_mEEvaAurel06_0001"    "boa_mEEvaMM06_5_0001"    
[13] "boa_minga_7_0014"         "boa_namedij_aurel_0001"   "boa_nEjke_kuriota_0001"   "boa_niivuwa_0001"         "boa_niivuwajE_0001"       "boa_ovehe_1_0001"        
[19] "boa_ovehe_1_0074"         "boa_peetsocouuba_0001"    "boa_piivyeebe_ajyu_0001"  "boa_taava_meewa_0001"     "boa_vuurihii_0001"        "boa_wakyu_hist_0001"     
[25] "boa_warEhko_mEE_0001"    

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded,subset=!bora.corpus.pos.data.frame.excluded$ntvr_ref %in% bora.corpus.pos.data.frame.excluded$ntvr_ref[bora.corpus.pos.data.frame.excluded$words_per_record == 0])

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 29940

# Omit records without morphological annotation
bora.corpus.pos.data.frame.excluded$ntvr_ref[is.na(bora.corpus.pos.data.frame.excluded$morpheme.id)]
  [1] "boa_aakityeJP1_0021"     "boa_aakityeJP1_0021"     "boa_aakityeJP1_0021"     "boa_aakityeJP1_0021"     "boa_aakityeJP1_0021"     "boa_aakityeJP1_0021"     "boa_aakityeJP1_0021"    
  [8] "boa_aakityeJP1_0021"     "boa_aakityeJP1_0021"     "boa_aakityeJP1_0022"     "boa_aakityeJP1_0022"     "boa_aakityeJP1_0022"     "boa_aakityeJP1_0022"     "boa_aakityeJP1_0022"    
 [15] "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"    
 [22] "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"     "boa_aakityeJP1_0023"     "boa_aakityeJP1_0024"     "boa_aakityeJP1_0024"     "boa_aakityeJP1_0024"    
 [29] "boa_aakityeJP1_0024"     "boa_aakityeJP1_0024"     "boa_aakityeJP1_0024"     "boa_aakityeJP1_0024"     "boa_aakityeJP1_0024"     "boa_aakityeJP1_0024"     "boa_aakityeJP1_0025"    
 [36] "boa_aakityeJP1_0025"     "boa_aakityeJP1_0025"     "boa_aakityeJP1_0025"     "boa_aakityeJP1_0025"     "boa_aakityeJP1_0025"     "boa_aakityeJP1_0025"     "boa_aakityeJP1_0026"    
 [43] "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"    
 [50] "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0026"     "boa_aakityeJP1_0027"    
 [57] "boa_aakityeJP1_0027"     "boa_aakityeJP1_0027"     "boa_aakityeJP1_0028"     "boa_aakityeJP1_0028"     "boa_aakityeJP1_0028"     "boa_aakityeJP1_0029"     "boa_aakityeJP1_0029"    
 [64] "boa_aakityeJP1_0029"     "boa_aakityeJP1_0029"     "boa_aakityeJP1_0029"     "boa_aakityeJP1_0029"     "boa_aakityeJP1_0029"     "boa_aakityeJP1_0029"     "boa_aakityeJP1_0029"    
 [71] "boa_aakityeJP1_0029"     "boa_aakityeJP1_0030"     "boa_aakityeJP1_0030"     "boa_aakityeJP1_0030"     "boa_aakityeJP1_0031"     "boa_aakityeJP1_0031"     "boa_aakityeJP1_0031"    
 [78] "boa_aakityeJP1_0032"     "boa_aakityeJP1_0032"     "boa_aakityeJP1_0032"     "boa_aakityeJP1_0032"     "boa_aakityeJP1_0033"     "boa_aakityeJP1_0033"     "boa_aakityeJP1_0033"    
 [85] "boa_aakityeJP1_0033"     "boa_aakityeJP1_0033"     "boa_aakityeJP1_0033"     "boa_aakityeJP1_0033"     "boa_aakityeJP1_0033"     "boa_aakityeJP1_0033"     "boa_aakityeJP1_0034"    
 [92] "boa_aakityeJP1_0034"     "boa_aakityeJP1_0034"     "boa_aakityeJP1_0034"     "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"    
 [99] "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"     "boa_aakityeJP1_0035"    
[106] "boa_aakityeJP1_0036"     "boa_aakityeJP1_0036"     "boa_aakityeJP1_0036"     "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"    
[113] "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"     "boa_aakityeJP1_0037"    
[120] "boa_aakityeJP1_0037"     "boa_aakityeJP1_0038"     "boa_aakityeJP1_0039"     "boa_inf_josrobetc3_0011" "boa_mEEva_ran_0023"      "boa_mEEva_ran_0023"      "boa_mEEva_ran_0023"     
[127] "boa_mEEva_ran_0023"      "boa_mEEva_ran_0023"      "boa_mEEva_ran_0023"      "boa_mEEva_ran_0023"      "boa_minga_2_0044"        "boa_minga_2_0044"        "boa_minga_2_0045"       
[134] "boa_minga_2_0045"        "boa_minga_2_0047"        "boa_minga_2_0050"        "boa_minga_2_0052"        "boa_minga_7_0026"       

bora.corpus.pos.data.frame.excluded = subset(bora.corpus.pos.data.frame.excluded,subset=!bora.corpus.pos.data.frame.excluded$ntvr_ref %in% bora.corpus.pos.data.frame.excluded$ntvr_ref[is.na(bora.corpus.pos.data.frame.excluded$morpheme.id)])

length(unique(bora.corpus.pos.data.frame.excluded$word.id))
[1] 29802

bora.corpus.pos.data.frame.wordtimes = bora.corpus.pos.data.frame.excluded

# Create a version for analyzing individual words - exclude empty and unclear words
bora.corpus.pos.data.frame.wordtimes.words = subset(bora.corpus.pos.data.frame.wordtimes,subset=!bora.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(bora.corpus.pos.data.frame.wordtimes$word.id[bora.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(bora.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 29802

# Exclude annotation units with unclear words xxx
bora.corpus.pos.data.frame.wordtimes$ntvr_ref[grepl("xx+",bora.corpus.pos.data.frame.wordtimes$word)]
[1] "boa_ovehe_1_0070"

bora.corpus.pos.data.frame.wordtimes.words = subset(bora.corpus.pos.data.frame.wordtimes.words,subset=!bora.corpus.pos.data.frame.wordtimes.words$word.id %in% as.vector(na.omit(bora.corpus.pos.data.frame.wordtimes.words$word.id[grepl("xx+", bora.corpus.pos.data.frame.wordtimes.words$word)])))

length(unique(bora.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 29801


## Chintang

length(unique(chintang.corpus.pos.data.frame$word.id))
[1] 47869

# Look for researchers
table(chintang.corpus.pos.data.frame$ELANParticipant)

            AbinasR                 AWR                 BBR                 BBS                  BH                 BhB               BIRKU                 BJR                 CAK 
                 21                 116                5869                 261                  97                1339                1117                2008                  13 
                CBR              child1              child2                  CK             comment                 DBR                 DDR                 DHY                 DKR 
               1122                  15                   5                1355                  82                 662                2233                6805                  19 
                 DR                 DRR                 DSR DurgaDevi Rai (DVR)                 DVR                 GAR                 GIT                 GPR                 GUM 
                546                 778                 555                   6                2932                 804                 459                1144                1109 
                HBH                 JBS                 JBT                  JK                Junu                 KRM                 KSR                  LK                 Lok 
                201                 443                3730                1325                   3                2111                   8                1281                2058 
                LTR             Mal ser              Malser                  MG                 MKU                MOKR                 MOR                 MYR                NARR 
               3501                 541                 462                  10                2803                 221                1424                 615                1787 
              Nisha                  NP                PCMR                 PPK                  PR                 PRB                PUDR                PUMR             Rajemma 
                730                  47                 432                1167                  13                  14                 492                 120                 819 
                RAP                 RBK                RCHR                 RDR                  RM                 ROS          Sanchamaya                SHAM                 SMR 
                140                1188                 744                4080                3427                 296                 645                  16                  18 
                 SR                 SRW                 SUK                 SWR                  TD                 UMR             unknown             UNKNOWN            unknown1 
               1209                 331                  70                8724                 256                1784                  37                  54                 240 
           UNKNOWN1            unknown2            UNKNOWN2            unknown3            unknown4            unknown5            unknown6            unknown7            unknown8 
                 63                 245                  22                  64                  30                   5                   7                  15                  20 
                VKR                 YRP 
               1280                   6 

# Exclude MG
chintang.corpus.pos.data.frame.excluded = subset(chintang.corpus.pos.data.frame,subset=chintang.corpus.pos.data.frame$ELANParticipant!="MG")

length(unique(chintang.corpus.pos.data.frame.excluded$word.id))
[1] 47860

# Code switching
# Exclude annotation units with more than 50% Nepali or English words
chintang.corpus.pos.data.frame.excluded = subset(chintang.corpus.pos.data.frame.excluded,subset=chintang.corpus.pos.data.frame.excluded$code_switching <= 0.5)

length(unique(chintang.corpus.pos.data.frame.excluded$word.id))
[1] 42695

# Ritual language and songs
chintang.exclude.always = c("bhale_song.txt","Burhahang_01.txt","celi_azik_01.txt","comolung_song.txt","ctn_song_RM01.txt","hutlung_1.txt","kholamang.txt","pani_panca.txt","rajdeo_02.txt","rajdeu_wal01.txt","sudhar_cuwa.txt","sudhar_daijo.txt","sudhar_pakuwa.txt","sudhar_palawa.txt","tupla_phema_1.txt")

unique(chintang.corpus.pos.data.frame$ntvr_file[chintang.corpus.pos.data.frame$plannedness=="0" | is.na(chintang.corpus.pos.data.frame$plannedness)])
 [1] "bhale_song.txt"    "Burhahang_01.txt"  "celi_azik_01.txt"  "comolung_song.txt" "ctn_song_RM01.txt" "hutlung_1.txt"     "kholamang.txt"     "pani_panca.txt"    "rajdeo_02.txt"    
[10] "rajdeu_wal01.txt"  "sudhar_cuwa.txt"   "sudhar_daijo.txt"  "sudhar_pakuwa.txt" "sudhar_palawa.txt" "tupla_phema_1.txt"

chintang.corpus.pos.data.frame.excluded = subset(chintang.corpus.pos.data.frame.excluded,subset=!chintang.corpus.pos.data.frame.excluded$ntvr_file %in% chintang.exclude.always)

length(unique(chintang.corpus.pos.data.frame.excluded$word.id))
[1] 37825

# Blacklist of annotation units with wrong annotation / transcription
chintang.annotation_unit.blacklist = c("ctn_pear_8-2_0417","ctn_pear_11-1_0118")

chintang.corpus.pos.data.frame.excluded = subset(chintang.corpus.pos.data.frame.excluded,subset=!chintang.corpus.pos.data.frame.excluded$ntvr_ref %in% chintang.annotation_unit.blacklist)

length(unique(chintang.corpus.pos.data.frame.excluded$word.id))
[1] 37818

# Exclude empty annotation units
chintang.corpus.pos.data.frame.excluded$ntvr_ref[chintang.corpus.pos.data.frame.excluded$words_per_record == 0]
  [1] "ctn_pear_1-2_0018" "ctn_pear_1-2_0040" "ctn_pear_1-2_0045" "ctn_pear_1-2_0054" "ctn_pear_1-2_0130" "ctn_pear_1-2_0159" "ctn_pear_1-2_0187" "ctn_pear_1-3_0006" "ctn_pear_1-3_0008"
 [10] "ctn_pear_1-3_0009" "ctn_pear_1-3_0017" "ctn_pear_1-3_0018" "ctn_pear_1-3_0140" "ctn_pear_1-3_0156" "ctn_pear_1-3_0157" "ctn_pear_1-4_0026" "ctn_pear_1-4_0032" "ctn_pear_1-4_0056"
 [19] "ctn_pear_1-4_0057" "ctn_pear_1-4_0062" "ctn_pear_1-4_0066" "ctn_pear_1-4_0080" "ctn_pear_1-4_0091" "ctn_pear_1-4_0093" "ctn_pear_1-4_0095" "ctn_pear_1-4_0103" "ctn_pear_1-4_0110"
 [28] "ctn_pear_1-4_0122" "ctn_pear_1-4_0124" "ctn_pear_1-4_0127" "ctn_pear_1-4_0128" "ctn_pear_1-4_0132" "ctn_pear_1-4_0133" "ctn_pear_1-4_0134" "ctn_pear_2-2_0108" "ctn_pear_2-3_0002"
 [37] "ctn_pear_2-3_0011" "ctn_pear_2-3_0022" "ctn_pear_2-3_0043" "ctn_pear_2-3_0045" "ctn_pear_2-3_0061" "ctn_pear_2-3_0067" "ctn_pear_2-3_0070" "ctn_pear_2-3_0074" "ctn_pear_2-3_0077"
 [46] "ctn_pear_2-3_0080" "ctn_pear_2-3_0107" "ctn_pear_2-3_0116" "ctn_pear_2-3_0119" "ctn_pear_2-3_0121" "ctn_pear_2-3_0129" "ctn_pear_2-3_0136" "ctn_pear_2-3_0149" "ctn_pear_2-3_0159"
 [55] "ctn_pear_2-3_0163" "ctn_pear_2-3_0165" "ctn_pear_2-3_0168" "ctn_pear_2-3_0170" "ctn_pear_2-3_0173" "ctn_pear_2-3_0176" "ctn_pear_2-3_0181" "ctn_pear_2-3_0189" "ctn_pear_2-3_0193"
 [64] "ctn_pear_2-3_0198" "ctn_pear_2-3_0212" "ctn_pear_2-3_0222" "ctn_pear_2-3_0224" "ctn_pear_2-3_0225" "ctn_pear_2-3_0233" "ctn_pear_2-3_0234" "ctn_pear_2-3_0242" "ctn_pear_2-3_0259"
 [73] "ctn_pear_2-3_0261" "ctn_pear_2-3_0271" "ctn_pear_2-3_0273" "ctn_pear_2-3_0276" "ctn_pear_2-3_0289" "ctn_pear_2-3_0290" "ctn_pear_2-3_0293" "ctn_pear_2-3_0308" "ctn_pear_2-3_0310"
 [82] "ctn_pear_2-3_0311" "ctn_pear_2-3_0315" "ctn_pear_2-3_0320" "ctn_pear_2-3_0322" "ctn_pear_2-3_0324" "ctn_pear_2-3_0333" "ctn_pear_2-3_0336" "ctn_pear_2-3_0339" "ctn_pear_2-3_0343"
 [91] "ctn_pear_2-3_0345" "ctn_pear_2-3_0354" "ctn_pear_2-3_0362" "ctn_pear_2-3_0381" "ctn_pear_2-3_0390" "ctn_pear_2-3_0392" "ctn_pear_2-3_0393" "ctn_pear_2-3_0397" "ctn_pear_2-3_0409"
[100] "ctn_pear_2-3_0412" "ctn_pear_2-3_0418" "ctn_pear_2-3_0424" "ctn_pear_2-3_0430" "ctn_pear_2-3_0447" "ctn_pear_2-3_0450" "ctn_pear_2-3_0461" "ctn_pear_2-3_0464" "ctn_pear_2-3_0466"
[109] "ctn_pear_2-3_0468" "ctn_pear_2-3_0469" "ctn_pear_2-3_0470" "ctn_pear_2-3_0471" "ctn_pear_8-1_0020" "ctn_pear_8-1_0023" "ctn_pear_8-1_0032" "ctn_pear_8-1_0044" "ctn_pear_8-1_0048"
[118] "ctn_pear_8-1_0054" "ctn_pear_8-1_0077" "ctn_pear_8-1_0081" "ctn_pear_8-1_0088" "ctn_pear_8-1_0098" "ctn_pear_8-1_0105" "ctn_pear_8-1_0112" "ctn_pear_8-1_0118" "ctn_pear_8-1_0121"
[127] "ctn_pear_8-1_0130" "ctn_pear_8-1_0134" "ctn_pear_8-1_0139" "ctn_pear_8-1_0140" "ctn_pear_8-1_0143" "ctn_pear_8-1_0145" "ctn_pear_8-1_0148" "ctn_pear_8-1_0152" "ctn_pear_8-1_0190"
[136] "ctn_pear_8-1_0193" "ctn_pear_8-1_0196" "ctn_pear_8-1_0201" "ctn_pear_8-1_0203" "ctn_pear_8-1_0206" "ctn_pear_8-1_0211" "ctn_pear_8-1_0216" "ctn_pear_8-1_0220" "ctn_pear_8-1_0222"
[145] "ctn_pear_8-1_0226" "ctn_pear_8-1_0233" "ctn_pear_8-1_0243" "ctn_pear_8-1_0251" "ctn_pear_8-1_0256" "ctn_pear_8-1_0262" "ctn_pear_8-1_0265" "ctn_pear_8-1_0274" "ctn_pear_8-1_0279"
[154] "ctn_pear_8-1_0280" "ctn_pear_8-1_0286" "ctn_pear_8-1_0289" "ctn_pear_8-1_0293" "ctn_pear_8-1_0301" "ctn_pear_8-1_0306" "ctn_pear_8-1_0322" "ctn_pear_8-1_0326" "ctn_pear_8-1_0330"
[163] "ctn_pear_8-1_0332" "ctn_pear_8-1_0335" "ctn_pear_8-1_0337" "ctn_pear_8-1_0342" "ctn_pear_8-1_0346" "ctn_pear_8-1_0349" "ctn_pear_8-1_0352" "ctn_pear_8-1_0353" "ctn_pear_8-1_0356"
[172] "ctn_pear_8-1_0359" "ctn_pear_8-1_0363" "ctn_pear_8-1_0369" "ctn_pear_8-1_0374" "ctn_pear_8-1_0376" "ctn_pear_8-1_0381" "ctn_pear_8-1_0385" "ctn_pear_8-1_0388" "ctn_pear_8-1_0390"
[181] "ctn_pear_8-1_0398" "ctn_pear_8-1_0406" "ctn_pear_8-1_0412" "ctn_pear_8-1_0415" "ctn_pear_8-1_0417" "ctn_pear_8-1_0424" "ctn_pear_8-1_0426" "ctn_pear_8-1_0432" "ctn_pear_8-1_0433"
[190] "ctn_pear_8-1_0446" "ctn_pear_8-1_0449" "ctn_pear_8-1_0459" "ctn_pear_8-1_0461" "ctn_pear_8-1_0466" "ctn_pear_8-1_0468" "ctn_pear_8-1_0470" "ctn_pear_8-1_0473" "ctn_pear_8-1_0480"
[199] "ctn_pear_8-1_0487" "ctn_pear_8-1_0492" "ctn_pear_8-1_0503" "ctn_pear_8-1_0508" "ctn_pear_8-1_0512" "ctn_pear_8-1_0520" "ctn_pear_8-1_0535" "ctn_pear_8-1_0538" "ctn_pear_8-1_0540"
[208] "ctn_pear_8-1_0542" "ctn_pear_8-1_0549" "ctn_pear_8-1_0563" "ctn_pear_8-1_0571" "ctn_pear_8-1_0573" "ctn_pear_8-1_0579" "ctn_pear_8-1_0581" "ctn_pear_8-1_0599" "ctn_pear_8-1_0605"
[217] "ctn_pear_8-1_0611" "ctn_pear_8-1_0614" "ctn_pear_8-1_0618" "ctn_pear_8-1_0653" "ctn_pear_8-1_0659" "ctn_pear_8-1_0664" "ctn_pear_8-1_0666" "ctn_pear_8-1_0667" "ctn_pear_8-1_0673"
[226] "ctn_pear_8-1_0682" "ctn_pear_8-1_0684" "ctn_pear_8-1_0686" "ctn_pear_8-1_0693" "ctn_pear_8-1_0701" "ctn_pear_8-1_0706" "ctn_pear_8-1_0713" "ctn_pear_8-1_0716" "ctn_pear_8-1_0723"
[235] "ctn_pear_8-1_0726" "ctn_pear_8-1_0728" "ctn_pear_8-1_0733" "ctn_pear_8-1_0735" "ctn_pear_8-1_0737" "ctn_pear_8-1_0739" "ctn_pear_8-1_0742" "ctn_pear_8-1_0745" "ctn_pear_8-1_0748"
[244] "ctn_pear_8-1_0753" "ctn_pear_8-1_0755" "ctn_pear_8-1_0762" "ctn_pear_8-1_0766" "ctn_pear_8-1_0768" "ctn_pear_8-1_0780" "ctn_pear_8-1_0783" "ctn_pear_8-1_0787" "ctn_pear_8-1_0796"
[253] "ctn_pear_8-1_0805" "ctn_pear_8-1_0809" "ctn_pear_8-1_0814" "ctn_pear_8-1_0825" "ctn_pear_8-1_0845" "ctn_pear_8-1_0853" "ctn_pear_8-1_0854" "ctn_pear_8-1_0866" "ctn_pear_8-1_0867"
[262] "ctn_pear_8-1_0870" "ctn_pear_8-1_0892" "ctn_pear_8-1_0898" "ctn_pear_8-1_0900" "ctn_pear_8-1_0918" "ctn_pear_8-1_0920" "ctn_pear_8-1_0922" "ctn_pear_8-1_0924" "ctn_pear_8-1_0930"
[271] "ctn_pear_8-1_0944" "ctn_pear_8-1_0955" "ctn_pear_8-1_0959" "ctn_pear_8-1_0961" "ctn_pear_8-1_0963" "ctn_pear_8-1_0964" "ctn_pear_8-1_0966" "ctn_pear_8-1_0984" "ctn_pear_8-1_0987"
[280] "ctn_pear_8-1_0989" "ctn_pear_8-1_0991" "ctn_pear_8-1_0995" "ctn_pear_8-1_1000" "ctn_pear_8-1_1003" "ctn_pear_8-1_1006" "ctn_pear_8-1_1008" "ctn_pear_8-1_1029" "ctn_pear_8-1_1037"
[289] "ctn_pear_8-1_1050" "ctn_pear_8-1_1052" "ctn_pear_8-1_1053" "ctn_pear_8-1_1057" "ctn_pear_8-1_1058" "ctn_pear_8-1_1062" "ctn_pear_8-1_1065" "ctn_pear_8-1_1070" "ctn_pear_8-1_1072"
[298] "ctn_pear_8-1_1074" "ctn_pear_8-1_1075" "ctn_pear_8-1_1079" "ctn_pear_8-1_1088" "ctn_pear_8-1_1092" "ctn_pear_8-1_1096" "ctn_pear_8-1_1101" "ctn_pear_8-1_1114" "ctn_pear_8-1_1134"
[307] "ctn_pear_8-1_1161" "ctn_pear_8-1_1164" "ctn_pear_8-1_1172" "ctn_pear_8-1_1175" "ctn_pear_8-1_1182" "ctn_pear_8-1_1188" "ctn_pear_8-1_1190" "ctn_pear_8-1_1196" "ctn_pear_8-1_1199"
[316] "ctn_pear_8-1_1235" "ctn_pear_8-1_1240" "ctn_pear_8-1_1277" "ctn_pear_8-1_1299" "ctn_pear_8-1_1305" "ctn_pear_8-1_1322" "ctn_pear_8-3_0178"

chintang.corpus.pos.data.frame.excluded = subset(chintang.corpus.pos.data.frame.excluded,subset=!chintang.corpus.pos.data.frame.excluded$ntvr_ref %in% chintang.corpus.pos.data.frame.excluded$ntvr_ref[chintang.corpus.pos.data.frame.excluded$words_per_record == 0])

length(unique(chintang.corpus.pos.data.frame.excluded$word.id))
[1] 37817

# Omit records without morphological annotation
chintang.corpus.pos.data.frame.excluded$ntvr_ref[is.na(chintang.corpus.pos.data.frame.excluded$morpheme.id)]
 [1] "ctn_chintang_now_0441"  "ctn_chintang_now_0553"  "ctn_chintang_now_0553"  "ctn_chintang_now_0554"  "ctn_chintang_now_0554"  "ctn_chintang_now_0554"  "ctn_chintang_now_0554" 
 [8] "ctn_chintang_now_0554"  "ctn_chintang_now_0555"  "ctn_chintang_now_0556"  "ctn_chintang_now_0556"  "ctn_chintang_now_0556"  "ctn_chintang_now_0557"  "ctn_chintang_now_0557" 
[15] "ctn_chintang_now_0557"  "ctn_chintang_now_0557"  "ctn_chintang_now_0557"  "ctn_chintang_now_0557"  "ctn_chintang_now_0557"  "ctn_chintang_now_0755"  "ctn_chintang_now_0755" 
[22] "ctn_chintang_now_0755"  "ctn_chintang_now_0755"  "ctn_chintang_now_0755"  "ctn_chintang_now_0823"  "ctn_chintang_now_0823"  "ctn_chintang_now_0823"  "ctn_chintang_now_0823" 
[29] "ctn_chintang_now_0914"  "ctn_chintang_now_0914"  "ctn_chintang_now_0914"  "ctn_chintang_now_0996"  "ctn_chintang_now_0996"  "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0181"
[36] "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0181"
[43] "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0181" "ctn_ctn_prob_talk_0872" "ctn_ctn_prob_talk_0872" "ctn_ctn_prob_talk_0872" "ctn_ctn_prob_talk_0872" "ctn_ctn_prob_talk_0872"
[50] "ctn_ctn_prob_talk_0872" "ctn_ctn_prob_talk_0872" "ctn_kamce_talk_0091"    "ctn_pear_1-2_0122"      "ctn_pear_1-2_0151"      "ctn_pear_1-2_0186"      "ctn_pear_1-4_0048"     
[57] "ctn_pear_1-4_0048"      "ctn_pear_1-4_0048"      "ctn_pear_1-4_0048"      "ctn_pear_1-4_0048"      "ctn_pear_1-4_0048"      "ctn_pear_1-4_0048"      "ctn_pear_1-4_0050"     
[64] "ctn_pear_1-4_0050"      "ctn_pear_1-4_0050"      "ctn_pear_2-1_0143"      "ctn_pear_2-1_0263"      "ctn_pear_2-1_0263"      "ctn_pear_2-2_0091"      "ctn_pear_2-2_0091"     
[71] "ctn_pear_2-2_0091"      "ctn_pear_2-2_0091"      "ctn_pear_5-1_0003"      "ctn_pear_8-1_0357"      "ctn_pear_8-1_0357"      "ctn_pear_8-1_0671"      "ctn_pear_8-1_1124"     
[78] "ctn_pear_8-1_1250"      "ctn_pear_8-1_1253"      "ctn_pear_8-1_1297"     

chintang.corpus.pos.data.frame.excluded = subset(chintang.corpus.pos.data.frame.excluded,subset=!chintang.corpus.pos.data.frame.excluded$ntvr_ref %in% chintang.corpus.pos.data.frame.excluded$ntvr_ref[is.na(chintang.corpus.pos.data.frame.excluded$morpheme.id)])

length(unique(chintang.corpus.pos.data.frame.excluded$word.id))
[1] 37737

chintang.corpus.pos.data.frame.wordtimes = chintang.corpus.pos.data.frame.excluded

length(unique(chintang.corpus.pos.data.frame.wordtimes$word.id))
[1] 37737

# Omit records with empty and unclear words
chintang.corpus.pos.data.frame.wordtimes$ntvr_ref[chintang.corpus.pos.data.frame.wordtimes$chars_per_word == 0]
character(0)

# Create a version for analyzing individual words - exclude empty and unclear words
chintang.corpus.pos.data.frame.wordtimes.words = subset(chintang.corpus.pos.data.frame.wordtimes,subset=!chintang.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(chintang.corpus.pos.data.frame.wordtimes$word.id[chintang.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(chintang.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 37737


## Dutch

length(unique(dutch.corpus.pos.data.frame$word.id))
[1] 39720

dutch.corpus.pos.data.frame.excluded = dutch.corpus.pos.data.frame

length(unique(dutch.corpus.pos.data.frame.excluded$word.id))
[1] 39720

dutch.corpus.pos.data.frame.wordtimes = dutch.corpus.pos.data.frame.excluded

length(unique(dutch.corpus.pos.data.frame.wordtimes$word.id))
[1] 39720

# Exclude annotation units with unclear words for annotation-unit-based study
dutch.corpus.pos.data.frame.wordtimes$ntvr_ref[grepl("xx+",dutch.corpus.pos.data.frame.wordtimes$word)]
  [1] "nld_fn000086_0071" "nld_fn000086_0072" "nld_fn000086_0083" "nld_fn000086_0103" "nld_fn000086_0122" "nld_fn000086_0142" "nld_fn000086_0170" "nld_fn000086_0172" "nld_fn000086_0187"
 [10] "nld_fn000086_0214" "nld_fn000086_0239" "nld_fn000106_0009" "nld_fn000106_0036" "nld_fn000106_0051" "nld_fn000106_0061" "nld_fn000106_0193" "nld_fn000137_0093" "nld_fn000137_0234"
 [19] "nld_fn000137_0234" "nld_fn000137_0314" "nld_fn000137_0315" "nld_fn000137_0331" "nld_fn000140_0327" "nld_fn000254_0031" "nld_fn000254_0069" "nld_fn000254_0069" "nld_fn000254_0091"
 [28] "nld_fn000254_0109" "nld_fn000254_0215" "nld_fn000254_0223" "nld_fn000254_0266" "nld_fn000254_0275" "nld_fn000254_0362" "nld_fn000254_0375" "nld_fn000254_0458" "nld_fn000254_0485"
 [37] "nld_fn000254_0519" "nld_fn000254_0523" "nld_fn000254_0526" "nld_fn000254_0555" "nld_fn000254_0559" "nld_fn000254_0582" "nld_fn000254_0588" "nld_fn000254_0598" "nld_fn000265_0003"
 [46] "nld_fn000265_0072" "nld_fn000265_0104" "nld_fn000265_0188" "nld_fn000265_0194" "nld_fn000265_0199" "nld_fn000265_0205" "nld_fn000265_0256" "nld_fn000265_0281" "nld_fn000265_0314"
 [55] "nld_fn000265_0352" "nld_fn000280_0018" "nld_fn000280_0019" "nld_fn000280_0046" "nld_fn000280_0144" "nld_fn000280_0145" "nld_fn000280_0155" "nld_fn000280_0164" "nld_fn000280_0289"
 [64] "nld_fn000280_0294" "nld_fn000415_0026" "nld_fn000415_0034" "nld_fn000415_0091" "nld_fn000415_0095" "nld_fn000415_0132" "nld_fn000415_0184" "nld_fn000415_0194" "nld_fn000415_0229"
 [73] "nld_fn000415_0270" "nld_fn000415_0284" "nld_fn000446_0029" "nld_fn000446_0058" "nld_fn000446_0068" "nld_fn000446_0078" "nld_fn000446_0091" "nld_fn000446_0107" "nld_fn000446_0110"
 [82] "nld_fn000446_0139" "nld_fn000446_0139" "nld_fn000446_0178" "nld_fn000446_0244" "nld_fn000446_0290" "nld_fn000446_0326" "nld_fn000446_0380" "nld_fn000446_0414" "nld_fn000485_0052"
 [91] "nld_fn000485_0065" "nld_fn000485_0072" "nld_fn000485_0154" "nld_fn000485_0252" "nld_fn000485_0262" "nld_fn000485_0278" "nld_fn000505_0018" "nld_fn000505_0018" "nld_fn000505_0037"
[100] "nld_fn000505_0041" "nld_fn000505_0047" "nld_fn000505_0049" "nld_fn000505_0061" "nld_fn000505_0101" "nld_fn000505_0106" "nld_fn000505_0130" "nld_fn000505_0134" "nld_fn000505_0135"
[109] "nld_fn000505_0138" "nld_fn000505_0147" "nld_fn000505_0167" "nld_fn000505_0199" "nld_fn000559_0015" "nld_fn000559_0026" "nld_fn000559_0028" "nld_fn000559_0053" "nld_fn000559_0056"
[118] "nld_fn000559_0073" "nld_fn000559_0077" "nld_fn000559_0081" "nld_fn000559_0083" "nld_fn000559_0086" "nld_fn000559_0088" "nld_fn000559_0088" "nld_fn000559_0091" "nld_fn000559_0104"
[127] "nld_fn000559_0121" "nld_fn000559_0129" "nld_fn000559_0158" "nld_fn000559_0160" "nld_fn000559_0163" "nld_fn000559_0166" "nld_fn000559_0167" "nld_fn000559_0175" "nld_fn000559_0176"
[136] "nld_fn000559_0187" "nld_fn000559_0190" "nld_fn000559_0196" "nld_fn000559_0198" "nld_fn000559_0207" "nld_fn000559_0208" "nld_fn000559_0208" "nld_fn000559_0225" "nld_fn000559_0239"
[145] "nld_fn000559_0242" "nld_fn000559_0247" "nld_fn000559_0255" "nld_fn000559_0262" "nld_fn000559_0280" "nld_fn000559_0285" "nld_fn000559_0286" "nld_fn000559_0287" "nld_fn000559_0288"
[154] "nld_fn000559_0298" "nld_fn000559_0310" "nld_fn000559_0316" "nld_fn000559_0336" "nld_fn000559_0340" "nld_fn000559_0344" "nld_fn000559_0346" "nld_fn000559_0348" "nld_fn000559_0384"
[163] "nld_fn000570_0032" "nld_fn000570_0057" "nld_fn000570_0080" "nld_fn000570_0096" "nld_fn000570_0096" "nld_fn000570_0101" "nld_fn000570_0127" "nld_fn000570_0145" "nld_fn000570_0146"
[172] "nld_fn000570_0148" "nld_fn000570_0169" "nld_fn000570_0204" "nld_fn000570_0215" "nld_fn000570_0227" "nld_fn000570_0236" "nld_fn000570_0242" "nld_fn000570_0254" "nld_fn000570_0277"
[181] "nld_fn000570_0285" "nld_fn000573_0004" "nld_fn000573_0009" "nld_fn000573_0064" "nld_fn000573_0100" "nld_fn000573_0126" "nld_fn000573_0146" "nld_fn000573_0169" "nld_fn000573_0185"
[190] "nld_fn000573_0207" "nld_fn000573_0223" "nld_fn000573_0244" "nld_fn000573_0257" "nld_fn000573_0264" "nld_fn000573_0297" "nld_fn000573_0298" "nld_fn000573_0311" "nld_fn000573_0341"
[199] "nld_fn000573_0350" "nld_fn000573_0388" "nld_fn000587_0016" "nld_fn000587_0022" "nld_fn000587_0023" "nld_fn000587_0023" "nld_fn000587_0027" "nld_fn000587_0028" "nld_fn000587_0030"
[208] "nld_fn000587_0032" "nld_fn000587_0036" "nld_fn000587_0036" "nld_fn000587_0050" "nld_fn000587_0051" "nld_fn000587_0055" "nld_fn000587_0067" "nld_fn000587_0071" "nld_fn000587_0073"
[217] "nld_fn000587_0077" "nld_fn000587_0081" "nld_fn000587_0095" "nld_fn000587_0111" "nld_fn000587_0111" "nld_fn000587_0112" "nld_fn000587_0113" "nld_fn000587_0152" "nld_fn000587_0158"
[226] "nld_fn000587_0158" "nld_fn000587_0172" "nld_fn000587_0189" "nld_fn000587_0214" "nld_fn000587_0217" "nld_fn000587_0221" "nld_fn000587_0227" "nld_fn000587_0233" "nld_fn000587_0236"
[235] "nld_fn000587_0241" "nld_fn000587_0249" "nld_fn000587_0262" "nld_fn000587_0262" "nld_fn000587_0267" "nld_fn000587_0277" "nld_fn000587_0293" "nld_fn000587_0329" "nld_fn000587_0347"
[244] "nld_fn000587_0356" "nld_fn000587_0358" "nld_fn000587_0364" "nld_fn000587_0365" "nld_fn000587_0368" "nld_fn000587_0373" "nld_fn000587_0394" "nld_fn000587_0401" "nld_fn000587_0401"
[253] "nld_fn000587_0432" "nld_fn000594_0068" "nld_fn000594_0093" "nld_fn000594_0136" "nld_fn000674_0002" "nld_fn000674_0012" "nld_fn000674_0036" "nld_fn000674_0063" "nld_fn000674_0067"
[262] "nld_fn000674_0075" "nld_fn000674_0085" "nld_fn000674_0103" "nld_fn000674_0192" "nld_fn000674_0211" "nld_fn000674_0307" "nld_fn000674_0323" "nld_fn000674_0329" "nld_fn000674_0339"
[271] "nld_fn000674_0342" "nld_fn000674_0386"

# Create a version for analyzing individual words - exclude empty and unclear words
dutch.corpus.pos.data.frame.wordtimes.words = subset(dutch.corpus.pos.data.frame.wordtimes,subset=!dutch.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(dutch.corpus.pos.data.frame.wordtimes$word.id[dutch.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(dutch.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 39720

dutch.corpus.pos.data.frame.wordtimes.words = subset(dutch.corpus.pos.data.frame.wordtimes.words,subset=!dutch.corpus.pos.data.frame.wordtimes.words$word.id %in% as.vector(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$word.id[grepl("xx+", dutch.corpus.pos.data.frame.wordtimes.words$word)])))

length(unique(dutch.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 39448


## English

length(unique(english.corpus.pos.data.frame$word.id))
[1] 56138

english.corpus.pos.data.frame.excluded = english.corpus.pos.data.frame

length(unique(english.corpus.pos.data.frame.excluded$word.id))
[1] 56138

english.corpus.pos.data.frame.wordtimes = english.corpus.pos.data.frame.excluded

length(unique(english.corpus.pos.data.frame.wordtimes$word.id))
[1] 56138

# Create a version for analyzing individual words - exclude empty and unclear words
english.corpus.pos.data.frame.wordtimes.words = subset(english.corpus.pos.data.frame.wordtimes,subset=!english.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(english.corpus.pos.data.frame.wordtimes$word.id[english.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(english.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 56136

english.corpus.pos.data.frame.wordtimes.words = subset(english.corpus.pos.data.frame.wordtimes.words,subset=!english.corpus.pos.data.frame.wordtimes.words$word.id %in% as.vector(na.omit(english.corpus.pos.data.frame.wordtimes.words$word.id[grepl("xx+", english.corpus.pos.data.frame.wordtimes.words$word)])))

length(unique(english.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 56136


## Even

length(unique(even.corpus.pos.data.frame$word.id))
[1] 41701

# Look for researchers
table(even.corpus.pos.data.frame$ELANParticipant)

        AAK         AAS         AEK         AEN         AVK         AVZ         AXK          BP    children     comment          EE         EKK         IDB         INK         IVK 
       1865        1250        1209         922        1315        1664        6364        1884           2         147          68         658        2729         442        4886 
        JPZ         KKK         KNK         LAT         LNZ          MK         MKK          MN          NA         NAS         NEN         NPZ     NPZ IVK NPZ IVK LNZ          OS 
        346        4068         154        3623          36         291        2351         572         330        2780          13         102           3         296         670 
        PDN         RDA          rh         SEN          SK         SPK         TDA         TPK         TVK         VAK         VNZ         XAK         ZAS          ZZ 
       4515       13447          81        1166        1352        1442           6        1777        1845          23        1134        1224        8378         345 

# Exclude BP=Brigitte, NA=Natasha, rh=reindeer herders, EE=only Russian, XAK, and comment
even.corpus.pos.data.frame.excluded = subset(even.corpus.pos.data.frame,subset=!even.corpus.pos.data.frame$ELANParticipant %in% c("BP","NA","rh","EE","XAK","comment","children"))

length(unique(even.corpus.pos.data.frame.excluded$word.id))
[1] 38972

# Exclude code-switching
table(even.corpus.pos.data.frame$lg)
      
77775 

length(unique(even.corpus.pos.data.frame.excluded$word.id))
[1] 38972

# Excludes songs and semi-speakers
even.exclude.always = c("3_women_3_songs_07Aug.txt","Kejmetinova_XA_various_07Aug.txt","Krivoshapkin_SP_oxota_07Aug.txt","Stepanova_ZA_song_Lamutskogo_07Aug.txt","Stepanova_ZA_song_ujamkan_07Aug.txt","Zaxarov_AV_song_07Aug.txt")

even.corpus.pos.data.frame.excluded = subset(even.corpus.pos.data.frame.excluded,subset=!even.corpus.pos.data.frame.excluded$ntvr_file %in% even.exclude.always)

length(unique(even.corpus.pos.data.frame.excluded$word.id))
[1] 37775

# Exclude empty annotation units
even.corpus.pos.data.frame.excluded$ntvr_ref[even.corpus.pos.data.frame.excluded$words_per_record == 0]
character(0)

even.corpus.pos.data.frame.excluded = subset(even.corpus.pos.data.frame.excluded,subset=!even.corpus.pos.data.frame.excluded$ntvr_ref %in% even.corpus.pos.data.frame.excluded$ntvr_ref[even.corpus.pos.data.frame.excluded$words_per_record == 0])

length(unique(even.corpus.pos.data.frame.excluded$word.id))
[1] 37775

# Omit records without morphological annotation
unique(even.corpus.pos.data.frame.excluded$ntvr_ref[is.na(even.corpus.pos.data.frame.excluded$morpheme.id)])
  [1] "eve_ARD_intro_stado_07Aug_0004"            "eve_ARD_intro_stado_07Aug_0004"            "eve_ARD_intro_stado_07Aug_0004"         
  [4] "eve_BID_traditions_07Aug_0038"             "eve_BID_traditions_07Aug_0038"             "eve_BID_traditions_07Aug_0038"            
  [7] "eve_BID_traditions_07Aug_0079"             "eve_BID_traditions_07Aug_0079"             "eve_BID_traditions_07Aug_0079"            
 [10] "eve_BID_traditions_07Aug_0079"             "eve_BID_traditions_07Aug_0079"             "eve_BID_traditions_07Aug_0079"            
 [13] "eve_BID_traditions_07Aug_0100"             "eve_BID_traditions_07Aug_0100"             "eve_BID_traditions_07Aug_0100"            
 [16] "eve_BID_traditions_07Aug_0100"             "eve_BID_traditions_07Aug_0100"             "eve_BID_traditions_07Aug_0100"            
 [19] "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"            
 [22] "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"            
 [25] "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"            
 [28] "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"            
 [31] "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0108"            
 [34] "eve_BID_traditions_07Aug_0108"             "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"            
 [37] "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"            
 [40] "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"            
 [43] "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"            
 [46] "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"            
 [49] "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"            
 [52] "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"            
 [55] "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0110"             "eve_BID_traditions_07Aug_0111"            
 [58] "eve_BID_traditions_07Aug_0111"             "eve_BID_traditions_07Aug_0111"             "eve_BID_traditions_07Aug_0111"            
 [61] "eve_BID_traditions_07Aug_0111"             "eve_BID_traditions_07Aug_0111"             "eve_BID_traditions_07Aug_0111"            
 [64] "eve_BID_traditions_07Aug_0111"             "eve_BID_traditions_07Aug_0111"             "eve_BID_traditions_07Aug_0111"            
 [67] "eve_BID_traditions_07Aug_0111"             "eve_BID_traditions_07Aug_0112"             "eve_BID_traditions_07Aug_0112"            
 [70] "eve_BID_traditions_07Aug_0112"             "eve_BID_traditions_07Aug_0112"             "eve_BID_traditions_07Aug_0112"            
 [73] "eve_BID_traditions_07Aug_0112"             "eve_BID_traditions_07Aug_0112"             "eve_BID_traditions_07Aug_0112"            
 [76] "eve_BID_traditions_07Aug_0112"             "eve_BID_traditions_07Aug_0112"             "eve_BID_traditions_07Aug_0112"            
 [79] "eve_BID_traditions_07Aug_0113"             "eve_BID_traditions_07Aug_0113"             "eve_BID_traditions_07Aug_0113"            
 [82] "eve_BID_traditions_07Aug_0113"             "eve_BID_traditions_07Aug_0113"             "eve_BID_traditions_07Aug_0113"            
 [85] "eve_BID_traditions_07Aug_0114"             "eve_BID_traditions_07Aug_0114"             "eve_BID_traditions_07Aug_0114"            
 [88] "eve_BID_traditions_07Aug_0114"             "eve_BID_traditions_07Aug_0114"             "eve_BID_traditions_07Aug_0114"            
 [91] "eve_BID_traditions_07Aug_0114"             "eve_BID_traditions_07Aug_0114"             "eve_BID_traditions_07Aug_0114"            
 [94] "eve_BID_traditions_07Aug_0115"             "eve_BID_traditions_07Aug_0115"             "eve_BID_traditions_07Aug_0115"            
 [97] "eve_BID_traditions_07Aug_0115"             "eve_BID_traditions_07Aug_0115"             "eve_BID_traditions_07Aug_0115"            
[100] "eve_BID_traditions_07Aug_0115"             "eve_BID_traditions_07Aug_0115"             "eve_BID_traditions_07Aug_0115"            
[103] "eve_BID_traditions_07Aug_0115"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[106] "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[109] "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[112] "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[115] "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[118] "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[121] "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[124] "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[127] "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"             "eve_BID_traditions_07Aug_0130"            
[130] "eve_KAA_headmistress_07Aug_0080"           "eve_KAA_headmistress_07Aug_0080"           "eve_KAA_headmistress_07Aug_0080"      
[133] "eve_KAA_headmistress_07Aug_0080"           "eve_KAA_headmistress_07Aug_0080"           "eve_KAE_childhood_07Aug_0027"       
[136] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[139] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[142] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[145] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[148] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[151] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[154] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[157] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[160] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[163] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[166] "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"              "eve_KAE_childhood_07Aug_0027"       
[169] "eve_KAE_childhood_07Aug_0027"              "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0002"           
[172] "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0002"           
[175] "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0002"           
[178] "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0002"           
[181] "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0002"                  "eve_KAX_1930s_07Aug_0004"           
[184] "eve_KAX_1930s_07Aug_0004"                  "eve_KAX_1930s_07Aug_0004"                  "eve_KAX_1930s_07Aug_0004"           
[187] "eve_KAX_1930s_07Aug_0004"                  "eve_KAX_1930s_07Aug_0004"                  "eve_KAX_1930s_07Aug_0004"           
[190] "eve_KAX_1930s_07Aug_0004"                  "eve_KAX_1930s_07Aug_0004"                  "eve_KAX_1930s_07Aug_0005"           
[193] "eve_KAX_1930s_07Aug_0005"                  "eve_KAX_1930s_07Aug_0005"                  "eve_KAX_1930s_07Aug_0006"           
[196] "eve_KAX_1930s_07Aug_0006"                  "eve_KAX_1930s_07Aug_0007"                  "eve_KAX_1930s_07Aug_0007"           
[199] "eve_KAX_1930s_07Aug_0007"                  "eve_KAX_1930s_07Aug_0007"                  "eve_KAX_1930s_07Aug_0008"           
[202] "eve_KAX_1930s_07Aug_0164"                  "eve_KAX_1930s_07Aug_0164"                  "eve_KAX_1930s_07Aug_0164"           
[205] "eve_KAX_1930s_07Aug_0164"                  "eve_KAX_1930s_07Aug_0164"                  "eve_KAX_1930s_07Aug_0164"           
[208] "eve_KAX_1930s_07Aug_0164"                  "eve_KAX_Seb_history1_07Aug_0062"           "eve_KAX_Seb_history1_07Aug_0062"    
[211] "eve_KAX_Seb_history1_07Aug_0110"           "eve_KAX_Seb_history1_07Aug_0110"           "eve_KAX_Seb_history1_07Aug_0110"    
[214] "eve_KAX_Seb_history1_07Aug_0110"           "eve_KAX_svatovstvo_07Aug_0004"             "eve_KAX_svatovstvo_07Aug_0004"      
[217] "eve_KAX_svatovstvo_07Aug_0004"             "eve_RDA_TPK_birth_with_even_07Aug_0011"    "eve_RDA_TPK_birth_with_even_07Aug_0011"          
[220] "eve_RDA_TPK_birth_with_even_07Aug_0011"    "eve_RDA_TPK_death_07Aug_0193"              "eve_RDA_TPK_death_07Aug_0193"                    
[223] "eve_RDA_TPK_death_07Aug_0193"              "eve_RDA_TPK_death_07Aug_0193"              "eve_RDA_TPK_death_07Aug_0193"                    
[226] "eve_RDA_TPK_names_origins_07Aug_0049"      "eve_RDA_TPK_names_origins_07Aug_0049"      "eve_RDA_TPK_names_origins_07Aug_0049"            
[229] "eve_RDA_TPK_names_origins_07Aug_0049"      "eve_stado#10_NM_life_stado_07Aug_0024"     "eve_stado#10_NM_life_stado_07Aug_0024"
[232] "eve_stado#10_NM_life_stado_07Aug_0024"     "eve_stado#10_NM_life_stado_07Aug_0024"     "eve_stado#10_NM_life_stado_07Aug_0024"
[235] "eve_stado#10_NSE_poems_07Aug_0001"         "eve_stado#10_NSE_poems_07Aug_0001"         "eve_stado#10_NSE_poems_07Aug_0003"        
[238] "eve_stado#10_NSE_poems_07Aug_0006"         "eve_stado#10_NSE_poems_07Aug_0006"         "eve_stado#10_NSE_poems_07Aug_0006"        
[241] "eve_stado#10_NSE_poems_07Aug_0010"         "eve_stado#10_NSE_poems_07Aug_0010"         "eve_stado#10_NSE_poems_07Aug_0010"        
[244] "eve_stado#9_kochevka_07Aug_0010"           "eve_stado#9_kochevka_07Aug_0010"           "eve_stado#9_kochevka_07Aug_0010"                 
[247] "eve_stado#9_kochevka_07Aug_0010"           "eve_stado#9_kochevka_07Aug_0010"           "eve_stado#9_kochevka_07Aug_0010"                 
[250] "eve_stado#9_kochevka_07Aug_0012"           "eve_stado#9_kochevka_07Aug_0012"           "eve_stado#9_learning_olenevod_07Aug_0003"        
[253] "eve_SNA_kochevaja_shkola_07Aug_0144"       "eve_SNA_kochevaja_shkola_07Aug_0145"       "eve_SNA_kochevaja_shkola_07Aug_0146"    
[256] "eve_SZA_jubki_Aniwrin_07Aug_0015"          "eve_SZA_jubki_Aniwrin_07Aug_0015"          "eve_SZA_jubki_Aniwrin_07Aug_0015"       

even.corpus.pos.data.frame.excluded = subset(even.corpus.pos.data.frame.excluded,subset=!even.corpus.pos.data.frame.excluded$ntvr_ref %in% even.corpus.pos.data.frame.excluded$ntvr_ref[is.na(even.corpus.pos.data.frame.excluded$morpheme.id)])

length(unique(even.corpus.pos.data.frame.excluded$word.id))
[1] 37517

even.corpus.pos.data.frame.wordtimes = even.corpus.pos.data.frame.excluded

length(unique(even.corpus.pos.data.frame.wordtimes$word.id))
[1] 37517

# [stammers] etc.
unique(even.corpus.pos.data.frame.wordtimes$word[grepl("\\[|\\]",even.corpus.pos.data.frame.wordtimes$word)])
 [1] "elle[n]"           "mindu[k]..."       "[eb]it."           "nọːdawrara[p]."    "goːn[em]."         "[stammers]"        "bekeb[ben]"        "tor[du],"          "lestnice[li]"     
[10] "tolinu[k]"         "gọlaŋča[mị].."     "Čajnịkča[n]"       "torewreče[l],"     "nụ[g].."           "bọl[la]"           "[nemketniken]."    "del[bi]"           "[Del]bi"          
[19] "egdʒel[buridʒi],"  "mịawandụla[w]"     "[Tarịt]"           "[Tar]"             "ŋeːlilgere[p]"     "ịsta[la]"          "ńulgeweːčed[dep]," "ieltenče[len]"     "Mu[t]"            
[28] "dʒugu[dun],"       "[indiscernible]"   "ụntịwa[n],"        "[höp]?"            "boholektu[k],"     "[voice"            "background]"       "aŋŋanị[dụ]"        "tarị[t]"          
[37] "[goːmi]"           "gerbutti[t]."      "họːj[a]"           "Ịstada[dụ]"        "[laughter]"        "biwren[ni],"       "Beje[t]"           "oskuola[du]"       "ịaggar[an],"      
[46] "awdakkara[r]."    

# Create a version for analyzing individual words - exclude empty and unclear words
even.corpus.pos.data.frame.wordtimes.words = subset(even.corpus.pos.data.frame.wordtimes,subset=!even.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(even.corpus.pos.data.frame.wordtimes$word.id[even.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(even.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 37485

even.corpus.pos.data.frame.wordtimes.words = subset(even.corpus.pos.data.frame.wordtimes.words,subset=!even.corpus.pos.data.frame.wordtimes.words$word.id %in% as.vector(na.omit(even.corpus.pos.data.frame.wordtimes.words$word.id[grepl("(xx+|XX+|\\[|\\])", even.corpus.pos.data.frame.wordtimes.words$word)])))

length(unique(even.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 37394


## Hoocąk

length(unique(hoocak.corpus.pos.data.frame$word.id))
[1] 23420

# Look for researchers
table(hoocak.corpus.pos.data.frame$ELANParticipant)

    FS12      FS5      FS6      FS7      FS9     FS99       IH      MS1     MS10     MS12     MS13     MS15     MS19      MS2     MS23     MS27     MS28     MS30     MS31     MS32 
     439     5060      275      337      465      682        3     1681      423     1297      168       65      834      583     1595     1071     1059     3113     2078     8189 
     MS4      MS7     MS98     MS99 UNKNOWN1 UNKNOWN2 UNKNOWN3 UNKNOWN4 UNKNOWN5 UNKNOWN6 UNKNOWN7 
    1939     2621     2955     2084        4       14       11     2020      310        3        9 

# Exclude IH
hoocak.corpus.pos.data.frame.excluded = subset(hoocak.corpus.pos.data.frame,subset=!hoocak.corpus.pos.data.frame$ELANParticipant %in% c("IH"))

length(unique(hoocak.corpus.pos.data.frame.excluded$word.id))
[1] 23417

# Code-Switching
# Exclude annotation units with more than 50% English words
hoocak.corpus.pos.data.frame.excluded = subset(hoocak.corpus.pos.data.frame.excluded,subset=hoocak.corpus.pos.data.frame.excluded$code_switching <= 0.5)

length(unique(hoocak.corpus.pos.data.frame.excluded$word.id))
[1] 23281

# Exclude ritual language and songs
hoocak.exclude.always = unique(hoocak.corpus.pos.data.frame.excluded$ntvr_file[hoocak.corpus.pos.data.frame.excluded$plannedness=="0" | is.na(hoocak.corpus.pos.data.frame.excluded$plannedness)])
hoocak.exclude.always
[1] "Saved_By_Grace.txt"

hoocak.corpus.pos.data.frame.excluded = subset(hoocak.corpus.pos.data.frame.excluded,subset=!hoocak.corpus.pos.data.frame.excluded$ntvr_file %in% hoocak.exclude.always)

length(unique(hoocak.corpus.pos.data.frame.excluded$word.id))
[1] 23198

# Exclude annotation units with wrong annotation / transcription
hoocak.annotation_unit.blacklist = c("win_caa_worak_0029", "win_gilbert_0017", "win_giving_directions_0059")

hoocak.corpus.pos.data.frame.excluded = subset(hoocak.corpus.pos.data.frame.excluded,subset=!hoocak.corpus.pos.data.frame.excluded$ntvr_ref %in% hoocak.annotation_unit.blacklist)

length(unique(hoocak.corpus.pos.data.frame.excluded$word.id))
[1] 23195

# Exclude empty annotation units
hoocak.corpus.pos.data.frame.excluded$ntvr_ref[hoocak.corpus.pos.data.frame.excluded$words_per_record == 0]
character(0)

hoocak.corpus.pos.data.frame.excluded = subset(hoocak.corpus.pos.data.frame.excluded,subset=!hoocak.corpus.pos.data.frame.excluded$ntvr_ref %in% hoocak.corpus.pos.data.frame.excluded$ntvr_ref[hoocak.corpus.pos.data.frame.excluded$words_per_record == 0])

length(unique(hoocak.corpus.pos.data.frame.excluded$word.id))
[1] 23195

# Omit records without morphological annotation
hoocak.corpus.pos.data.frame.excluded$ntvr_ref[is.na(hoocak.corpus.pos.data.frame.excluded$morpheme.id)]
character(0)

hoocak.corpus.pos.data.frame.excluded = subset(hoocak.corpus.pos.data.frame.excluded,subset=!hoocak.corpus.pos.data.frame.excluded$ntvr_ref %in% hoocak.corpus.pos.data.frame.excluded$ntvr_ref[is.na(hoocak.corpus.pos.data.frame.excluded$morpheme.id)])

length(unique(hoocak.corpus.pos.data.frame.excluded$word.id))
[1] 23195


hoocak.exclude.timeseries = c()

hoocak.corpus.pos.data.frame.wordtimes = subset(hoocak.corpus.pos.data.frame.excluded,subset=!hoocak.corpus.pos.data.frame.excluded$ntvr_file %in% hoocak.exclude.timeseries)

length(unique(hoocak.corpus.pos.data.frame.wordtimes$word.id))
[1] 23195

# Create a version for analyzing individual words - exclude empty and unclear words
hoocak.corpus.pos.data.frame.wordtimes.words = subset(hoocak.corpus.pos.data.frame.wordtimes,subset=!hoocak.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(hoocak.corpus.pos.data.frame.wordtimes$word.id[hoocak.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(hoocak.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 23181


## Nǁng

length(unique(nuu.corpus.pos.data.frame$word.id))
[1] 31760

# Look for researchers ER, GU, SI, visitor, WI
table(nuu.corpus.pos.data.frame$ELANParticipant)

      ?       B       C       D       E      ER       F       G      GU       I      NA      SI visitor      WI 
      8   12783    7057     581    3516     310    3631    5623      47    2169      43      22       1       6 

# Also exclude ? and NA according to e-mail from Alena (18.06.2014)
nuu.corpus.pos.data.frame.excluded = subset(nuu.corpus.pos.data.frame,subset=!nuu.corpus.pos.data.frame$ELANParticipant %in% c("ER","GU","SI","visitor","WI","?","NA"))

length(unique(nuu.corpus.pos.data.frame.excluded$word.id))
[1] 31352

# Code-Switching
# Exclude annotation units with more than 50% Afrikaans or English words
nuu.corpus.pos.data.frame.excluded = subset(nuu.corpus.pos.data.frame.excluded,subset=nuu.corpus.pos.data.frame.excluded$code_switching <= 0.5)

length(unique(nuu.corpus.pos.data.frame.excluded$word.id))
[1] 26730

# No songs or ritual speech
unique(nuu.corpus.pos.data.frame.excluded$ntvr_file[nuu.corpus.pos.data.frame.excluded$plannedness=="0" | is.na(nuu.corpus.pos.data.frame.excluded$plannedness)])
character(0)

# Exclude annotation units with wrong annotation / transcription
nuu.annotation_unit.blacklist = c("ngh_NC080903-01_A_0355", "ngh_NM071109-01_A_till_270_0174")

nuu.corpus.pos.data.frame.excluded = subset(nuu.corpus.pos.data.frame.excluded, subset=!nuu.corpus.pos.data.frame.excluded$ntvr_ref %in% nuu.annotation_unit.blacklist)

length(unique(nuu.corpus.pos.data.frame.excluded$word.id))
[1] 26727

# Omit empty records
nuu.corpus.pos.data.frame.excluded$ntvr_ref[nuu.corpus.pos.data.frame.excluded$words_per_record == 0]
character(0)

nuu.corpus.pos.data.frame.excluded = subset(nuu.corpus.pos.data.frame.excluded,subset=!nuu.corpus.pos.data.frame.excluded$ntvr_ref %in% nuu.corpus.pos.data.frame.excluded$ntvr_ref[nuu.corpus.pos.data.frame.excluded$words_per_record == 0])

length(unique(nuu.corpus.pos.data.frame.excluded$word.id))
[1] 26727

# Omit records without morphological annotation
nuu.corpus.pos.data.frame.excluded$ntvr_ref[is.na(nuu.corpus.pos.data.frame.excluded$morpheme.id)]
character(0)

nuu.corpus.pos.data.frame.excluded = subset(nuu.corpus.pos.data.frame.excluded,subset=!nuu.corpus.pos.data.frame.excluded$ntvr_ref %in% nuu.corpus.pos.data.frame.excluded$ntvr_ref[is.na(nuu.corpus.pos.data.frame.excluded$morpheme.id)])

length(unique(nuu.corpus.pos.data.frame.excluded$word.id))
[1] 26727

nuu.corpus.pos.data.frame.wordtimes = nuu.corpus.pos.data.frame.excluded

length(unique(nuu.corpus.pos.data.frame.wordtimes$word.id))
[1] 26727

# Create a version for analyzing individual words - exclude empty and unclear words
nuu.corpus.pos.data.frame.wordtimes.words = subset(nuu.corpus.pos.data.frame.wordtimes,subset=!nuu.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(nuu.corpus.pos.data.frame.wordtimes$word.id[nuu.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(nuu.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 25850


## Texistepec Popoluca

length(unique(popoluca.corpus.pos.data.frame$word.id))
[1] 24811

# Look for researchers
table(popoluca.corpus.pos.data.frame$ELANParticipant)

  SP1 
46629 

# No information about code-switching contained in corpus, relatively rare

# No songs or ritual speech

# Blacklist for incorrectly annotated / transcribed annotation units
popoluca.annotation_unit.blacklist = c("Blancaflor 043", "Blancaflor 143", "Blancaflor 160", "Blancaflor 193", "Blancaflor 218", "Blancaflor 361",
"Blancaflor 427", "Blancaflor 506", "Blancaflor 549", "Blancaflor 583", "Blancaflor 593", "Blancaflor 615",
"Blancaflor 616", "Blancaflor 694", "Blancaflor 715", "Blancaflor 732", "Blancaflor 771",
"Blancaflor 802", "Blancaflor 819", "Blancaflor 871", "Blancaflor 881", "Blancaflor 922", "Blancaflor 931",
"Blancaflor 996", "Blancaflor 997", "Blancaflor 998", "Blancaflor 999", "Blancaflor 1 000",
"Blancaflor 1 001", "Blancaflor 1 027", "Blancaflor 1 061", "Blancaflor 1 068", "Blancaflor 1 071", "Blancaflor 1 074", "Blancaflor 1 109",
"Blancaflor 1 119", "Blancaflor 1 166", "Blancaflor 1 174", "Blancaflor 1 184", "Blancaflor 1 185",
"Blancaflor 1 187", "Blancaflor 1 188", "Blancaflor 1 219", "Blancaflor 1 229", "Blancaflor 1 231",
"Juan Flojo 000", "Juan Flojo 1 205", "Juan Flojo 1 206", "Juan Flojo 1 207", "Juan Flojo 1 208", "Juan Flojo 1 209",
"Juan Flojo 1 210", "Juan Flojo 1 211", "Juan Flojo 1 212", "Juan Flojo 1 213", "Jesus 000", "Juan Ratoncito 000", "Chichimeca 000",
"Muchacha Floja 000", "Pepito 000", "Pepito 001", "Pepito 003", "Pepito 014")

popoluca.corpus.pos.data.frame.excluded = subset(popoluca.corpus.pos.data.frame,subset=!popoluca.corpus.pos.data.frame$orig_ref %in% popoluca.annotation_unit.blacklist)

length(unique(popoluca.corpus.pos.data.frame.excluded$word.id))
[1] 24526

# Omit empty records
popoluca.corpus.pos.data.frame.excluded$ntvr_ref[popoluca.corpus.pos.data.frame.excluded$words_per_record == 0]
character(0)

popoluca.corpus.pos.data.frame.excluded = subset(popoluca.corpus.pos.data.frame.excluded,subset=!popoluca.corpus.pos.data.frame.excluded$ntvr_ref %in% popoluca.corpus.pos.data.frame.excluded$ntvr_ref[popoluca.corpus.pos.data.frame.excluded$words_per_record == 0])

length(unique(popoluca.corpus.pos.data.frame.excluded$word.id))
[1] 24526

# Omit records without morphological annotation
popoluca.corpus.pos.data.frame.excluded$ntvr_ref[is.na(popoluca.corpus.pos.data.frame.excluded$morpheme.id)]
character(0)

popoluca.corpus.pos.data.frame.excluded = subset(popoluca.corpus.pos.data.frame.excluded,subset=!popoluca.corpus.pos.data.frame.excluded$ntvr_ref %in% popoluca.corpus.pos.data.frame.excluded$ntvr_ref[is.na(popoluca.corpus.pos.data.frame.excluded$morpheme.id)])

length(unique(popoluca.corpus.pos.data.frame.excluded$word.id))
[1] 24526

# Throw out sessions without wordtimes
popoluca.exclude.timeseries = c("JesusQuevedo.txt","LosGatos.txt","NicolasitoyNicolason.txt")

popoluca.corpus.pos.data.frame.wordtimes = subset(popoluca.corpus.pos.data.frame.excluded,subset=!popoluca.corpus.pos.data.frame.excluded$ntvr_file %in% popoluca.exclude.timeseries)

length(unique(popoluca.corpus.pos.data.frame.wordtimes$word.id))
[1] 21321

# Create a version for analyzing individual words - exclude empty and unclear words
popoluca.corpus.pos.data.frame.wordtimes.words = subset(popoluca.corpus.pos.data.frame.wordtimes,subset=!popoluca.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(popoluca.corpus.pos.data.frame.wordtimes$word.id[popoluca.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(popoluca.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 21321


## Sakha

length(unique(sakha.corpus.pos.data.frame$word.id))
[1] 31784

# Look for researchers
table(sakha.corpus.pos.data.frame$ELANParticipant)

          AAA           AGM          AICh          APJu           ARR           ASP            BP       comment           EJS            EM           EPE           ESY granddaughter 
         1787          2731          1530           302          4032          2498           364           202          1986           656             8          2466            37 
          MAN           MEI           OGA           PIB           PIE           PJI           PNL           PVP           REX     secretary           smb            VB           XKM 
          827           637            23          2313           683          5959          3653          2855          5891            63           189            34          3814 
          XLE 
         7561 

# Exclude BP=Brigitte and comment
sakha.corpus.pos.data.frame.excluded = subset(sakha.corpus.pos.data.frame,subset=sakha.corpus.pos.data.frame$ELANParticipant!="BP" & sakha.corpus.pos.data.frame$ELANParticipant!="comment")

length(unique(sakha.corpus.pos.data.frame.excluded$word.id))
[1] 31278

# No information about code-switching contained in corpus, relatively rare

# Exclude songs and ritual speech
unique(sakha.corpus.pos.data.frame.excluded$ntvr_file[sakha.corpus.pos.data.frame.excluded$plannedness=="0" | is.na(sakha.corpus.pos.data.frame.excluded$plannedness)])
character(0)

# Blacklist of incorrectly annotated / transcribed annotation units
sakha.annotation_unit.blacklist = c("sah_Krusuporka_09Aug_0107")

sakha.corpus.pos.data.frame.excluded = subset(sakha.corpus.pos.data.frame.excluded, subset=!sakha.corpus.pos.data.frame.excluded$ntvr_ref %in% sakha.annotation_unit.blacklist)

length(unique(sakha.corpus.pos.data.frame.excluded$word.id))
[1] 31278

sakha.corpus.pos.data.frame.excluded$ntvr_ref[sakha.corpus.pos.data.frame.excluded$words_per_record == 0]
character(0)

# Exclude empty annotation units
sakha.corpus.pos.data.frame.excluded = subset(sakha.corpus.pos.data.frame.excluded,subset=!sakha.corpus.pos.data.frame.excluded$ntvr_ref %in% sakha.corpus.pos.data.frame.excluded$ntvr_ref[sakha.corpus.pos.data.frame.excluded$words_per_record == 0])

length(unique(sakha.corpus.pos.data.frame.excluded$word.id))
[1] 31278

# Omit records without morphological annotation
sakha.corpus.pos.data.frame.excluded$ntvr_ref[is.na(sakha.corpus.pos.data.frame.excluded$morpheme.id)]
[1] "sah_MA_09Aug_0097" "sah_MA_09Aug_0097" "sah_MA_09Aug_0099" "sah_MA_09Aug_0099" "sah_MA_09Aug_0102" "sah_MA_09Aug_0102"

sakha.corpus.pos.data.frame.excluded = subset(sakha.corpus.pos.data.frame.excluded,subset=!sakha.corpus.pos.data.frame.excluded$ntvr_ref %in% sakha.corpus.pos.data.frame.excluded$ntvr_ref[is.na(sakha.corpus.pos.data.frame.excluded$morpheme.id)])

length(unique(sakha.corpus.pos.data.frame.excluded$word.id))
[1] 31272

sakha.corpus.pos.data.frame.wordtimes = sakha.corpus.pos.data.frame.excluded

length(unique(sakha.corpus.pos.data.frame.wordtimes$word.id))
[1] 31272

# Create a version for analyzing individual words - exclude empty and unclear words
sakha.corpus.pos.data.frame.wordtimes.words = subset(sakha.corpus.pos.data.frame.wordtimes,subset=!sakha.corpus.pos.data.frame.wordtimes$word.id %in% as.vector(na.omit(sakha.corpus.pos.data.frame.wordtimes$word.id[sakha.corpus.pos.data.frame.wordtimes$chars_per_word==0])))

length(unique(sakha.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 31203

sakha.corpus.pos.data.frame.wordtimes.words = subset(sakha.corpus.pos.data.frame.wordtimes.words,subset=!sakha.corpus.pos.data.frame.wordtimes.words$word.id %in% as.vector(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$word.id[grepl("(xx+|XX+|\\[|\\])", sakha.corpus.pos.data.frame.wordtimes.words$word)])))

length(unique(sakha.corpus.pos.data.frame.wordtimes.words$word.id))
[1] 31139


### Make speaker and session IDs unique

# Make speakers unique
baure.corpus.pos.data.frame$ELANParticipant = paste(baure.corpus.pos.data.frame$ntvr_language,baure.corpus.pos.data.frame$ELANParticipant,sep=" ")
bora.corpus.pos.data.frame$ELANParticipant = paste(bora.corpus.pos.data.frame$ntvr_language,bora.corpus.pos.data.frame$ELANParticipant,sep=" ")
chintang.corpus.pos.data.frame$ELANParticipant = paste(chintang.corpus.pos.data.frame$ntvr_language,chintang.corpus.pos.data.frame$ELANParticipant,sep=" ")
dutch.corpus.pos.data.frame$ELANParticipant = paste(dutch.corpus.pos.data.frame$ntvr_language,dutch.corpus.pos.data.frame$ELANParticipant,sep=" ")
english.corpus.pos.data.frame$ELANParticipant = paste(english.corpus.pos.data.frame$ntvr_language,english.corpus.pos.data.frame$ELANParticipant,sep=" ")
even.corpus.pos.data.frame$ELANParticipant = paste(even.corpus.pos.data.frame$ntvr_language,even.corpus.pos.data.frame$ELANParticipant,sep=" ")
hoocak.corpus.pos.data.frame$ELANParticipant = paste(hoocak.corpus.pos.data.frame$ntvr_language,hoocak.corpus.pos.data.frame$ELANParticipant,sep=" ")
nuu.corpus.pos.data.frame$ELANParticipant = paste(nuu.corpus.pos.data.frame$ntvr_language,nuu.corpus.pos.data.frame$ELANParticipant,sep=" ")
popoluca.corpus.pos.data.frame$ELANParticipant = paste(popoluca.corpus.pos.data.frame$ntvr_language,popoluca.corpus.pos.data.frame$ELANParticipant,sep=" ")
sakha.corpus.pos.data.frame$ELANParticipant = paste(sakha.corpus.pos.data.frame$ntvr_language,sakha.corpus.pos.data.frame$ELANParticipant,sep=" ")

baure.corpus.pos.data.frame.excluded$ELANParticipant = paste(baure.corpus.pos.data.frame.excluded$ntvr_language,baure.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
bora.corpus.pos.data.frame.excluded$ELANParticipant = paste(bora.corpus.pos.data.frame.excluded$ntvr_language,bora.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
chintang.corpus.pos.data.frame.excluded$ELANParticipant = paste(chintang.corpus.pos.data.frame.excluded$ntvr_language,chintang.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
dutch.corpus.pos.data.frame.excluded$ELANParticipant = paste(dutch.corpus.pos.data.frame.excluded$ntvr_language,dutch.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
english.corpus.pos.data.frame.excluded$ELANParticipant = paste(english.corpus.pos.data.frame.excluded$ntvr_language,english.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
even.corpus.pos.data.frame.excluded$ELANParticipant = paste(even.corpus.pos.data.frame.excluded$ntvr_language,even.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
hoocak.corpus.pos.data.frame.excluded$ELANParticipant = paste(hoocak.corpus.pos.data.frame.excluded$ntvr_language,hoocak.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
nuu.corpus.pos.data.frame.excluded$ELANParticipant = paste(nuu.corpus.pos.data.frame.excluded$ntvr_language,nuu.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
popoluca.corpus.pos.data.frame.excluded$ELANParticipant = paste(popoluca.corpus.pos.data.frame.excluded$ntvr_language,popoluca.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")
sakha.corpus.pos.data.frame.excluded$ELANParticipant = paste(sakha.corpus.pos.data.frame.excluded$ntvr_language,sakha.corpus.pos.data.frame.excluded$ELANParticipant,sep=" ")

baure.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(baure.corpus.pos.data.frame.wordtimes$ntvr_language,baure.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
bora.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(bora.corpus.pos.data.frame.wordtimes$ntvr_language,bora.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
chintang.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(chintang.corpus.pos.data.frame.wordtimes$ntvr_language,chintang.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
dutch.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(dutch.corpus.pos.data.frame.wordtimes$ntvr_language,dutch.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
english.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(english.corpus.pos.data.frame.wordtimes$ntvr_language,english.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
even.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(even.corpus.pos.data.frame.wordtimes$ntvr_language,even.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
hoocak.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(hoocak.corpus.pos.data.frame.wordtimes$ntvr_language,hoocak.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
nuu.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(nuu.corpus.pos.data.frame.wordtimes$ntvr_language,nuu.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
popoluca.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(popoluca.corpus.pos.data.frame.wordtimes$ntvr_language,popoluca.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")
sakha.corpus.pos.data.frame.wordtimes$ELANParticipant = paste(sakha.corpus.pos.data.frame.wordtimes$ntvr_language,sakha.corpus.pos.data.frame.wordtimes$ELANParticipant,sep=" ")

baure.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(baure.corpus.pos.data.frame.wordtimes.words$ntvr_language,baure.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
bora.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(bora.corpus.pos.data.frame.wordtimes.words$ntvr_language,bora.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
chintang.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(chintang.corpus.pos.data.frame.wordtimes.words$ntvr_language,chintang.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
dutch.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(dutch.corpus.pos.data.frame.wordtimes.words$ntvr_language,dutch.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
english.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(english.corpus.pos.data.frame.wordtimes.words$ntvr_language,english.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
even.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(even.corpus.pos.data.frame.wordtimes.words$ntvr_language,even.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
hoocak.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(hoocak.corpus.pos.data.frame.wordtimes.words$ntvr_language,hoocak.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
nuu.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(nuu.corpus.pos.data.frame.wordtimes.words$ntvr_language,nuu.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
popoluca.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(popoluca.corpus.pos.data.frame.wordtimes.words$ntvr_language,popoluca.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")
sakha.corpus.pos.data.frame.wordtimes.words$ELANParticipant = paste(sakha.corpus.pos.data.frame.wordtimes.words$ntvr_language,sakha.corpus.pos.data.frame.wordtimes.words$ELANParticipant,sep=" ")


# Make sessions unique
baure.corpus.pos.data.frame$ntvr_file = paste(baure.corpus.pos.data.frame$ntvr_language,baure.corpus.pos.data.frame$ntvr_file,sep=" ")
bora.corpus.pos.data.frame$ntvr_file = paste(bora.corpus.pos.data.frame$ntvr_language,bora.corpus.pos.data.frame$ntvr_file,sep=" ")
chintang.corpus.pos.data.frame$ntvr_file = paste(chintang.corpus.pos.data.frame$ntvr_language,chintang.corpus.pos.data.frame$ntvr_file,sep=" ")
dutch.corpus.pos.data.frame$ntvr_file = paste(dutch.corpus.pos.data.frame$ntvr_language,dutch.corpus.pos.data.frame$ntvr_file,sep=" ")
english.corpus.pos.data.frame$ntvr_file = paste(english.corpus.pos.data.frame$ntvr_language,english.corpus.pos.data.frame$ntvr_file,sep=" ")
even.corpus.pos.data.frame$ntvr_file = paste(even.corpus.pos.data.frame$ntvr_language,even.corpus.pos.data.frame$ntvr_file,sep=" ")
hoocak.corpus.pos.data.frame$ntvr_file = paste(hoocak.corpus.pos.data.frame$ntvr_language,hoocak.corpus.pos.data.frame$ntvr_file,sep=" ")
nuu.corpus.pos.data.frame$ntvr_file = paste(nuu.corpus.pos.data.frame$ntvr_language,nuu.corpus.pos.data.frame$ntvr_file,sep=" ")
popoluca.corpus.pos.data.frame$ntvr_file = paste(popoluca.corpus.pos.data.frame$ntvr_language,popoluca.corpus.pos.data.frame$ntvr_file,sep=" ")
sakha.corpus.pos.data.frame$ntvr_file = paste(sakha.corpus.pos.data.frame$ntvr_language,sakha.corpus.pos.data.frame$ntvr_file,sep=" ")

baure.corpus.pos.data.frame.excluded$ntvr_file = paste(baure.corpus.pos.data.frame.excluded$ntvr_language,baure.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
bora.corpus.pos.data.frame.excluded$ntvr_file = paste(bora.corpus.pos.data.frame.excluded$ntvr_language,bora.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
chintang.corpus.pos.data.frame.excluded$ntvr_file = paste(chintang.corpus.pos.data.frame.excluded$ntvr_language,chintang.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
dutch.corpus.pos.data.frame.excluded$ntvr_file = paste(dutch.corpus.pos.data.frame.excluded$ntvr_language,dutch.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
english.corpus.pos.data.frame.excluded$ntvr_file = paste(english.corpus.pos.data.frame.excluded$ntvr_language,english.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
even.corpus.pos.data.frame.excluded$ntvr_file = paste(even.corpus.pos.data.frame.excluded$ntvr_language,even.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
hoocak.corpus.pos.data.frame.excluded$ntvr_file = paste(hoocak.corpus.pos.data.frame.excluded$ntvr_language,hoocak.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
nuu.corpus.pos.data.frame.excluded$ntvr_file = paste(nuu.corpus.pos.data.frame.excluded$ntvr_language,nuu.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
popoluca.corpus.pos.data.frame.excluded$ntvr_file = paste(popoluca.corpus.pos.data.frame.excluded$ntvr_language,popoluca.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")
sakha.corpus.pos.data.frame.excluded$ntvr_file = paste(sakha.corpus.pos.data.frame.excluded$ntvr_language,sakha.corpus.pos.data.frame.excluded$ntvr_file,sep=" ")

baure.corpus.pos.data.frame.wordtimes$ntvr_file = paste(baure.corpus.pos.data.frame.wordtimes$ntvr_language,baure.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
bora.corpus.pos.data.frame.wordtimes$ntvr_file = paste(bora.corpus.pos.data.frame.wordtimes$ntvr_language,bora.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
chintang.corpus.pos.data.frame.wordtimes$ntvr_file = paste(chintang.corpus.pos.data.frame.wordtimes$ntvr_language,chintang.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
dutch.corpus.pos.data.frame.wordtimes$ntvr_file = paste(dutch.corpus.pos.data.frame.wordtimes$ntvr_language,dutch.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
english.corpus.pos.data.frame.wordtimes$ntvr_file = paste(english.corpus.pos.data.frame.wordtimes$ntvr_language,english.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
even.corpus.pos.data.frame.wordtimes$ntvr_file = paste(even.corpus.pos.data.frame.wordtimes$ntvr_language,even.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
hoocak.corpus.pos.data.frame.wordtimes$ntvr_file = paste(hoocak.corpus.pos.data.frame.wordtimes$ntvr_language,hoocak.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
nuu.corpus.pos.data.frame.wordtimes$ntvr_file = paste(nuu.corpus.pos.data.frame.wordtimes$ntvr_language,nuu.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
popoluca.corpus.pos.data.frame.wordtimes$ntvr_file = paste(popoluca.corpus.pos.data.frame.wordtimes$ntvr_language,popoluca.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")
sakha.corpus.pos.data.frame.wordtimes$ntvr_file = paste(sakha.corpus.pos.data.frame.wordtimes$ntvr_language,sakha.corpus.pos.data.frame.wordtimes$ntvr_file,sep=" ")

baure.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(baure.corpus.pos.data.frame.wordtimes.words$ntvr_language,baure.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
bora.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(bora.corpus.pos.data.frame.wordtimes.words$ntvr_language,bora.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
chintang.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(chintang.corpus.pos.data.frame.wordtimes.words$ntvr_language,chintang.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
dutch.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(dutch.corpus.pos.data.frame.wordtimes.words$ntvr_language,dutch.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
english.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(english.corpus.pos.data.frame.wordtimes.words$ntvr_language,english.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
even.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(even.corpus.pos.data.frame.wordtimes.words$ntvr_language,even.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
hoocak.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(hoocak.corpus.pos.data.frame.wordtimes.words$ntvr_language,hoocak.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
nuu.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(nuu.corpus.pos.data.frame.wordtimes.words$ntvr_language,nuu.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
popoluca.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(popoluca.corpus.pos.data.frame.wordtimes.words$ntvr_language,popoluca.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")
sakha.corpus.pos.data.frame.wordtimes.words$ntvr_file = paste(sakha.corpus.pos.data.frame.wordtimes.words$ntvr_language,sakha.corpus.pos.data.frame.wordtimes.words$ntvr_file,sep=" ")


# Number of speakers per text
baure.number.of.speakers = as.table(by(baure.corpus.pos.data.frame.excluded,baure.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
bora.number.of.speakers = as.table(by(bora.corpus.pos.data.frame.excluded,bora.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
chintang.number.of.speakers = as.table(by(chintang.corpus.pos.data.frame.excluded,chintang.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
dutch.number.of.speakers = as.table(by(dutch.corpus.pos.data.frame.excluded,dutch.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
english.number.of.speakers = as.table(by(english.corpus.pos.data.frame.excluded,english.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
even.number.of.speakers = as.table(by(even.corpus.pos.data.frame.excluded,even.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
hoocak.number.of.speakers = as.table(by(hoocak.corpus.pos.data.frame.excluded,hoocak.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
nuu.number.of.speakers = as.table(by(nuu.corpus.pos.data.frame.excluded,nuu.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
popoluca.number.of.speakers = as.table(by(popoluca.corpus.pos.data.frame.excluded,popoluca.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))
sakha.number.of.speakers = as.table(by(sakha.corpus.pos.data.frame.excluded,sakha.corpus.pos.data.frame.excluded$ntvr_file,function(x) length(unique(na.omit(x$ELANParticipant)))))

# Add information about the number of speakers
baure.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(baure.number.of.speakers[baure.corpus.pos.data.frame.excluded$ntvr_file])
bora.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(bora.number.of.speakers[bora.corpus.pos.data.frame.excluded$ntvr_file])
chintang.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(chintang.number.of.speakers[chintang.corpus.pos.data.frame.excluded$ntvr_file])
dutch.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(dutch.number.of.speakers[dutch.corpus.pos.data.frame.excluded$ntvr_file])
english.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(english.number.of.speakers[english.corpus.pos.data.frame.excluded$ntvr_file])
even.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(even.number.of.speakers[even.corpus.pos.data.frame.excluded$ntvr_file])
hoocak.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(hoocak.number.of.speakers[hoocak.corpus.pos.data.frame.excluded$ntvr_file])
nuu.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(nuu.number.of.speakers[nuu.corpus.pos.data.frame.excluded$ntvr_file])
popoluca.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(popoluca.number.of.speakers[popoluca.corpus.pos.data.frame.excluded$ntvr_file])
sakha.corpus.pos.data.frame.excluded$speakers_per_session = as.numeric(sakha.number.of.speakers[sakha.corpus.pos.data.frame.excluded$ntvr_file])

baure.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(baure.number.of.speakers[baure.corpus.pos.data.frame.wordtimes$ntvr_file])
bora.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(bora.number.of.speakers[bora.corpus.pos.data.frame.wordtimes$ntvr_file])
chintang.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(chintang.number.of.speakers[chintang.corpus.pos.data.frame.wordtimes$ntvr_file])
dutch.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(dutch.number.of.speakers[dutch.corpus.pos.data.frame.wordtimes$ntvr_file])
english.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(english.number.of.speakers[english.corpus.pos.data.frame.wordtimes$ntvr_file])
even.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(even.number.of.speakers[even.corpus.pos.data.frame.wordtimes$ntvr_file])
hoocak.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(hoocak.number.of.speakers[hoocak.corpus.pos.data.frame.wordtimes$ntvr_file])
nuu.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(nuu.number.of.speakers[nuu.corpus.pos.data.frame.wordtimes$ntvr_file])
popoluca.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(popoluca.number.of.speakers[popoluca.corpus.pos.data.frame.wordtimes$ntvr_file])
sakha.corpus.pos.data.frame.wordtimes$speakers_per_session = as.numeric(sakha.number.of.speakers[sakha.corpus.pos.data.frame.wordtimes$ntvr_file])

baure.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(baure.number.of.speakers[baure.corpus.pos.data.frame.wordtimes.words$ntvr_file])
bora.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(bora.number.of.speakers[bora.corpus.pos.data.frame.wordtimes.words$ntvr_file])
chintang.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(chintang.number.of.speakers[chintang.corpus.pos.data.frame.wordtimes.words$ntvr_file])
dutch.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(dutch.number.of.speakers[dutch.corpus.pos.data.frame.wordtimes.words$ntvr_file])
english.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(english.number.of.speakers[english.corpus.pos.data.frame.wordtimes.words$ntvr_file])
even.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(even.number.of.speakers[even.corpus.pos.data.frame.wordtimes.words$ntvr_file])
hoocak.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(hoocak.number.of.speakers[hoocak.corpus.pos.data.frame.wordtimes.words$ntvr_file])
nuu.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(nuu.number.of.speakers[nuu.corpus.pos.data.frame.wordtimes.words$ntvr_file])
popoluca.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(popoluca.number.of.speakers[popoluca.corpus.pos.data.frame.wordtimes.words$ntvr_file])
sakha.corpus.pos.data.frame.wordtimes.words$speakers_per_session = as.numeric(sakha.number.of.speakers[sakha.corpus.pos.data.frame.wordtimes.words$ntvr_file])


## Corpus statistics of part actually used in articulation speed study - individual words
### Corpus statistics

# Number of sessions
length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 37

length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 37

length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 40

length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 17

length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 47

length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 67

length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 62

length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 33

length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 6

length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$ntvr_file)))
[1] 16

# Number of speakers
length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 12

length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 46

length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 74

length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 42

length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 80

length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 32

length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 28

length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 7

length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 1

length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$ELANParticipant)))
[1] 25

# Number of records
length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 4343

length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 3979

length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 9026 # Changed

length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 5746

length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 6941

length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 4839

length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 2936

length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 7775

length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 5461

length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 3925

# Number of words
length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 17652

length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 29801

length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 37737 # Changed

length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 39448

length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 56136 # Changed

length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 37394

length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 23181

length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 25850

length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 21321

length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 31139

# Number of morphemes
length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 33116

length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 66048

length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 68501 # Changed

length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 39448

length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 61562 # Changed

length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 71266

length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 41037

length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 29417

length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 39688

length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$morpheme.id)))
[1] 52384

# Words per annotation unit
length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 4.064472

length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 7.48957

length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 4.180922 # Changed

length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 6.865298

length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 8.087595 # Changed

length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 7.72763

length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 7.895436

length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 3.324759

length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 3.90423

length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$word.id))) / length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$ntvr_ref)))
[1] 7.933503

# Morphemes per word
length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(baure.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1.876048

length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(bora.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 2.216301

length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(chintang.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1.815221 # Changed

# Artifact of lack of morphological analysis
length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(dutch.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1

length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(english.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1.096658 # Changed

length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(even.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1.905814

length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(hoocak.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1.770286

length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(nuu.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1.137988

length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(popoluca.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1.861451

length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$morpheme.id))) / length(unique(na.omit(sakha.corpus.pos.data.frame.wordtimes.words$word.id)))
[1] 1.682263


### Combine data frame for word times - individual words

common.columns.wordtimes.words = c("record.id","word.id","morpheme.id","ntvr_language","language","word_order","agreement","case_based",
"ntvr_file","speakers_per_session","logicity","plannedness","ntvr_ref","orig_ref","ntvr_number","code_switching","translation","ELANBegin","ELANEnd",
"ELANParticipant","seconds_per_record","seconds_per_record.no_fldps","seconds_per_record.no_pauses","seconds_per_record.no_pauses.no_fldps",
"pause_per_record","pause_per_record.no_fldps","pause_per_record_percentage","pause_per_record_percentage.no_fldps","words_per_record",
"words_per_record.no_fldps","flst_per_record","fldps_per_record","empty_word_in_record","morphs_per_record","morphs_per_record.no_fldps",
"chars_per_record","chars_per_record.no_fldps","speed_per_record","speed_per_record.no_fldps","log_speed_per_record","log_speed_per_record.no_fldps",
"inv_speed_per_record","inv_speed_per_record.no_fldps","log_inv_speed_per_record","log_inv_speed_per_record.no_fldps","speed_per_record.no_pauses",
"speed_per_record.no_pauses.no_fldps","log_speed_per_record.no_pauses","log_speed_per_record.no_pauses.no_fldps","inv_speed_per_record.no_pauses",
"inv_speed_per_record.no_pauses.no_fldps","log_inv_speed_per_record.no_pauses","log_inv_speed_per_record.no_pauses.no_fldps","final_lengthening",
"final_lengthening2","word","WordBegin","WordMidPoint","WordEnd","WordLength","pause_before_word","pause_after_word",
"fldps","morph","gloss","mt","lg","id","ps","ntvr_ps_root","ntvr_ps_word","whole_word_morph","whole_word_gloss","whole_word_mt","whole_word_lg",
"whole_word_id","whole_word_ps","whole_word_ntvr_ps_root","le","root","position","position.no_fldps","position_from_last","position_from_last.no_fldps",
"position_percentage","position_percentage.no_fldps","final.word","word_type","word_freq","word_freq_rank","word_freq_rank2","morphs_per_word","chars_per_word","speed_per_word",
"log_speed_per_word","inv_speed_per_word","log_inv_speed_per_word")

# Check columns
setdiff(common.columns.wordtimes.words,colnames(baure.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(bora.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(chintang.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(dutch.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(english.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(even.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(hoocak.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(nuu.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(popoluca.corpus.pos.data.frame.wordtimes.words))
setdiff(common.columns.wordtimes.words,colnames(sakha.corpus.pos.data.frame.wordtimes.words))

# Check additional potentially interesting columns
# (maybe check sex for English data)
intersect(intersect(intersect(intersect(intersect(intersect(intersect(intersect(intersect(
setdiff(colnames(baure.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words),
setdiff(colnames(bora.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words)),
setdiff(colnames(chintang.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words)),
setdiff(colnames(dutch.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words)),
setdiff(colnames(english.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words)),
setdiff(colnames(even.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words)),
setdiff(colnames(hoocak.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words)),
setdiff(colnames(nuu.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words)),
setdiff(colnames(popoluca.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words)),
setdiff(colnames(sakha.corpus.pos.data.frame.wordtimes.words),common.columns.wordtimes.words))

 [1] "words_per_prewindow"                               "words_per_prewindow.no_fldps"                     
 [3] "chars_per_prewindow"                               "chars_per_prewindow.no_fldps"                     
 [5] "morphs_per_prewindow"                              "morphs_per_prewindow.no_fldps"                    
 [7] "seconds_per_prewindow"                             "seconds_per_prewindow.no_fldps"                   
 [9] "seconds_per_prewindow.no_pauses"                   "seconds_per_prewindow.no_pauses.no_fldps"         
[11] "pause_per_prewindow.no_fldps"                      "pause_per_prewindow_percentage"                   
[13] "pause_per_prewindow_percentage.no_fldps"           "pause_per_prewindow"                              
[15] "speed_per_prewindow"                               "speed_per_prewindow.no_fldps"                     
[17] "log_speed_per_prewindow"                           "log_speed_per_prewindow.no_fldps"                 
[19] "inv_speed_per_prewindow"                           "inv_speed_per_prewindow.no_fldps"                 
[21] "log_inv_speed_per_prewindow"                       "log_inv_speed_per_prewindow.no_fldps"             
[23] "speed_per_prewindow.no_pauses"                     "speed_per_prewindow.no_pauses.no_fldps"           
[25] "log_speed_per_prewindow.no_pauses"                 "log_speed_per_prewindow.no_pauses.no_fldps"       
[27] "inv_speed_per_prewindow.no_pauses"                 "inv_speed_per_prewindow.no_pauses.no_fldps"       
[29] "log_inv_speed_per_prewindow.no_pauses"             "log_inv_speed_per_prewindow.no_pauses.no_fldps"   
[31] "fldps_per_prewindow"                               "flst_per_prewindow"                               
[33] "PrewindowBegin"                                    "PrewindowBegin.no_fldps"                          
[35] "empty_word_in_prewindow"                           "verbs_per_prewindow"                              
[37] "verbs_per_prewindow.no_fldps"                      "nouns_per_record"                                 
[39] "verbs_per_record"                                  "auxiliaries_per_record"                           
[41] "pronouns_per_record"                               "bound_pronouns_per_record"                        
[43] "NTVR.nouns_per_record"                             "NTVR.nouns.and.pronouns_per_record"               
[45] "NTVR.nouns.pronouns.and.bound_pronouns_per_record" "alternative.NTVR.nouns_per_record"                
[47] "verbs_per_record.words"                            "all_verbs_per_record"                             
[49] "NTVR_per_record"                                   "alternative.NTVR_per_record"                      
[51] "all_verbs_per_record.words"                        "all_verbs_per_prewindow"                          
[53] "all_verbs_per_prewindow.no_fldps"                  "alternative.NTVR.nouns_per_record.no_fldps"       
[55] "alternative.NTVR_per_record.no_fldps"              "pause_per_prewindow_factor_100"                   
[57] "pause_per_prewindow_factor_100.no_fldps"           "pause_per_prewindow_factor_150"                   
[59] "pause_per_prewindow_factor_150.no_fldps"           "pause_fldps_per_prewindow_factor_100"             
[61] "pause_fldps_per_prewindow_factor_150"              "pause_per_prewindow_factor"                       
[63] "pause_per_prewindow_factor.no_fldps"               "pause_fldps_per_prewindow_factor"                 

combined.wordtimes.words = rbind(baure.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
bora.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
chintang.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
dutch.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
english.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
even.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
hoocak.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
nuu.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
popoluca.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words],
sakha.corpus.pos.data.frame.wordtimes.words[,common.columns.wordtimes.words])

# Check for errors
combined.wordtimes.words$word[is.nan(combined.wordtimes.words$log_inv_speed_per_word)]
character(0)


### Plot a language map
map(interior=F)
points(ntvr.autotyp$longitude,ntvr.autotyp$latitude,col="red",pch=19,cex=1.5)
points(ntvr.autotyp$longitude,ntvr.autotyp$latitude,col="black",pch=1,cex=1.5)
text(ntvr.autotyp$longitude,ntvr.autotyp$latitude,col="black",ntvr.autotyp$language,pos=c(4,2,3,3,1,3,1,3,3,3),offset=0.3,cex=1.2)

library(extrafonts)
library(maps)
library(mapproj)
pdf("ntvr.language.map.pdf",width=12,height=8,family="CMU Sans Serif")
autotyp.map(ntvr.autotyp, color='red', labels='language', label.pos=c(4,2,3,3,1,3,1,3,3,3), cex=1.4, label.cex=1.4, label.offset=0.4)
dev.off()
embed_fonts("ntvr.language.map.pdf", outfile="ntvr.language.map.fonts.pdf")

pdf("ntvr.language.map.no_sakha.pdf",width=12,height=8,family="CMU Sans Serif")
autotyp.map(subset(ntvr.autotyp, language!="Sakha"), color='red', labels='language', label.pos=c(4,2,3,3,1,3,3,3,3), cex=1.4, label.cex=1.4, label.offset=0.4)
dev.off()
embed_fonts("ntvr.language.map.no_sakha.pdf", outfile="ntvr.language.map.no_sakha.fonts.pdf")
